<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[理解JavaScript作用域链]]></title>
    <url>%2F2017%2F09%2F16%2F%E7%90%86%E8%A7%A3JavaScript%E4%BD%9C%E7%94%A8%E5%9F%9F%E9%93%BE%2F</url>
    <content type="text"><![CDATA[最近在读《JavaScript权威指南》，读到“函数作用域和声明提前”这部分内容时有点晕，上网查了一些资料，算是弄明白了，所以把自己的理解记下来~ 作用域 全局作用域 在代码中任何地方都能访问到的对象拥有全局作用域，一般来说以下几种情形拥有全局作用域: 最外层函数和在最外层函数外面定义的变量拥有全局作用域，例如： 123456789101112var a="global";function doSomething()&#123; var b="local"; function innerSay()&#123; alert(b); &#125; innerSay();&#125;alert(a); //globalalert(b); //脚本错误doSomething(); //localinnerSay() //脚本错误 所有末定义直接赋值的变量自动声明为拥有全局作用域，例如： 12345678function doSomething()&#123; var a="local"; b="global"; alert(a);&#125;doSomething(); //localalert(b); //globalalert(a); //脚本错误 所有window对象的属性拥有全局作用域 一般情况下，window对象的内置属性都拥有全局作用域，例如window.name、window.location、window.top等等。 局部作用域 和全局作用域相反，局部作用域一般只在固定的代码片段内可访问到，最常见的例如函数内部，所有在一些地方也会看到有人把这种作用域称为函数作用域，例如下列代码中的a和函数innerSay都只拥有局部作用域。 123456789function doSomething()&#123; var a="local"; function innerSay()&#123; alert(a); &#125; innerSay();&#125;alert(a); //脚本错误innerSay(); //脚本错误 执行上下文在JavaScript中有三种代码运行环境： Global Code JavaScript代码开始运行的默认环境 Function Code 代码进入一个JavaScript函数 Eval Code 使用eval()执行代码 为了表示不同的运行环境，JavaScript中有一个执行上下文(Execution context，EC)的概念。也就是说，当JavaScript代码执行的时候，会进入不同的执行上下文，这些执行上下文就构成了一个执行上下文栈(Execution context stack，ECS)。 1234567891011121314151617181920var a = "global var";function foo()&#123; console.log(a);&#125;function outerFunc()&#123; var b = "var in outerFunc"; console.log(b); function innerFunc()&#123; var c = "var in innerFunc"; console.log(c); foo(); &#125; innerFunc();&#125;outerFunc() 代码首先进入Global Execution Context，然后依次进入outerFunc，innerFunc和foo的执行上下文，执行上下文栈就可以表示为： 当JavaScript代码执行的时候，第一个进入的总是默认的Global Execution Context，所以说它总是在ECS的最底部。 对于每个Execution Context都有三个重要的属性，变量对象(VO)，作用域链(Scope chain)和this。 问题提出123456789var a = 'global';function echo() &#123; alert(a); var a = 'local'; alert(a); alert(b);&#125;echo(); 运行结果为： 123undefinedlocal[脚本出错] 是不是跟你预想的不同？ 理解作用域链任何执行上下文时刻的作用域, 都是由作用域链(scope chain)来实现： 在一个函数被定义的时候, 这个函数对象的[[scope]]属性会指向它定义时刻的执行上下文的scope chain 在一个函数对象被调用的时候，会创建一个活动对象(AO)，然后将这个活动对象做为此时执行上下文的作用域链(scope chain)最前端, 并将这个函数对象的[[scope]]加入到scope chain中 例子： 1234function add(num1,num2) &#123; var sum = num1 + num2; return sum;&#125; 在执行func的定义语句的时候, 会创建一个这个函数对象的[[scope]]属性， 并将这个[[scope]]属性, 指向定义它的执行上下文的作用域链上。 此时因为add定义在全局环境, 所以此时的scope chain只是指向全局活动对象window active object 1var total = add(5,10); 在调用add的时候, 会创建一个活动对象(假设为aObj)，并创建arguments属性, 然后会给这个对象添加俩个命名属性aObj.num1, aObj.num2; 对于每一个在这个函数中申明的局部变量和函数定义, 都作为该活动对象的同名命名属性 然后将调用参数赋值给形参数，对于缺少的调用参数，赋值为undefined 然后将这个活动对象做为scope chain的最前端, 并将add的[[scope]]属性所指向的,scope chain, 加入到当前scope chain 有了上面的作用域链, 在发生标识符解析的时候, 就会逆向查询当前scope chain列表的每一个活动对象的属性，如果找到同名的就返回。找不到，那就是这个标识符没有被定义。 变量对象(VO)与活动对象(AO) 变量对象是在函数被调用，但是函数尚未执行的时刻被创建的，这个创建变量对象的过程实际就是函数内数据(函数参数、内部变量、内部函数)初始化的过程。 未进入执行阶段之前，变量对象中的属性都不能访问。但是进入执行阶段之后，变量对象转变为了活动对象，里面的属性都能被访问了，然后开始进行执行阶段的操作。所以活动对象实际就是变量对象在真正执行时的另一种形式。 实例1234567891011121314function factory() &#123; var a = 'local'; var intro = function()&#123; alert(a); &#125; return intro;&#125;function app(para)&#123; var a = para; factory();&#125;app('global'); 执行代码，在刚进入app函数体时，scope chain为： 123456789[[scope chain]] = [&#123; para : 'global', a : undefined, arguments : ['global']&#125;, &#123; window call object&#125;] 当调用进入factory的函数体的时候，此时的scope chain为: 12345678[[scope chain]] = [&#123; a : undefined, intor : undefined&#125;, &#123; window call object&#125;] 在定义intro函数的时候，intro函数的[[scope]]为: 12345678[[scope chain]] = [&#123; a : 'local', intor : undefined&#125;, &#123; window call object&#125;] 当调用进入intor的时候， 此时的scope chain为: 12345678910[[scope chain]] = [&#123; intro call object&#125;, &#123; a : 'local', intor : undefined&#125;, &#123; window call object&#125;] 运行结果为： 1local 问题解决回到”问题提出”部分： 当echo函数被调用的时候, echo的活动对象已经被预编译过程创建, 此时echo的活动对象为: 123[callObj] = &#123;name : undefined&#125; 当第一次alert的时候, 发生了标识符解析, 在echo的活动对象中找到了name属性, 所以这个name属性, 完全的遮挡了全局活动对象中的name属性 参考JavaScript的执行上下文 JavaScript 开发进阶：理解 JavaScript 作用域和作用域链 Javascript作用域原理 图解Javascript——变量对象和活动对象]]></content>
      <categories>
        <category>编程</category>
      </categories>
      <tags>
        <tag>javascript</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[组合模式的妙用]]></title>
    <url>%2F2017%2F09%2F16%2F%E7%BB%84%E5%90%88%E6%A8%A1%E5%BC%8F%E7%9A%84%E5%A6%99%E7%94%A8%2F</url>
    <content type="text"><![CDATA[组合模式定义 Component 是组合中的对象声明接口，在适当的情况下，实现所有类共有接口的默认行为。声明一个接口用于访问和管理Component子部件。 Leaf 在组合中表示叶子结点对象，叶子结点没有子结点。 Composite 定义有枝节点行为，用来存储子部件，在Component接口中实现与子部件有关操作，如增加(add)和删除 组合模式让多用于优化处理递归或分级数据结构，比如文件系统：文件系统由目录和文件组成。每个目录都可以装内容。目录的内容可以是文件，也可以是目录。按照这种方式，计算机的文件系统就是以递归结构来组织的。描述这样的数据结构，可以使用组合模式。 实践需求项目中有这样一个需求：上传一个zip格式的文件，服务器程序解压缩该文件，并生成json格式的文件层级描述，对于每个文件要求在json对象中包含该文件MD5、sha1、文件名以及大小。比如： 1234567891011121314151617181920212223242526272829303132333435363738&#123; &quot;children&quot;: [ &#123; &quot;children&quot;: [ &#123; &quot;md5&quot;: &quot;xxxxxxxxxxxx&quot;, &quot;sha1&quot;: &quot;xxxxxxxxxxxxx&quot;, &quot;size&quot;: 1024, &quot;path&quot;: &quot;123.txt&quot; &#125;, &#123; &quot;md5&quot;: &quot;xxxxxxxxxxxx&quot;, &quot;sha1&quot;: &quot;xxxxxxxxxxxxx&quot;, &quot;size&quot;: 1024, &quot;path&quot;: &quot;456.txt&quot; &#125; ], &quot;path&quot;: &quot;yukai&quot; &#125;, &#123; &quot;children&quot;: [ &#123; &quot;children&quot;: [ &#123; &quot;md5&quot;: &quot;xxxxxxxxxxxx&quot;, &quot;sha1&quot;: &quot;xxxxxxxxxx&quot;, &quot;size&quot;: 1024, &quot;path&quot;: &quot;123.txt&quot; &#125; ], &quot;path&quot;: &quot;book&quot; &#125; ], &quot;path&quot;: &quot;zhanglei&quot; &#125; ], &quot;path&quot;: &quot;we.zip&quot;&#125; 表示：123456789101112we.zip | |----zhanglei | | | |----book | | | |----123.txt |----yukai | | |----123.txt | |----456.txt 实现 根据上面提到组合模式的定义，实现文件的层级描述： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970public abstract class Component &#123; private String path; public Component(String path) &#123; this.path = path; &#125; public abstract void add(Component component); public String getPath() &#123; return path; &#125; public void setPath(String path) &#123; this.path = path; &#125;&#125;public class Composite extends Component&#123; private List&lt;Component&gt; children; public Composite(String path) &#123; super(path); children = new ArrayList&lt;&gt;(); &#125; @Override public void add(Component component) &#123; children.add(component); &#125;&#125;public class Leaf extends Component &#123; public Leaf(String path) &#123; super(path); &#125; private String md5; private String sha1; private long size; @Override public void add(Component component) &#123; return; &#125; public String getMd5() &#123; return md5; &#125; public void setMd5(String md5) &#123; this.md5 = md5; &#125; public String getSha1() &#123; return sha1; &#125; public void setSha1(String sha1) &#123; this.sha1 = sha1; &#125; public long getSize() &#123; return size; &#125; public void setSize(long l) &#123; this.size = l; &#125;&#125; 写一个简单的测试类测试我们的实现： 123456789101112131415161718192021222324252627@Testpublic void testComponent() &#123; Composite root = new Composite("we.zip"); Composite component1 = new Composite("yukai"); Leaf leaf1 = new Leaf("123.txt"); leaf1.setMd5("xxxxxxxxxxx"); leaf1.setSha1("xxxxxxxxxxxxx"); leaf1.setSize(1024); component1.add(leaf1); Leaf leaf2 = new Leaf("456.txt"); leaf1.setMd5("xxxxxxxxxxx"); leaf1.setSha1("xxxxxxxxxxxxx"); leaf1.setSize(1024); Composite component2 = new Composite("zhanglei"); Component component3 = new Composite("book"); Leaf leaf = new Leaf("123.txt"); leaf.setMd5("xxxxxxxx"); leaf.setSha1("xxxxxxx"); leaf.setSize(1024); component3.add(leaf); component2.add(component3); root.add(component1); root.add(component2); Gson gson = new Gson(); String json = gson.toJson(root); System.out.println(json);&#125; 输出的结果正好是我们上面提到的json串。 递归遍历文件目录，生成json树 上面的数据结构可以满足我们对生成的json树的格式要求，接下来便是遍历文件目录，生成组合模式中的结构，代码很简单： 1234567891011121314151617181920212223public void walk(Path parentPath, Component parent) throws IOException &#123; File file = parentPath.toFile(); File[] list = file.listFiles(); if (list == null) &#123; return; &#125; Composite composite; Leaf leaf; for (File f : list) &#123; String currentName = f.getName(); if (f.isDirectory()) &#123; composite = new Composite(currentName); parent.add(composite); walk(f.toPath(), composite); &#125; else &#123; leaf = new Leaf(currentName); leaf.setSize(f.length()); leaf.setMd5(FileProvider.md5Hex(f)); leaf.setSha1(FileProvider.sha1Hex(f)); parent.add(leaf); &#125; &#125;&#125; 上面的代码使用递归的方式，遍历文件目录，生成目录结构。我们可以这样使用它： 1234567String zipFile = ".../..../..../abc.zip";File file = new File(zipFile);Composite root = new Composite(file.getName());walkDirectory(file.toPath(), root);Gson gson = new Gson();String json = gson.toJson(root);System.out.println(json); 通过上面的代码，看似复杂的生成文件json树的需求就被轻易的解决了，看起来真的很优雅！ have a nice day~~~]]></content>
      <categories>
        <category>编程</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>设计模式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java-NIO-Reactor]]></title>
    <url>%2F2017%2F09%2F13%2FJava-NIO-Reactor%2F</url>
    <content type="text"><![CDATA[接着学习java-NIO。这次要从宏观架构上来学习NIO，并涉及到一个模型：Reactor线程模型。 传统的BIO模式 12345678910111213141516171819202122232425262728class Server &#123; public static void main() &#123; ExecutorService executor = Excutors.newFixedThreadPollExecutor(100);//线程池 ServerSocket serverSocket = new ServerSocket(); serverSocket.bind(8088); while(!Thread.currentThread.isInturrupted())&#123;//主线程死循环等待新连接到来 Socket socket = serverSocket.accept(); executor.submit(new ConnectIOnHandler(socket));//为新的连接创建新的线程 &#125; &#125; static class ConnectIOnHandler implements Runnable &#123; private Socket socket; public ConnectIOnHandler(Socket socket)&#123; this.socket = socket; &#125; public void run()&#123; while(!Thread.currentThread.isInturrupted()&amp;&amp;!socket.isClosed())&#123; String someThing = socket.read();//读取数据 if(someThing!=null)&#123; ......//处理数据 socket.write()....//写数据 &#125; &#125; &#125; &#125;&#125; 上面的代码中，我们在主线程中处理客户端的连接请求，然后为每个建立的连接分配一个线程去执行。socket.read()、socket.write()是同步阻塞的，我们开启了多线程，就可以让CPU去处理更多的连接，这也是多线程的本质： 利用了多核的并行处理能力 当io阻塞系统，但CPU空闲时，利用多线程使用CPU资源 上面的方案也有其致命缺陷，因为其本质还是依赖线程: 线程创建和销毁的代价很高 线程很占内存 线程的切换带来的资源消耗。有可能恰好轮到一个线程的时间片，但此时这个线程被io阻塞，这时会发生线程切换(无意义的损耗) 上面的线程池定义了100个线程，意味着同时只能为100个用户服务。倘若服务器同故障节点通信，由于其io是阻塞的，如果所有可用线程被故障节点阻塞，那么新的请求在队列中排队,直到连接超时。 所以，当面对数十万的连接请求，传统的BIO是无能为力的。 NIO工作原理回顾前面的学习内容 Linux网络IO模型 BIO的read过程：发起系统调用，试图从内核空间读取数据到用户空间，如果数据没有就绪(数据还没有从硬件拷贝到内核)，一直阻塞，直到返回数据 NIO的处理过程：发起系统调用，试图从内核空间读取数据到用户空间，如果数据没有就绪，直接返回0，永远也不会阻塞 需要注意的是： 从内核拷贝数据到用户空间这个io操作是阻塞的，而且需要消耗CPU(性能非常高，基本不耗时) BIO等待内核数据就绪的过程是空等，不需要CPU Reactor与NIO相结合所谓的Reactor模式，核心就是事件驱动，或者j叫回调的方式。这种方式就是，应用业务向一个中间人注册一个回调（event handler），当IO就绪后，就这个中间人产生一个事件，并通知此handler进行处理。 那么由谁来充当这个中间人呢？是由一个不断等待和循环的单独进程（线程）来做这件事，它接受所有handler的注册，并负责先操作系统查询IO是否就绪，在就绪后就调用指定handler进行处理，这个角色的名字就叫做Reactor。 回想一下 Linux网络IO模型 中提到的 IO复用，一个线程可以同时处理多个Connection，是不是正好契合Reactor的思想。所以，在java中可以使用NIO来实现Reactor模型。 单线程Reactor Reactor：负责响应事件，将事件分发给绑定了该事件的Handler处理； Handler：事件处理器，绑定了某类事件，负责执行对应事件的Task对事件进行处理； Acceptor：Handler的一种，绑定了connect事件。当客户端发起connect请求时，Reactor会将accept事件分发给Acceptor处理。 看一下其对应的实现： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384class Reactor implements Runnable &#123; final Selector selector; final ServerSocketChannel serverSocket; Reactor(int port) throws IOException &#123; //Reactor初始化 selector = Selector.open(); serverSocket = ServerSocketChannel.open(); serverSocket.socket().bind(new InetSocketAddress(port)); serverSocket.configureBlocking(false); //非阻塞 SelectionKey sk = serverSocket.register(selector, SelectionKey.OP_ACCEPT); //分步处理,第一步,接收accept事件 sk.attach(new Acceptor()); //attach callback object, Acceptor &#125; public void run() &#123; try &#123; while (!Thread.interrupted()) &#123; selector.select(); Set selected = selector.selectedKeys(); Iterator it = selected.iterator(); while (it.hasNext()) dispatch((SelectionKey)(it.next()); //Reactor负责dispatch收到的事件 selected.clear(); &#125; &#125; catch (IOException ex) &#123; /* ... */ &#125; &#125; void dispatch(SelectionKey k) &#123; Runnable r = (Runnable)(k.attachment()); //调用之前注册的callback对象 if (r != null) r.run(); &#125; class Acceptor implements Runnable &#123; // inner public void run() &#123; try &#123; SocketChannel c = serverSocket.accept(); if (c != null) new Handler(selector, c); &#125; catch(IOException ex) &#123; /* ... */ &#125; &#125; &#125;&#125;final class Handler implements Runnable &#123; final SocketChannel socket; final SelectionKey sk; ByteBuffer input = ByteBuffer.allocate(MAXIN); ByteBuffer output = ByteBuffer.allocate(MAXOUT); static final int READING = 0, SENDING = 1; int state = READING; Handler(Selector sel, SocketChannel c) throws IOException &#123; socket = c; c.configureBlocking(false); // Optionally try first read now sk = socket.register(sel, 0); sk.attach(this); //将Handler作为callback对象 sk.interestOps(SelectionKey.OP_READ); //第二步,接收Read事件 sel.wakeup(); &#125; boolean inputIsComplete() &#123; /* ... */ &#125; boolean outputIsComplete() &#123; /* ... */ &#125; void process() &#123; /* ... */ &#125; public void run() &#123; try &#123; if (state == READING) read(); else if (state == SENDING) send(); &#125; catch (IOException ex) &#123; /* ... */ &#125; &#125; void read() throws IOException &#123; socket.read(input); if (inputIsComplete()) &#123; process(); state = SENDING; // Normally also do first write now sk.interestOps(SelectionKey.OP_WRITE); //第三步,接收write事件 &#125; &#125; void send() throws IOException &#123; socket.write(output); if (outputIsComplete()) sk.cancel(); //write完就结束了, 关闭select key &#125;&#125; NIO由原来的阻塞读写（占用线程）变成了单线程轮询事件，找到可以进行读写的网络描述符进行读写。除了事件的轮询是阻塞的（没有可干的事情必须要阻塞），剩余的I/O操作都是纯CPU操作，没有必要开启多线程。 缺点： 一个连接里完整的网络处理过程一般分为accept、read、decode、process(compute)、encode、send这几步，如果在process这个过程中需要处理大量的耗时业务，比如连接DB或者进行耗时的计算等，整个线程都被阻塞，无法处理其他的链路 单线程，不能充分利用多核处理器 单线程处理I/O的效率确实非常高，没有线程切换，只是拼命的读、写、选择事件。但是如果有成千上万个链路，即使不停的处理，一个线程也无法支撑 单线程，一旦线程意外进入死循环或者抛出未捕获的异常，整个系统就挂掉了 对于缺点1，通常的解决办法是将decode、process、encode扔到后台业务线程池中执行，避免阻塞reactor。但对于缺点2、3、4，单线程的reactor是无能为力的。 多线程的Reactor 有专门一个reactor线程用于监听服务端ServerSocketChannel，接收客户端的TCP连接请求； 网络IO的读/写操作等由一个worker reactor线程池负责，由线程池中的NIO线程负责监听SocketChannel事件，进行消息的读取、解码、编码和发送。 一个NIO线程可以同时处理N条链路，但是一个链路只注册在一个NIO线程上处理，防止发生并发操作问题。 注意，socketchannel、selector、thread三者的对应关系是： socketchannel只能注册到一个selector上，但是一个selector可以被多个socketchannel注册； selector与thread一般为一一对应。 12345678910Selector[] selectors; // 一个selector对应一个线程int next = 0;class Acceptor &#123; public synchronized void run() &#123; ... Socket connection = serverSocket.accept(); if (connection != null) new Handler(selectors[next], connection); if (++next == selectors.length) next = 0; &#125;&#125; 主从多线程Reactor 在绝大多数场景下，Reactor多线程模型都可以满足性能需求；但是在极个别特殊场景中，一个NIO线程负责监听和处理所有的客户端连接可能会存在性能问题。比如，建立连接时需要进行复杂的验证和授权工作等。 服务端用于接收客户端连接的不再是个1个单独的reactor线程，而是一个boss reactor线程池； 服务端启用多个ServerSocketChannel监听不同端口时，每个ServerSocketChannel的监听工作可以由线程池中的一个NIO线程完成。 NIO实战 参考老外写的一个 Java-NIO-Server：Java NIO: Non-blocking Server，代码在 github上。不错的一个参考，解决了NIO中半包粘包的问题，但是代码可读性不高； 另外一个NIO-Server，代码比较简单，可读性较高，代码风格值得学习。但避开了半包粘包的问题，也不算是正真意义上的Reactor模型。 参考Scalable IO in Java netty学习系列：NIO Reactor模型 &amp; Netty线程模型 Java NIO浅析]]></content>
      <categories>
        <category>编程</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>NIO</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[炒茄子]]></title>
    <url>%2F2017%2F09%2F09%2F%E7%82%92%E8%8C%84%E5%AD%90%2F</url>
    <content type="text"><![CDATA[原料茄子、姜片、葱、蒜、干辣椒、郫县豆瓣酱、盐、花椒粒、料酒、醋、生抽、白糖、味精 做法 茄子一个，洗净，切成条 锅烧热，直接将切好的茄条倒入，小火翻炒，直到茄子变软，且水分炒调一些，盛出 锅中倒油，油七成热后加入姜片、葱丝、蒜末、干辣椒、花椒粒炒香 放入一勺郫县豆瓣酱，继续翻炒出红油和香味 倒入茄子条，翻炒几下 将香醋3勺，生抽2勺，盐半勺，料酒1勺，白糖1勺，味精半勺调成汁，倒入锅中 翻炒均匀，待调味汁收干入味后撒葱花出锅 成品加了洋葱一起炒～]]></content>
      <categories>
        <category>生活</category>
      </categories>
      <tags>
        <tag>食物</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[git服务器的配置]]></title>
    <url>%2F2017%2F09%2F06%2Fgit%E6%9C%8D%E5%8A%A1%E5%99%A8%E7%9A%84%E9%85%8D%E7%BD%AE%2F</url>
    <content type="text"><![CDATA[公司一直在使用Starteam作版本控制，这是个很古老的工具，也有不少的BUG…最近为公司搭建了Git服务器试用，把搭建的过程记录下来… ssh配置可以使用ssh协议搭建ssh服务，适合于几个人的小团队，每个人都拥有读写的权限。 配置git服务器通过创建一个专门的git用户，作为访问git服务的账户123456$ ssh root@192.168.1.110$ sudo adduser git$ su git$ cd$ mkdir .ssh &amp;&amp; chmod 700 .ssh$ touch .ssh/authorized_keys &amp;&amp; chmod 600 .ssh/authorized_keys 配置客户机 安装git 本机生成ssh key123456789101112131415右键，打开Git Bash Here$ ssh-keygen -t rsa -b 4096 -C &quot;your_email@example.com&quot;Generating public/private rsa key pair.Enter a file in which to save the key (/c/Users/you/.ssh/id_rs[Press enter]Enter passphrase (empty for no passphrase): [Type a passphrase]Enter same passphrase again: [Type passphrase again]``` 3. 将公钥传送到远程主机上(git服务器所在的主机) $ ssh ssh-copy-id git@192.168.1.110### **新建仓库**以JDBC为例，仓库目录结构参照 Starteam:oscar5.7-&gt; OSCAR7.0_64BITS_DEV-&gt; OSCAR_RELEASE_2012- **新建裸仓库** $ ssh git@192.168.1.110$ cd git$ mkdir OSCAR_RELEASE_2012/Cross_Platform/jdbc.git$ cd OSCAR_RELEASE_2012/Cross_Platform/jdbc.git$ git init –bareInitialized empty Git repository in /home/git/git/OSCAR_RELEASE_2012/Cross_Platform/jdbc.git/12- **将项目推送到远程仓库**客户机yukai： 右键，打开Git Bash Here$ cd jdbc //进入JDBC源码所在的根目录$ git init$ git add .$ git commit -m ‘initial commit’$ git remote add origin git@192.168.1.110:/home/git/git/OSCAR_RELEASE_2012/Cross_Platform/jdbc.git/$ git push origin master12- **克隆git服务器上的仓库**客户机fuqiuying： 右键，打开Git Bash Here$ git clone git@192.168.1.110:/home/git/git/OSCAR_RELEASE_2012/Cross_Platform/jdbc.git/12345678- **修改git用户登录shell**需要注意的是，目前所有（获得授权的）开发者用户都能以系统用户 git 的身份登录服务器从而获得一个普通 shell借助一个名为 git-shell 的受限 shell 工具，你可以方便地将用户 git 的活动限制在与 Git 相关的范围内layout: post如果将 git-shell 设置为用户 git 的登录 shell，那么用户 git 便不能获得此服务器的普通 shell 访问权限 $ cat /etc/shells #查看git-shell是否已经存在于 /etc/shells 文件中$ which git-shell #查看git-shell的安装位置$ sudo vim /etc/shells #将上一步查询得到的git-shell安装位置加入到/etc/shells文件末尾$ sudo chsh git #执行此命令，修改git用户的shell，会提示输入修改的shell，这里修改为git-shell的安装位置1这样，用户 git 就只能利用 SSH 连接对 Git 仓库进行推送和拉取操作，而不能登录机器并取得普通 shell。 如果试图登录，你会发现尝试被拒绝，像这样： $ ssh git@gitserverfatal: Interactive git shell is not enabled.hint: ~/git-shell-commands should exist and have read and execute access.Connection to gitserver closed.12345678## gitlab配置gitlab可以说是一个翻版的GitHub，拥有权限管理，review等功能。适合于公司内部使用。centos7为例：- **配置安装环境** $ sudo yum install curl policycoreutils openssh-server openssh-clients$ sudo systemctl enable sshd$ sudo systemctl start sshd$ sudo yum install postfix$ sudo systemctl enable postfix$ sudo systemctl start postfix$ sudo firewall-cmd –permanent –add-service=http$ sudo systemctl reload firewalld1- **下载并安装** $ curl -sS http://packages.gitlab.com.cn/install/gitlab-ce/script.rpm.sh | sudo bash$ sudo yum install gitlab-ce1- **配置gitlab** $ sudo vim /etc/gitlab/gitlab.rb external_url=”192.168.1.110:8888”1- **开放端口并应用配置** $ sudo firewall-cmd –zone=public –add-port=8888/tcp –permanent$ sudo firewall-cmd –reload$ firewall-cmd –list-all$ sudo gitlab-ctl reconfigure1- **检测是否安装成功** $ sudo gitlab-ctl status[sudo] password for firehare:run: nginx: (pid 13334) 16103s; run: log: (pid 4244) 22211srun: postgresql: (pid 4153) 22280s; run: log: (pid 4152) 22280srun: redis: (pid 4070) 22291s; run: log: (pid 4069) 22291srun: sidekiq: (pid 4234) 22212s; run: log: (pid 4233) 22212srun: unicorn: (pid 4212) 22218s; run: log: (pid 4211) 22218s12- **gitlab汉化** $ sudo cat /opt/gitlab/embedded/service/gitlab-rails/VERSION123假设当前版本为 v9.5.2，并确认汉化版本库是否包含该版本的汉化标签(-zh结尾)，也就是是否包含 v9.5.2-zh。如果版本相同，首先在本地 clone 仓库。 克隆汉化版本库$ git clone https://gitlab.com/xhang/gitlab.git 如果已经克隆过，则进行更新$ git fetch1然后比较汉化标签和原标签，导出 patch 用的 diff 文件。 $ git diff v9.5.2 v9.5.2-zh &gt; ../9.5.2-zh.diff1上传 9.5.2-zh.diff 文件到服务器 $ cd ..$ sudo gitlab-ctl stop$ sudo yum -y install patch$ sudo patch -d /opt/gitlab/embedded/service/gitlab-rails -p1 &lt; 9.5.2-zh.diff1重启gitlab $ sudo gitlab-ctl start$ sudo gitlab-ctl reconfigure``` 参考 git book gitlab中文网 gitlab汉化]]></content>
      <categories>
        <category>工具</category>
      </categories>
      <tags>
        <tag>git</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[红烧排骨]]></title>
    <url>%2F2017%2F09%2F01%2F%E7%BA%A2%E7%83%A7%E6%8E%92%E9%AA%A8%2F</url>
    <content type="text"><![CDATA[原料排骨、葱片、姜片、八角、花椒粒、料酒、生抽、蚝油、盐、白糖 做法 锅中倒水，将剁好洗净的肋排放入，煮几分钟，撇去杂质后捞出 锅中放少许油烧热，放入葱花、姜片、八角、花椒炒香 放入肋排，翻炒至肉变色(注意时间不要太长，否则肉会变老) 倒入料酒、生抽、蚝油，翻炒几下 加入清水(高汤)刚好没过排骨，大火烧开 小火慢炖四十分钟左右，大火收汁出锅 成品]]></content>
      <categories>
        <category>生活</category>
      </categories>
      <tags>
        <tag>食物</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[状态机与状态模式]]></title>
    <url>%2F2017%2F08%2F10%2F%E7%8A%B6%E6%80%81%E6%9C%BA%E4%B8%8E%E7%8A%B6%E6%80%81%E6%A8%A1%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[又是很长时间没有写博客了(一个月)…最近在做一个SpringBoot+Vue的项目，所以一直在看spring相关的东西。今天要学习的跟spring没有关系，是我在之前维护的一个测试工具是遇到的一个知识点–状态机 这个测试的一个功能就是解析自己定义的一套脚本语法规则，涉及到对输入的语句进行解析，然后下发到对应的执行器去执行。 之前的解析逻辑是用一个while循环，对每一个字符判断，然后各种if…else和临时变量…总之读起来十分费劲，并且总容易出BUG，而且十分不容易修改，因为每一个修改都很容易影响到原来的解析结果。于是我把这段解析的代码重构了一遍，就是使用了状态机的思想。 什么是状态机 有限状态机（英语：finite-state machine，缩写：FSM）又称有限状态自动机，简称状态机，是表示有限个状态以及在这些状态之间的转移和动作等行为的数学模型。 状态机可归纳为4个要素，即现态、条件、动作、次态。“现态”和“条件”是因，“动作”和“次态”是果： 现态：是指当前所处的状态。 条件：又称为“事件”。当一个条件被满足，将会触发一个动作，或者执行一次状态的迁移。 动作：条件满足后执行的动作。动作执行完毕后，可以迁移到新的状态，也可以仍旧保持原状态。动作不是必需的，当条件满足后，也可以不执行任何动作，直接迁移到新状态。 次态：条件满足后要迁往的新状态。“次态”是相对于“现态”而言的，“次态”一旦被激活，就转变成新的“现态”了。 不是太好理解，我也是copy网上的概念，我们下面会举例子说明。 什么是状态模式 Context（环境类） 环境类又称为上下文类，它是拥有多种状态的对象。由于环境类的状态存在多样性且在不同状态下对象的行为有所不同，因此将状态独立出去形成单独的状态类。在环境类中维护一个抽象状态类State的实例，这个实例定义当前状态，在具体实现时，它是一个State子类的对象。 State（抽象状态类） 它用于定义一个接口以封装与环境类的一个特定状态相关的行为，在抽象状态类中声明了各种不同状态对应的方法，而在其子类中实现类这些方法，由于不同状态下对象的行为可能不同，因此在不同子类中方法的实现可能存在不同，相同的方法可以写在抽象状态类中。 ConcreteState（具体状态类） 它是抽象状态类的子类，每一个子类实现一个与环境类的一个状态相关的行为，每一个具体状态类对应环境的一个具体状态，不同的具体状态类其行为有所不同。 同样的，下面会举例说明。 一个例子假设现在有这么一个需求：给出一段java程序，要求删除其中的注释并返回删除注释之后的代码。 想想怎么去实现这个功能？初步的思路是在一个while循环里面，遍历这个String，对每个字符进行判断，然后是if else等等…功能肯定是可以实现的，但是我们有一个更加合适的套路，就是使用状态机。 设计状态机如下： 设正常状态为0，并且初始为正常状态 每遍历一个字符，就依次检查下列条件，若成立或全部检查完毕，则回到这里检查下一个字符 状态0中遇到/，说明可能会遇到注释，则进入状态1 例子： int a = b; / 状态1中遇到/，说明进入单行注释部分，则进入状态2 例子： int a = b; // 状态1中遇到，说明进入多行注释部分，则进入状态3 例子： int a= b; / 状态1中没有遇到*或/，说明/是路径符号或除号，则恢复状态0 例子： 8/3 状态2中遇到回车符\n，说明单行注释结束，则恢复状态0 例子： int a = b; //hehe 状态2中不是遇到回车符\n，说明单行注释还在继续，则维持状态2 例子： int a = b; //hehe 状态3中遇到，说明多行注释可能要结束，则进入状态4 例子： int a = b; /heh* 状态3中不是遇到，说明多行注释还在继续，则维持状态3 例子： int a = b; /hehe 状态4中遇到/，说明多行注释要结束，则恢复状态0 例子： int a = b; /hehe/ 状态4中不是遇到/，说明多行注释只是遇到，还要继续，则恢复状态3 例子： int a = b; /hehe*h 状态图： if else实现状态机1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192package space.kyu.mode.state;public class CodeProcessor1 &#123; private StringBuilder codeWithoutComment; private String originCode; public CodeProcessor1(String code) &#123; originCode = code; &#125; public String clearComment() &#123; codeWithoutComment = new StringBuilder(); char c, state; state = 0; for (int i = 0; i &lt; originCode.length(); ++i) &#123; c = getChar(i); if (state == 0) &#123; if (c == '/') &#123; state = 1; &#125; else &#123; putChar(c); // action &#125; &#125; else if (state == 1) &#123; if (c == '/') // 例子： int a = b; // &#123; state = 2; &#125; else if (c == '*') // 例子： int a= b; /* &#123; state = 3; &#125; else // 例子： &lt;common/md5.h&gt; or 8/3 &#123; state = 0; putChar('/'); // action putChar(c); // action &#125; &#125; else if (state == 2) &#123; if (c == '\n') // 例子： int a = b; //hehe &#123; state = 0; putChar(c); // action &#125; // 例子： int a = b; //hehe &#125; else if (state == 3) &#123; if (c == '*') // 例子： int a = b; /*heh* &#123; state = 4; &#125; // 例子： int a = b; /*hehe &#125; else if (state == 4) &#123; if (c == '/') // 例子： int a = b; /*hehe*/ &#123; state = 0; &#125; else // 例子： int a = b; /*hehe*h &#123; state = 3; &#125; &#125; else &#123; System.out.println("state error!"); &#125; &#125; return codeWithoutComment.toString(); &#125; private char getChar(int i) &#123; return originCode.charAt(i); &#125; private void putChar(char c) &#123; codeWithoutComment.append(c); &#125; public static void main(String[] args) &#123; String code = " public static void main(String[] args) &#123;" + "\n" + " /*hehe " + "\n" + " hehe " + "\n" + " */ " + "\n" + " /*hehe*/" + "\n" + " int a, int b; " + "\n" + " /* hehe */ " + "\n" + " //hehe" + "\n" + " a = 4+2; //hehe" + "\n" + " b = a;" + "\n" + " String file = \"/tmp/log.log\"" + "\n" + " &#125;"; System.out.println(code); System.out.println("*******************************"); CodeProcessor1 process = new CodeProcessor1(code); String str = process.clearComment(); System.out.println(str); &#125;&#125; 输出结果： 1234567891011121314151617181920212223public static void main(String[] args) &#123; /*hehe hehe */ /*hehe*/ int a, int b; /* hehe */ //hehe a = 4+2; //hehe b = a; String file = &quot;/tmp/log.log&quot; &#125;******************************* public static void main(String[] args) &#123; int a, int b; a = 4+2; b = a; String file = &quot;/tmp/log.log&quot; &#125; 状态模式实现状态机123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115package space.kyu.mode.state.interfac;public class CodeProcessor2 &#123; InputState currentState; StringBuilder codeWithoutComment; String originCode; public CodeProcessor2(String code) &#123; originCode = code; currentState = new Normal(); &#125; public String clearComment() &#123; codeWithoutComment = new StringBuilder(); for (int i = 0; i &lt; originCode.length(); ++i) &#123; char charAt = getChar(i); currentState.handleInput(charAt, this); &#125; return codeWithoutComment.toString(); &#125; private char getChar(int i) &#123; return originCode.charAt(i); &#125; public void putChar(char c) &#123; codeWithoutComment.append(c); &#125; public static void main(String[] args) &#123; String code = " public static void main(String[] args) &#123;" + "\n" + " /*hehe " + "\n" + " hehe " + "\n" + " */ " + "\n" + " /*hehe*/" + "\n" + " int a, int b; " + "\n" + " /* hehe */ " + "\n" + " //hehe" + "\n" + " a = 4+2; //hehe" + "\n" + " b = a;" + "\n" + " String file = \"/tmp/log.log\"" + "\n" + " &#125;"; System.out.println(code); System.out.println("*******************************"); CodeProcessor2 process = new CodeProcessor2(code); String str = process.clearComment(); System.out.println(str); &#125;&#125;abstract class InputState &#123; protected char backslash = '/'; protected char asterisk = '*'; protected char lineBreaks = '\n'; abstract void handleInput(char charAt, CodeProcessor2 processor);&#125;class Normal extends InputState &#123; @Override public void handleInput(char charAt, CodeProcessor2 processor) &#123; if (charAt == backslash) &#123; processor.currentState = new CommentSymbol(); &#125; else &#123; processor.putChar(charAt); &#125; &#125;&#125;class CommentSymbol extends InputState &#123; @Override public void handleInput(char charAt, CodeProcessor2 processor) &#123; if (charAt == backslash) &#123; processor.currentState = new SinglelineComment(); &#125; else if (charAt == asterisk) &#123; processor.currentState = new MutilineComment(); &#125; else &#123; processor.putChar('/'); processor.putChar(charAt); processor.currentState = new Normal(); &#125; &#125;&#125;class SinglelineComment extends InputState &#123; @Override public void handleInput(char charAt, CodeProcessor2 processor) &#123; if (charAt == lineBreaks) &#123; processor.putChar(charAt); processor.currentState = new Normal(); &#125; &#125;&#125;class MutilineComment extends InputState &#123; @Override public void handleInput(char charAt, CodeProcessor2 processor) &#123; if (charAt == asterisk) &#123; processor.currentState = new MutilineCommentEnding(); &#125; &#125;&#125;class MutilineCommentEnding extends InputState &#123; @Override public void handleInput(char charAt, CodeProcessor2 processor) &#123; if (charAt == backslash) &#123; processor.currentState = new Normal(); &#125; else &#123; processor.currentState = new MutilineComment(); &#125; &#125;&#125; 其中： CodeProcessor2 为 Context（环境类） InputState 为 State（抽象状态类） Normal等继承了InputState的类 为 ConcreteState（具体状态类） 输出结果： 1234567891011121314151617181920212223public static void main(String[] args) &#123; /*hehe hehe */ /*hehe*/ int a, int b; /* hehe */ //hehe a = 4+2; //hehe b = a; String file = &quot;/tmp/log.log&quot; &#125;******************************* public static void main(String[] args) &#123; int a, int b; a = 4+2; b = a; String file = &quot;/tmp/log.log&quot; &#125; enum实现状态机利用java中提供的enum实现状态机也是状态模式的一种，这样让代码更整洁并且不会产生很多的类导致类膨胀。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129package space.kyu.mode.state;public class CodeProcessor &#123; InputState currentState; StringBuilder codeWithoutComment; String originCode; public CodeProcessor(String code) &#123; originCode = code; currentState = States.NORMAL; &#125; public String clearComment() &#123; codeWithoutComment = new StringBuilder(); for(int i = 0; i &lt; originCode.length(); ++i)&#123; char charAt = getChar(i); currentState.handleInput(charAt, this); &#125; return codeWithoutComment.toString(); &#125; private char getChar(int i) &#123; return originCode.charAt(i); &#125; public void putChar(char c)&#123; codeWithoutComment.append(c); &#125; public static void main(String[] args) &#123; String code = " public static void main(String[] args) &#123;" + "\n" + " /*hehe " + "\n" + " hehe " + "\n" + " */ " + "\n" + " /*hehe*/" + "\n" + " int a, int b; " + "\n" + " /* hehe */ " + "\n" + " //hehe" + "\n" + " a = 4+2; //hehe" + "\n" + " b = a;" + "\n" + " String file = \"/tmp/log.log\"" + "\n" + " &#125;"; System.out.println(code); System.out.println("*******************************"); CodeProcessor process = new CodeProcessor(code); String str = process.clearComment(); System.out.println(str); &#125; &#125; interface InputState &#123; void handleInput(char charAt, CodeProcessor processor); &#125; enum States implements InputState &#123; /** * 正常状态 */ NORMAL&#123; @Override public void handleInput(char charAt, CodeProcessor processor) &#123; if (charAt == backslash) &#123; processor.currentState = COMMENT_SYMBOL; &#125; else &#123; processor.putChar(charAt); &#125; &#125; &#125;, /** * 遇到注释符 / */ COMMENT_SYMBOL&#123; @Override public void handleInput(char charAt, CodeProcessor processor) &#123; if (charAt == backslash) &#123; processor.currentState = SINGLE_LINE_COMMENT; &#125; else if (charAt == asterisk) &#123; processor.currentState = MUTI_LINE_COMMENT; &#125; else &#123; processor.putChar('/'); processor.putChar(charAt); processor.currentState = NORMAL; &#125; &#125; &#125;, /** * 进入单行注释 */ SINGLE_LINE_COMMENT&#123; @Override public void handleInput(char charAt, CodeProcessor processor) &#123; if (charAt == lineBreaks) &#123; processor.putChar(charAt); processor.currentState = NORMAL; &#125; &#125; &#125;, /** * 进入多行注释 */ MUTI_LINE_COMMENT&#123; @Override public void handleInput(char charAt, CodeProcessor processor) &#123; if (charAt == asterisk) &#123; processor.currentState = MUTI_LINE_COMMENT_ENDDING; &#125; &#125; &#125;, /** * 多行注释 遇到 * */ MUTI_LINE_COMMENT_ENDDING&#123; @Override public void handleInput(char charAt, CodeProcessor processor) &#123; if (charAt == backslash) &#123; processor.currentState = NORMAL; &#125; else &#123; processor.currentState = MUTI_LINE_COMMENT; &#125; &#125; &#125;; char backslash = '/'; char asterisk = '*'; char lineBreaks = '\n'; &#125; 输出结果：1234567891011121314151617181920212223 public static void main(String[] args) &#123; /*hehe hehe */ /*hehe*/ int a, int b; /* hehe */ //hehe a = 4+2; //hehe b = a; String file = &quot;/tmp/log.log&quot; &#125;******************************* public static void main(String[] args) &#123; int a, int b; a = 4+2; b = a; String file = &quot;/tmp/log.log&quot; &#125; 参考有限状态机]]></content>
      <categories>
        <category>编程</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>设计模式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[springboot配置https]]></title>
    <url>%2F2017%2F07%2F12%2Fspringboot%E9%85%8D%E7%BD%AEhttps%2F</url>
    <content type="text"><![CDATA[这两天打算在组内做个培训，关于Https方面的。于是一直在查资料，理解，顺便把今天了解的内容总结一下。 之前已经写过两篇有关ssl方面的笔记：关于加密的一点总结，ssl总结。当时的理解现在看来还有一些欠缺的地方，温故而知新嘛！ 数字签名 数字签名是一种类似写在纸上的普通的物理签名，但是使用了公钥加密领域的技术实现，用于鉴别数字信息的方法。(很空洞有木有~) 数字签名的作用：身份认证与完整性检验 下面模拟一个场景，小明给小红写一封信。 首先将摘要信息用发送者小明的私钥加密，生成数字签名，与原始信息一起传送给接收者小红。(什么是摘要信息，公钥私钥在前面的笔记中提到了，不再赘述) 小红使用小明的公钥对小明私钥加密后的摘要信息进行解密，如果解密成功，则说明接收到的内容确实由小明发出。这就完成了发送者小明的身份认证。 小红对收到的原始信息使用信息摘要算法得到其哈希值，与2中解密后的摘要信息进行比较，如果一致，证明原始信息未经篡改。保证了信息完整性（完整性检验）。 上面的过程有一个明显的疑问，就是小红是如何得到小明提供的公钥呢？ 把公钥放到互联网的某个地方的一个下载地址，事先给客户去下载？ 每次和客户开始通信时，服务器把公钥发给客户？ 客户无法确定这个下载地址是不是服务器发布的，你凭什么就相信这个地址下载的东西就是服务器发布的而不是别人伪造的呢，万一下载到一个假的怎么办？另外要所有的客户都在通信前事先去下载公钥也很不现实。 任何人都可以自己生成一对公钥和私钥，他只要向客户发送他自己的私钥就可以冒充服务器了。 所以。数字证书出现了。 数字证书 数字证书是一种权威性的电子文档，可以由权威公正的第三方机构，即CA（例如中国各地方的CA公司）中心签发的证书，也可以由企业级CA系统进行签发。 小红无法确定自己获得的公钥是不是小明的，她想到了一个办法： 要求小明去找“证书中心”（certificate authority，简称CA），为公钥做认证。证书中心用自己的私钥，对小明的公钥和一些相关信息一起加密，生成”数字证书”（Digital Certificate）。 小明以后再给小红写信，只要在签名的同时，再附上数字证书就行了。 小红收信后，用CA的公钥解开数字证书，就可以拿到小明真实的公钥了，然后就能证明“数字签名”是否真的是小明签的。 Https演化上面小明给小红写信的过程类似于https的工作原理。首先我们知道，所谓https是在http协议的基础上加了一层ssl/tls协议： ssl/tls能起到什么作用呢？ 所有信息都是加密传播，第三方无法窃听（窃听风险） 具有校验机制，一旦被篡改，通信双方会立刻发现（篡改风险） 配备身份证书，防止身份被冒充（冒充风险） 如何做到以上几点，参考之前的笔记中关于通信演化过程的内容。 https通信的过程如下图： 握手阶段服务器发送了自己的证书，确认了服务器的身份并且双方商议好了对称加密的算法好密钥，应用数据传输阶段就使用对称加密算法加密信息进行通信了。 证书链在握手阶段，服务器会把自己的证书发送到客户端(以浏览器为例)，那么客户端是怎么使用这个证书确认服务器的身份的呢？ 首先观察一下证书里有什么内容： 上图只截取了一部分，我们看几个比较重要的： Issuer (证书的发布机构) 指出是什么机构发布的这个证书，也就是指明这个证书是哪个公司创建的(只是创建证书，不是指证书的使用者)。 Valid from , Valid to (证书的有效期) 也就是证书的有效时间，或者说证书的使用期限。 过了有效期限，证书就会作废，不能使用了。 Public key (公钥) 公钥是用来对消息进行加密的，也就是服务器使用的公钥。 Subject (使用者) 这个证书是发布给谁的，或者说证书的所有者，一般是某个人或者某个公司名称、机构的名称、公司网站的网址等。 Thumbprint, Thumbprint algorithm (指纹以及指纹算法) 这个是用来保证证书的完整性的，也就是说确保证书没有被修改过。 其原理就是在发布证书时，发布者根据指纹算法(一个hash算法)计算整个证书的hash值(指纹)并和证书放在一起，使用者在打开证书时，自己也根据指纹算法计算一下证书的hash值(指纹)，如果和刚开始的值对得上，就说明证书没有被修改过，因为证书的内容被修改后，根据证书的内容计算的出的hash值(指纹)是会变化的。 Signature algorithm (签名所使用的算法) 指纹的加密结果就是数字签名。 注意，这个指纹会使用证书发布机构的私钥用签名算法(Signature algorithm)加密后生成数字签名和证书放在一起。 Signature algorithm就是指的这个数字证书的数字签名所使用的加密算法，这样就可以使用证书发布机构的证书里面的公钥，根据这个算法对指纹进行解密。 什么是证书链呢？ 上图中的Issuer’s DN即证书颁发机构，这样的证书颁发机构可能不止一个，上图表示一个3级证书链。 Owner’s DN 代表服务器发来的证书，浏览器得到这个证书之后根据Issuer’s DN获得该证书的颁发机构的证书，以此类推，最终得到根证书。比如 A-&gt;B-&gt;C-&gt;root 什么是根证书呢？一般是内嵌在操作系统中的，公认的可以信任的证书机构颁发的自签名证书。这些证书发布机构自己持有与他自己的数字证书对应的私钥，他会用这个私钥加密所有他发布的证书的指纹作为数字签名。浏览器无条件的信任根证书。 得到根证书后，拿到其公钥，然后使用这个公钥对证书链的上一级证书c依据Signature algorithm对指纹的加密结果(签名)进行解密，得到证书c的指纹。解密成功，证明c确实是由root颁发的，然后使用Thumbprint algorithm计算一下证书c的指纹，如果和解密得到的指纹相同，证明证书没有被篡改。因此，证书c是可以信任的。以此类推，证明证书A是可以信任的。也就是服务器发来的证书是可以信任的。 问题一：服务器可不可以随便下载一个认证的证书自己使用呢？ 证书中包含了服务器端的公钥，浏览器会使用该公钥加密一个随机字符串要求服务器解密。服务器没有该证书的私钥，故解密失败 问题二：可不可以篡改一个已经认证的服务器为我所用？ 证书中包含了证书的指纹，证书一经篡改就会被察觉 可以看到，https已经是很安全了。但是要注意，一旦信任根证书，则意味着信任了该证书所签发的所有下级证书，所以，安装根证书一定要谨慎！ 使用keytool生成证书使用下面的方法生成一个二级证书链： 生成根证书密钥 12keytool -genkey -alias CA -keyalg RSA -validity 365 -keystore server.keystore -storepass 123456 -keypass 123456 keytool -list -v -keystore server.keystore 生成自签名证书密钥 12keytool -genkey -keystore server.keystore -alias server -keyalg RSA -validity 365 -storepass 123456 -keypass 123456 keytool -list -keystore server.keystore -alias server 提交申请 12keytool -certreq -keystore server.keystore -alias server -storepass 123456 -file server.certreq keytool -printcertreq -file server.certreq -v 颁发证书 12// 新升级的chrome58，要求证书中至少包含一个[Subject Alternative Name](https://support.dnsimple.com/articles/what-is-ssl-san/)keytool -gencert -keystore server.keystore -alias CA -ext san=ip:192.168.1.70 -infile server.certreq -outfile server.crt -storepass 123456 自签名证书导入keystore 12keytool -importcert -keystore server.keystore -alias server -file server.crt -storepass 123456keytool -list -keystore server.keystore -v -alias server 导出根证书 1keytool -export -alias CA -keystore server.keystore -file CA.crt -storepass 123456 目录下得到以下几个文件： 1234CA.crt //根证书server.certreq // server证书申请server.crt // server证书server.keystore //密钥库 Chrome导入根证书设置-&gt;高级-&gt;管理证书-&gt;受信任的根证书颁发机构-&gt;导入 springboot配置https在application.properties中增加以下配置：(跟上一步对应) 1234567server.ssl.key-store=server.keystoreserver.ssl.key-store-password=123456server.ssl.keyStoreType=JKSserver.ssl.keyAlias:server 开启http配置好https后发现http方式无法访问，服务器强制使用https方式，可以在 @Configuration注解的类中增加下面的配置同时开启http 1234567891011121314151617181920212223242526@Beanpublic EmbeddedServletContainerFactory servletContainer() &#123; TomcatEmbeddedServletContainerFactory tomcat = new TomcatEmbeddedServletContainerFactory() &#123; @Override protected void postProcessContext(Context context) &#123; SecurityConstraint securityConstraint = new SecurityConstraint(); securityConstraint.setUserConstraint("CONFIDENTIAL"); SecurityCollection collection = new SecurityCollection(); collection.addPattern("/*"); securityConstraint.addCollection(collection); context.addConstraint(securityConstraint); &#125; &#125;; tomcat.addAdditionalTomcatConnectors(initiateHttpConnector()); return tomcat;&#125;private Connector initiateHttpConnector() &#123; Connector connector = new Connector("org.apache.coyote.http11.Http11NioProtocol"); connector.setScheme("http"); connector.setPort(8080); connector.setSecure(false); connector.setRedirectPort(8443); return connector; &#125; http重定向到https1234567891011121314151617181920212223242526272829303132@Value("$&#123;server.port&#125;") private int port;@Beanpublic EmbeddedServletContainerFactory servletContainer() &#123; TomcatEmbeddedServletContainerFactory tomcat = new TomcatEmbeddedServletContainerFactory() &#123; @Override protected void postProcessContext(Context context) &#123; SecurityConstraint securityConstraint = new SecurityConstraint(); securityConstraint.setUserConstraint("CONFIDENTIAL"); SecurityCollection collection = new SecurityCollection(); collection.addPattern("/*"); securityConstraint.addCollection(collection); context.addConstraint(securityConstraint); &#125; &#125;; tomcat.addAdditionalTomcatConnectors(initiateHttpConnector()); return tomcat;&#125;private Connector initiateHttpConnector() &#123; Connector connector = new Connector("org.apache.coyote.http11.Http11NioProtocol"); connector.setScheme("http"); connector.setPort(getHttpPort()); connector.setSecure(false); connector.setRedirectPort(port); return connector;&#125; private int getHttpPort() &#123; return 80;&#125; https配置到此完成，美滋滋：]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>密码学</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux网络IO模型]]></title>
    <url>%2F2017%2F07%2F10%2FLinux%E7%BD%91%E7%BB%9CIO%E6%A8%A1%E5%9E%8B%2F</url>
    <content type="text"><![CDATA[学习Java-NIO在网络端的应用，就需要了解Linux的网络IO模型，才能够体会为什么需要NIO和NIO的好处在哪里。 什么是同步与异步、阻塞与非阻塞引用知乎 怎样理解阻塞非阻塞与同步异步的区别？ 上面的一个回答，很生动的说明了同步异步，阻塞非阻塞之间的区别联系： 老张爱喝茶，废话不说，煮开水。 出场人物：老张，水壶两把（普通水壶，简称水壶；会响的水壶，简称响水壶）。 1 老张把水壶放到火上，立等水开。（同步阻塞） 老张觉得自己有点傻 2 老张把水壶放到火上，去客厅看电视，时不时去厨房看看水开没有。（同步非阻塞） 老张还是觉得自己有点傻，于是变高端了，买了把会响笛的那种水壶。水开之后，能大声发出嘀~~~~的噪音。 3 老张把响水壶放到火上，立等水开。（异步阻塞） 老张觉得这样傻等意义不大 4 老张把响水壶放到火上，去客厅看电视，水壶响之前不再去看它了，响了再去拿壶。（异步非阻塞） 老张觉得自己聪明了。 所谓同步异步，只是对于水壶而言。普通水壶，同步；响水壶，异步。虽然都能干活，但响水壶可以在自己完工之后，提示老张水开了。这是普通水壶所不能及的。同步只能让调用者去轮询自己（情况2中），造成老张效率的低下。 所谓阻塞非阻塞，仅仅对于老张而言。立等的老张，阻塞；看电视的老张，非阻塞。情况1和情况3中老张就是阻塞的，媳妇喊他都不知道。虽然3中响水壶是异步的，可对于立等的老张没有太大的意义。所以一般异步是配合非阻塞使用的，这样才能发挥异步的效用。 看上面的例子，我们再来关注Linux网络IO模型，然后结合这个例子去理解。 Linux网络IO模型Unix提供了五种IO模式，分别是： 阻塞IO 非阻塞IO IO复用 信号驱动IO 异步IO 在之前的学习中我们也了解了从用户进程到底层硬件执行IO的过程，以read为例： 数据需要从硬件设备拷贝到内核空间的缓冲区，然后从内核缓冲区拷贝到用户进程空间。 我们把数据需要从硬件设备拷贝到内核空间的缓冲区这个过程类比为烧水，从内核缓冲区拷贝到用户进程空间这个过程类比为用烧好的水泡茶。 阻塞IO 阻塞IO是最常用的IO模型，我们在java中调用传统BIO(InputStream、OutpuytStream)的读写方法都是这种IO模型。 观察上图，在进程空间中调用recvfrom，其系统调用直到数据从硬件设备拷贝到内核缓冲区并且从内核拷贝到用户进程空间时才会返回，在此期间一直是阻塞的，进程在从调用recvfrom到他返回这段时间一直都是阻塞的，故称为阻塞IO。 阻塞IO对应了我们上面提到的同步阻塞。在这种IO模式下整个过程相当于使用不会响的普通水壶烧水，并且老张一直在旁边盯着，干不了其他事。水烧好后老张再去泡茶。整个过程是同步阻塞的。 在阻塞IO模式下，在同一个线程当中，我们对于多个连接，只能依次处理： 123456while true &#123; for i in stream[] &#123; //可能会阻塞很长时间 read until available &#125;&#125; 非阻塞IO 用户进程发起一个recvfrom调用的时候，如果内核缓冲区的数据还没有准备好(没有完全从硬件拷贝到内核)，那么他不会阻塞用户进程，而是立刻返回一个error。用户发起一个recvfrom操作之后，不需要等待，而是马上会得到一个结果，用户可以判断这个结果，如果是一个error，表示数据还没有准备好，于是可以再次发起recvfrom操作，一旦内核数据准备好了，就可以把数据拷贝到用户进程空间，然后返回。 这种IO模型称之为非阻塞IO，整个过程可以类比为：在这种IO模式下调用recvfrom相当于使用不会响的普通水壶烧水，老张时不时跑到厨房看看水烧开了没(这个过程是同步非阻塞的)，如果水烧开了，他就用烧开的水泡茶(相当于从内核copy数据到用户空间这一段，这个过程其实是同步阻塞的) 在非阻塞IO模式下，我们发现可以在一个线程中处理多个连接了： 1234567// 忙轮询while true &#123; for i in stream[]; &#123; // 如果数据没有准备好，就立即返回，处理下一个流 read until unavailable &#125;&#125; 我们只要不停的把所有流从头到尾问一遍，又从头开始。这样就可以处理多个流了，但这样的做法显然不好，因为如果所有的流都没有数据，那么只会白白浪费CPU。 为了避免CPU空转，可以引进了一个代理: select或poll(两者本质上相同) IO复用 Linux 提供了select/poll，进程将一个或多个fd传递给select或poll系统调用，并且阻塞在select或poll方法上。同时，kernel会侦测所有select负责的fd是否处于就绪状态，如果有任何一个fd就绪，select或poll就会返回，这个时候用户进程再调用recvfrom，将数据从内核缓冲区拷贝到用户进程空间。 这个图和blocking IO的图有些相似，但是还有一些区别。因为这里需要使用两个system call (select 和 recvfrom)，而blocking IO只调用了一个system call (recvfrom)。但是，用select的优势在于它可以同时处理多个connection。 12345678while true &#123; // 在select上阻塞 select(streams[]) // 无差别轮询 for i in streams[] &#123; read until unavailable &#125;&#125; 于是，如果没有I/O事件产生，我们的程序就会阻塞在select处。但是依然有个问题，我们从select那里仅仅知道了，有I/O事件发生了，但却并不知道是那几个流(可能有一个，多个，甚至全部)，我们只能无差别轮询所有流，找出能读出数据，或者写入数据的流，对他们进行操作。使用select，我们有O(n)的无差别轮询复杂度，同时处理的流越多，每一次无差别轮询时间就越长。 Linux还提供了一个epoll系统调用，不同于忙轮询和无差别轮询，epoll之会把哪个流发生了怎样的I/O事件通知我们。此时我们对这些流的操作都是有意义的(复杂度降低到了O(1))。 123456789// 事先调用epoll_ctl注册感兴趣的事件到epollfdwhile true &#123; // 返回触发注册事件的流 active_stream[] = epoll_wait(epollfd) // 无须遍历所有的流 for i in active_stream[] &#123; read or write till &#125;&#125; 信号驱动IO 首先开启套接口信号驱动IO功能，并通过系统调用sigaction执行一个信号处理函数，此系统调用立即返回。当数据准备就绪时，就为该进程生成一个sigio信号，通过信号回调通知进程。进程调用recvfrom读取数据，将数据从内核缓冲区拷贝到用户进程空间。 上面的过程可以类比为：老张使用会响的水壶烧水，然后就去客厅看电视了。水烧好后水壶响起来(这个过程是异步非阻塞的)，老张再来厨房用烧好的水泡茶(这个过程是同步阻塞的)。 异步IO 用户进程发起recvfrom操作之后，立刻就可以开始去做其它的事。而另一方面，从kernel的角度，当它收到一个asynchronous read之后，首先它会立刻返回，所以不会对用户进程产生任何block。然后，kernel会等待数据准备完成，然后将数据拷贝到用户内存，当这一切都完成之后，kernel会给用户进程发送一个signal，告诉它read操作完成了。 这种IO模式与信号驱动IO的区别在于：信号驱动IO由内核通知我们什么时候可以开始一个IO操作，异步IO则由内核告诉我们IO操作何时完成。 异步IO模式可以类比为：在这种IO模式下整个过程相当于使用会响的水壶烧水，并且，这个水壶更加智能，水烧好后可以自动泡茶，然后发出声响通知老张。老张把水放到火上就去客厅看电视了，水烧好并且茶叶泡好之后，水壶发出声响通知老张。 参考Linux IO模式及 select、poll、epoll详解 怎样理解阻塞非阻塞与同步异步的区别？ epoll 或者 kqueue 的原理是什么？ 《Netty权威指南》 电子工业出版社]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>linux</tag>
        <tag>NIO</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java-NIO-Channel]]></title>
    <url>%2F2017%2F07%2F08%2FJava-NIO-Channel%2F</url>
    <content type="text"><![CDATA[Java NIO 学习第三篇–Channel Channel通道(Channel)的作用有类似于流(Stream)，用于传输文件或者网络上的数据。 上图中，箭头就相当于通道。一个不是很准确的例子：把通道想象成铁轨，缓冲区则是列车，铁轨的起始与终点则可以是socket，文件系统和我们的程序。假如当我们在代码中要写入数据到一份文件的时候，我们先把列车(缓冲区)装满，然后把列车(缓冲区)放置到铁轨上(通道)，数据就被传递到通道的另一端，文件系统。读取文件则相反，文件的内容被装到列车上，传递到程序这一侧，然后我们在代码中就可以读取这个列车中的内容(读取缓冲区)。 通道与传统的流还是有一些区别的： 通道可以同时支持读写(不是一定支持)，而流只支持单方向的操作，比如输入流只能读，输出流只能写。 通道可以支持异步的读或写，而流是同步的。 通道的读取或写入是通过缓冲区来进行的，而流则写入或返回字节。 FileChannel通道大致上可以分为两类：文件通道和socket通道。看一下文件通道： 文件通道可以由以下几个方法获得： 12345678910RandomAccessFile file = new RandomAccessFile(new File(fileName), "rw");FileChannel channel = file.getChannel();FileInputStream stream = new FileInputStream(new File(fileName));FileChannel channel = stream.getChannel();FileOutputStream stream = new FileOutputStream(new File(fileName));FileChannel channel = stream.getChannel();FileChannel channel = FileChannel.open(Paths.get(fileName)); FileChannel 类结构： 可见FileChannel实现了读写接口、聚集、发散接口，以及文件锁功能。下面会提到。 看一下FileChannel的基本方法： 123456789101112public abstract class FileChannel extends AbstractChannel implements ByteChannel, GatheringByteChannel, ScatteringByteChannel &#123; // 这里仅列出部分API public abstract long position() public abstract void position (long newPosition) public abstract int read (ByteBuffer dst) public abstract int read (ByteBuffer dst, long position) public abstract int write (ByteBuffer src) public abstract int write (ByteBuffer src, long position) public abstract long size() public abstract void truncate (long size) public abstract void force (boolean metaData)&#125; 在通道出现之前，底层的文件操作都是通过RandomAccessFile类的方法来实现的。FileChannel模拟同样的 I/O 服务，因此它们的API自然也是很相似的。 上图是FileChannel、RandomAccessFile 和 POSIX I/O system calls 三者在方法上的对应关系。 POSIX接口我们在上一篇文章中也略有提及，他是一个系统级别的接口。下面看一下这几个接口，主要也是和上一篇文章文件描述符的介绍做一个呼应。 position()和position(long newPosition) position()返回当前文件的position值，position(long newPosition)将当前position设置为指定值。当字节被read()或write()方法传输时，文件position会自动更新。 position的含义与Buffer类中的position含义相似，都是指向下一个字节读取的位置。 回想一下介绍文件描述符的文章当中提到，当进程打开一个文件时，内核就会创建一个新的file对象，这个file对象有一个字段loff_t f_pos描述了文件的当前位置，position相当于loff_t f_pos的映射。由此可知，如果是使用同一文件描述符读取文件，那么他们的position是相互影响的： 12345RandomAccessFile file = new RandomAccessFile(new File(fileName), "rw");FileChannel channel = file.getChannel();System.out.println("position: " + channel.position());file.seek(30);System.out.println("position: " + channel.position()); 打印如下： 12position: 0position: 30 这是因为，file与channel使用了同一个文件描述符。如果新建另一个相同文件的通道，那么他们之间的position不会相互影响，因为使用了不同的文件描述符，指向不同的file对象。 truncate(long size) 当需要减少一个文件的size时，truncate()方法会砍掉指定的size值之外的所有数据。这个方法要求通道具有写权限。 如果当前size大于给定size，超出给定size的所有字节都会被删除。如果提供的新size值大于或等于当前的文件size值，该文件不会被修改。 12345678RandomAccessFile file = new RandomAccessFile(new File(fileName), "rw");FileChannel channel = file.getChannel();System.out.println("size: " + channel.size());System.out.println("position: " + channel.position());System.out.println("trucate: 90");channel.truncate(90);System.out.println("size: " + channel.size());System.out.println("position: " + channel.position()); 打印如下： 12345size: 100position: 0trucate: 90size: 90position: 0 force(boolean metaData) force()方法告诉通道强制将全部待定的修改都应用到磁盘的文件上。 如果文件位于一个本地文件系统，那么一旦force()方法返回，即可保证从通道被创建(或上次调用force())时起的对文件所做的全部修改已经被写入到磁盘。但是，如果文件位于一个远程的文件系统，如NFS上，那么不能保证待定修改一定能同步到永久存储器。 force()方法的布尔型参数表示在方法返回值前文件的元数据(metadata)是否也要被同步更新到磁盘。元数据指文件所有者、访问权限、最后一次修改时间等信息。 FileChannel对象是线程安全的。如果有一个线程已经在执行会影响通道位置或文件大小的操作，那么其他尝试进行此类操作之一的线程必须等待。 ReadableByteChannel、WritableByteChannel通道可以是单向或者双向的。 12345678910public interface ReadableByteChannel extends Channel&#123; public int read (ByteBuffer dst) throws IOException;&#125;public interface WritableByteChannel extends Channel&#123; public int write (ByteBuffer src) throws IOException;&#125;public interface ByteChannel extends ReadableByteChannel, WritableByteChannel&#123;&#125; 实现ReadableByteChannel或WritableByteChannel其中之一的channel是单向的，只可以读或者写。如果一个类同时实现了这两种接口，那么他就具备了双向传输的能力。 java为我们提供了一个接口ByteChannel，同时继承了上述两个接口。所以，实现了ByteChannel接口的类可以读，也可以写。 在FlieChannel这一节中我们知道，文件在不同的方式下以不同的权限打开。比如FileInputStream.getChannel()方法返回一个FileChannel实例，FileChannel是个抽象类，间接的实现了ByteChannel接口，也就意味着提供了read和write接口。但是FileInputStream.getChannel()方法返回的FileChannel实际上是只读的，很简单，因为FileInputStream本身就是个输入流啊~在这样一个通道上调用write方法将抛出NonWritableChannelException异常，因为FileInputStream对象总是以read-only的权限打开通道。看一下代码： FileInputStream.getChannel() 12345678910111213141516public FileChannel getChannel() &#123; synchronized (this) &#123; if (channel == null) &#123; // 第三个参数指定通道是否可读，第四个参数指定通道是否可写 channel = FileChannelImpl.open(fd, path, true, false, this); /* * Increment fd's use count. Invoking the channel's close() * method will result in decrementing the use count set for * the channel. */ fd.incrementAndGetUseCount(); &#125; return channel; &#125;&#125; 同样的，FileOutputStream.getChannel()返回的通道是不可读的。 InterruptibleChannelInterruptibleChannel是一个标记接口，当被通道使用时可以标示该通道是可以中断的。 如果一个线程在一个通道上处于阻塞状态时被中断(另外一个线程调用该线程的interrupt()方法设置中断状态)，那么该通道将被关闭，该被阻塞线程也会产生一个ClosedByInterruptException异常。也就是说，假如一个线程的interrupt status被设置并且该线程试图访问一个通道，那么这个通道将立即被关闭，同时将抛出相同的ClosedByInterruptException异常。 在java任务取消中提到了，传统的java io 在读写时阻塞，是不会响应中断的。解决办法就是使用InterruptibleChannel，在线程被中断时可以关闭通道并返回。 可中断的通道也是可以异步关闭。实现InterruptibleChannel接口的通道可以在任何时候被关闭，即使有另一个被阻塞的线程在等待该通道上的一个I/O操作完成。当一个通道被关闭时，休眠在该通道上的所有线程都将被唤醒并接收到一个AsynchronousCloseException异常。接着通道就被关闭并将不再可用。 Scatter/Gather发散(Scatter)读取是将数据读入多个缓冲区(缓冲区数组)的操作。通道将数据依次填满到每个缓冲区当中。 汇聚(Gather)写出是将多个缓冲区(缓冲区数组)数据依次写入到通道的操作。 在FileChannel中提到的两个接口，提供了发散汇聚的功能： 12345678public interface ScatteringByteChannel extends ReadableByteChannel&#123; public long read (ByteBuffer[] dsts) throws IOException; public long read (ByteBuffer[] dsts, int offset, int length) throws IOException;&#125;public interface GatheringByteChannel extends WritableByteChannel&#123; public long write(ByteBuffer[] srcs) throws IOException; public long write(ByteBuffer[] srcs, int offset, int length) throws IOException;&#125; 发散汇聚在某些场景下是很有用的，比如有一个消息协议格式分为head和body(比如http协议)，我们在接收这样一个消息的时候，通常的做法是把数据一下子都读过来，然后解析他。使用通道的发散功能会使这个过程变得简单： 12345678// head数据128字节ByteBuffer header = ByteBuffer.allocate(128);// body数据1024字节ByteBuffer body = ByteBuffer.allocate(1024);ByteBuffer[] bufferArray = &#123; header, body &#125;;channel.read(bufferArray); 通道会依次填满这个buffer数组的每个buffer，如果一个buffer满了，就移动到下一个buffer。很自然的把head和body的数据分开了，但是要注意head和body的数据长度必须是固定的，因为channel只有填满一个buffer之后才会移动到下一个buffer。 FileLock摘抄一段oracle官网上FileLock的介绍吧，感觉说的挺清楚了。(因为懒，就不翻译了，读起来不是很费劲) A token representing a lock on a region of a file.A file-lock object is created each time a lock is acquired on a file via one of the lock or tryLock methods of the FileChannel class, or the lock or tryLock methods of the AsynchronousFileChannel class. A file-lock object is initially valid. It remains valid until the lock is released by invoking the release method, by closing the channel that was used to acquire it, or by the termination of the Java virtual machine, whichever comes first. The validity of a lock may be tested by invoking its &gt;isValid method. A file lock is either exclusive or shared. A shared lock prevents other concurrently-running programs from acquiring an overlapping exclusive lock, but does allow them to acquire overlapping shared locks. An exclusive lock prevents other programs from acquiring an overlapping lock of either type. &gt;Once it is released, a lock has no further effect on the locks that may be acquired by other programs. Whether a lock is exclusive or shared may be determined by invoking its isShared method. Some platforms do not support shared locks, in which case a request for a shared lock is automatically converted into a request for an exclusive lock. The locks held on a particular file by a single Java virtual machine do not overlap. The overlaps method may be used to test whether a candidate lock range overlaps an existing lock. A file-lock object records the file channel upon whose file the lock is held, the type and validity of the lock, and the position and size of the locked region. Only the validity of a lock is subject to change over time; all other aspects of a lock’s state are immutable. File locks are held on behalf of the entire Java virtual machine. They are not suitable for controlling access to a file by multiple threads within the same virtual machine. File-lock objects are safe for use by multiple concurrent threads. Platform dependencies This file-locking API is intended to map directly to the native locking facility of the underlying operating system. Thus the locks held on a file should be visible to all programs that have access to the file, regardless of the language in which those programs are written. Whether or not a lock actually prevents another program from accessing the content of the locked region is system-dependent and therefore unspecified. The native file-locking facilities of some systems are merely advisory, meaning that programs must cooperatively observe a known locking protocol in &gt;order to guarantee data integrity. On other systems native file locks are mandatory, meaning that if one program locks a region of a file then other programs are actually prevented from accessing that region in a way that would violate the lock. On yet other systems, whether native file locks are &gt;advisory or mandatory is configurable on a per-file basis. To ensure consistent and correct behavior across platforms, it is strongly recommended that the locks provided by this API be used as if they were advisory locks. On some systems, acquiring a mandatory lock on a region of a file prevents that region from being mapped into memory, and vice versa. Programs that combine locking and mapping should be prepared for this combination to fail. On some systems, closing a channel releases all locks held by the Java virtual machine on the underlying file regardless of whether the locks were acquired via that channel or via another channel open on the same file. It is strongly recommended that, within a program, a unique channel be used to &gt;acquire all locks on any given file. Some network filesystems permit file locking to be used with memory-mapped files only when the locked regions are page-aligned and a whole multiple of the underlying hardware’s page size. Some network filesystems do not implement file locks on regions that extend past a certain position, often 230 &gt;or 231. In general, great care should be taken when locking files that reside on network filesystems. FileLock可以由以下几个方法获得： 1234567public abstract class FileChannel extends AbstractChannel implements ByteChannel, GatheringByteChannel, ScatteringByteChannel &#123;// 这里仅列出部分API public final FileLock lock() public abstract FileLock lock (long position, long size, boolean shared) public final FileLock tryLock() public abstract FileLock tryLock (long position, long size, boolean shared)&#125; 其中，lock是阻塞的，tryLock是非阻塞的。position和size决定了锁定的区域，shared决定了文件锁是共享的还是独占的。 不带参数的lock方法等价于fileChannel.lock(0L, Long.MAX_VALUE, false)，tryLock亦然。 lock方法是响应中断的，当线程被中断时方法抛出FileLockInterruptionException异常。如果通道被另外一个线程关闭，该暂停线程将恢复并产生一个 AsynchronousCloseException异常。 上面还提到了，文件锁是针对于进程级别的。如果有多个进程同时对一个文件锁定，并且其中有独占锁的话，这些锁的申请会被串行化。 如果是同一个进程(Jvm实例)的多个线程同时请求同一个文件区域的lock的话，会抛出OverlappingFileLockException异常。 Channel-to-ChannelFileChannel提供了接口，用于通道和通道之间的直接传输。 12345public abstract class FileChannel extends AbstractChannel implements ByteChannel, GatheringByteChannel, ScatteringByteChannel &#123; // 这里仅列出部分API public abstract long transferTo (long position, long count, WritableByteChannel target) public abstract long transferFrom (ReadableByteChannel src, long position, long count)&#125; 只有FileChannel类有这两个方法，因此Channel-to-Channel传输中通道之一必须是FileChannel。不能在socket通道之间直接传输数据，不过socket通道实现WritableByteChannel和ReadableByteChannel接口，因此文件的内容可以用transferTo()方法传输给一个socket通道，或者也可以用transferFrom()方法将数据从一个socket通道直接读取到一个文件中。 直接的通道传输不会更新与某个FileChannel关联的position值。请求的数据传输将从position参数指定的位置开始，传输的字节数不超过count参数的值。实际传输的字节数会由方法返回。 直接通道传输的另一端如果是socket通道并且处于非阻塞模式的话，数据的传输将具有不确定性。比如，transferFrom从socket通道读取数据，如果socket中的数据尚未准备好，那么方法将直接返回。 例子： 12345678910111213141516171819202122RandomAccessFile fromFile = new RandomAccessFile("fromFile.txt", "rw");FileChannel fromChannel = fromFile.getChannel();RandomAccessFile toFile = new RandomAccessFile("toFile.txt", "rw");FileChannel toChannel = toFile.getChannel();long position = 0;long count = fromChannel.size();toChannel.transferFrom(fromChannel, position, count);RandomAccessFile fromFile = new RandomAccessFile("fromFile.txt", "rw");FileChannel fromChannel = fromFile.getChannel();RandomAccessFile toFile = new RandomAccessFile("toFile.txt", "rw");FileChannel toChannel = toFile.getChannel();long position = 0;long count = fromChannel.size();fromChannel.transferTo(position, count, toChannel); 参考Java nio入门教程详解]]></content>
      <categories>
        <category>编程</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>NIO</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[java文件描述符]]></title>
    <url>%2F2017%2F07%2F07%2Fjava%E6%96%87%E4%BB%B6%E6%8F%8F%E8%BF%B0%E7%AC%A6%2F</url>
    <content type="text"><![CDATA[文件描述符在Linux中，进程是通过文件描述符（file descriptors，简称fd）而不是文件名来访问文件的，文件描述符实际上是一个整数。 内核中，对应于每个进程都有一个文件描述符表，表示这个进程打开的所有文件。文件描述符就是这个表的索引。 文件描述表中每一项都是一个指针，指向一个用于描述打开的文件的数据块———file对象，file对象中描述了文件的打开模式，读写位置等重要信息。 当进程打开一个文件时，内核就会创建一个新的file对象。因此，我们在进程中使用多线程打开同一个文件，每个线程会有各自的文件描述符，每个线程也会有保存自己的读取位置，互不影响。 需要注意的是，file对象不是专属于某个进程的，不同进程的文件描述符表中的指针可以指向相同的file对象，从而共享这个打开的文件。比如，如果在调用fork之前父进程已经打开文件，则fork后子进程有一个父进程描述符表的副本。父子进程共享相同的打开文件集合，因此共享相同的文件位置。 file对象有引用计数，记录了引用这个对象的文件描述符个数，只有当引用计数为0时，内核才销毁file对象，因此某个进程关闭文件，不影响与之共享同一个file对象的进程。 每个file结构体都指向一个file_operations结构体，这个结构体的成员都是函数指针，指向实现各种文件操作的内核函数。比如在用户程序中read一个文件描述符，read通过系统调用进入内核，然后找到这个文件描述符所指向的file结构体，找到file结构体所指向的file_operations结构体，调用它的read成员所指向的内核函数以完成用户请求。在用户程序中调用lseek、read、write、ioctl、open等函数，最终都由内核调用file_operations的各成员所指向的内核函数完成用户请求。file_operations结构体中的release成员用于完成用户程序的close请求，之所以叫release而不叫close是因为它不一定真的关闭文件，而是减少引用计数，只有引用计数减到0才关闭文件。 file对象中包含一个指针，指向dentry对象。“dentry”是directory entry（目录项）的缩写，dentry对象代表一个独立的文件路径，如果一个文件路径被打开多次，那么会建立多个file对象，但它们都指向同一个dentry对象。为了减少读盘次数，内核缓存了目录的树状结构，称为dentry cache，其中每个节点是一个dentry结构体。 每个dentry结构体都有一个指针指向inode结构体。inode结构体保存着从磁盘inode读上来的信息。在上图的例子中，有两个dentry，分别表示/home/akaedu/a和/home/akaedu/b，它们都指向同一个inode，说明这两个文件互为硬链接。inode结构体中保存着从磁盘分区的inode读上来信息，例如所有者、文件大小、文件类型和权限位等。 每个进程刚刚启动的时候，文件描述符0是标准输入，1是标准输出，2是标准错误。如果此时去打开一个新的文件，它的文件描述符会是3。 java中的FileDescriptor在java中，有着与文件描述符对应的一个类对象：FileDescriptor。我们看一下FileDescriptor与Channel的关系： FileInputStream.getChannel(): 123456789101112131415public FileChannel getChannel() &#123; synchronized (this) &#123; if (channel == null) &#123; channel = FileChannelImpl.open(fd, path, true, false, this); /* * Increment fd's use count. Invoking the channel's close() * method will result in decrementing the use count set for * the channel. */ fd.incrementAndGetUseCount(); &#125; return channel; &#125;&#125; 其中的FileChannelImpl.open(fd, path, true, false, this)参数fd就是FileDescriptor实例。 看一下他是怎么产生的： 123456789101112131415161718192021public FileInputStream(File file) throws FileNotFoundException &#123; String name = (file != null ? file.getPath() : null); SecurityManager security = System.getSecurityManager(); if (security != null) &#123; security.checkRead(name); &#125; if (name == null) &#123; throw new NullPointerException(); &#125; if (file.isInvalid()) &#123; throw new FileNotFoundException("Invalid file path"); &#125; fd = new FileDescriptor(); fd.incrementAndGetUseCount(); this.path = name; open(name);&#125;static &#123; initIDs();&#125; 注意到initIDs()这个静态方法： 123456jfieldID fis_fd; /* id for jobject 'fd' in java.io.FileInputStream */JNIEXPORT void JNICALLJava_java_io_FileInputStream_initIDs(JNIEnv *env, jclass fdClass) &#123; fis_fd = (*env)-&gt;GetFieldID(env, fdClass, "fd", "Ljava/io/FileDescriptor;");&#125; 在FileInputStream类加载阶段，fis_fd就被初始化了，fid_fd相当于是FileInputStream.fd字段的一个内存偏移量，便于在必要时操作内存给它赋值。 看一下FileDescriptor的实例化过程： 123456789public /**/ FileDescriptor() &#123; fd = -1; handle = -1; useCount = new AtomicInteger();&#125;static &#123; initIDs();&#125; FileDescriptor也有一个initIDs，他和FileInputStream.initIDs的方法类似，把设置IO_fd_fdID为FileDescriptor.fd字段的内存偏移量。 123456789/* field id for jint 'fd' in java.io.FileDescriptor */jfieldID IO_fd_fdID;/************************************************************** * static methods to store field ID's in initializers */JNIEXPORT void JNICALLJava_java_io_FileDescriptor_initIDs(JNIEnv *env, jclass fdClass) &#123; IO_fd_fdID = (*env)-&gt;GetFieldID(env, fdClass, "fd", "I");&#125; 接下来再看FileInputStream构造函数中的open(name)方法，字面上看，这个方法打开了一个文件，他也是一个本地方法，open方法直接调用了fileOpen方法，fileOpen方法如下: 12345678910111213141516171819void fileOpen(JNIEnv *env, jobject this, jstring path, jfieldID fid, int flags)&#123; WITH_PLATFORM_STRING(env, path, ps) &#123; FD fd;#if defined(__linux__) || defined(_ALLBSD_SOURCE) /* Remove trailing slashes, since the kernel won't */ char *p = (char *)ps + strlen(ps) - 1; while ((p &gt; ps) &amp;&amp; (*p == '/')) *p-- = '\0';#endif // 打开一个文件并获取到文件描述符 fd = handleOpen(ps, flags, 0666); if (fd != -1) &#123; SET_FD(this, fd, fid); &#125; else &#123; throwFileNotFoundException(env, path); &#125; &#125; END_PLATFORM_STRING(env, ps);&#125; 其中的handleOpen函数打开了一个文件描述符，相当于和文件建立了联系，并且将返回的文件描述符描述符赋值给了局部变量fd,然后调用了SET_FD宏: 123#define SET_FD(this, fd, fid) \ if ((*env)-&gt;GetObjectField(env, (this), (fid)) != NULL) \ (*env)-&gt;SetIntField(env, (*env)-&gt;GetObjectField(env, (this), (fid)),IO_fd_fdID, (fd)) 注意到IO_fd_fdID，他是FileDescriptor.fd字段的内存偏移量。这个方法相当于设置FileDescriptor.fd的值等于文件描述符fd。 需要注意的是，FileDescriptor有两个字段：handle和fd，上面的代码表示我们只设置了fd字段为文件描述符，没有提到handle字段，这是因为： 在 win32 的实现中将 创建好的 文件句柄 设置到 handle 字段，在 linux 版本中则使用的是 FileDescriptor 的 fd 字段。 由此，可知 handle 和 fd 是共存的但并不同时在使用，在 win32 平台上使用 handle 字段，在 linux 平台上使用 fd 字段。 所以，FileInputStream打开文件的过程总结如下： 创建 FileDescriptor 对象 每一个 FileInputStream 有一个 FileDescriptor，代表这个流底层的文件的fd 调用 native 方法 open, 打开文件 内部调用 handleOpen 打开文件，返回文件描述符 fd 初始化 FileDescriptor 对象 将 文件描述符 fd 设置到，FileDescriptor 对象的 fd 中 再谈java文件读取在java-NIO-Buffer这篇文章中我们提到了FileInputStream.read方法，再来回顾一下： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859JNIEXPORT jint JNICALL Java_java_io_FileInputStream_readBytes(JNIEnv *env, jobject this, jbyteArray bytes, jint off, jint len) &#123;//除了前两个参数，后三个就是readBytes方法传递进来的，字节数组、起始位置、长度三个参数 return readBytes(env, this, bytes, off, len, fis_fd); &#125;jintreadBytes(JNIEnv *env, jobject this, jbyteArray bytes, jint off, jint len, jfieldID fid)&#123; jint nread; char stackBuf[BUF_SIZE]; char *buf = NULL; FD fd; if (IS_NULL(bytes)) &#123; JNU_ThrowNullPointerException(env, NULL); return -1; &#125; if (outOfBounds(env, off, len, bytes)) &#123; JNU_ThrowByName(env, "java/lang/IndexOutOfBoundsException", NULL); return -1; &#125; if (len == 0) &#123; return 0; &#125; else if (len &gt; BUF_SIZE) &#123; buf = malloc(len);// buf的分配 if (buf == NULL) &#123; JNU_ThrowOutOfMemoryError(env, NULL); return 0; &#125; &#125; else &#123; buf = stackBuf; &#125; fd = GET_FD(this, fid); if (fd == -1) &#123; JNU_ThrowIOException(env, "Stream Closed"); nread = -1; &#125; else &#123; nread = IO_Read(fd, buf, len);// buf是使用malloc分配的直接缓冲区，也就是堆外内存 if (nread &gt; 0) &#123; (*env)-&gt;SetByteArrayRegion(env, bytes, off, nread, (jbyte *)buf);// 将直接缓冲区的内容copy到bytes数组中 &#125; else if (nread == JVM_IO_ERR) &#123; JNU_ThrowIOExceptionWithLastError(env, "Read error"); &#125; else if (nread == JVM_IO_INTR) &#123; JNU_ThrowByName(env, "java/io/InterruptedIOException", NULL); &#125; else &#123; /* EOF */ nread = -1; &#125; &#125; if (buf != stackBuf) &#123; free(buf); &#125; return nread;&#125; 上述代码中的fis_fd是不是很眼熟？他就是FileInputStream.fd字段的内存偏移量。注意到fd = GET_FD(this, fid);这个方法，获取到其对应的文件描述符，然后使用该文件描述符读取文件内容，填充缓冲区。由此可见，java底层读取文件都是通过文件描述符来进行的。比如： 文章开始提到每个进程刚刚启动的时候，文件描述符0是标准输入，1是标准输出，2是标准错误。如果此时去打开一个新的文件，它的文件描述符会是3，FileDescriptor中的fd为0，1，2时也表示同样的意义。 12FileOutputStream fileOutputStream = new FileOutputStream(FileDescriptor.out);fileOutputStream.write('hello world');// 控制台打印 hello world，因为fileOutputStream使用了标准输出的文件描述符 参考linux 文件描述符表 打开文件表 inode vnode linux中文件描述符fd和文件指针flip的理解 JNI探秘–FileDescriptor、FileInputStream 解惑]]></content>
      <categories>
        <category>编程</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>NIO</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java-NIO-MappedByteBuffer]]></title>
    <url>%2F2017%2F07%2F04%2FJava-NIO-MappedByteBuffer%2F</url>
    <content type="text"><![CDATA[java nio 学习第二篇–内存映射文件 内核空间与用户空间Kernel space 是 Linux 内核的运行空间，User space 是用户程序的运行空间。为了安全，它们是隔离的，即使用户的程序崩溃了，内核也不受影响。 内核空间中存放的是内核代码和数据。内核空间是操作系统所在区域。内核代码有特别的权力：它能与设备控制器通讯，控制着用户区域进程的运行状态，等等。最重要的是，所有 I/O 都直接或间接通过内核空间。 用户空间是常规进程所在区域，进程的用户空间中存放的是用户程序的代码和数据。 Linux使用两级保护机制：0级供内核使用，3级供用户程序使用。 当一个任务（进程）执行系统调用而陷入内核代码中执行时，我们就称进程处于内核运行态（内核态）。此时处理器处于特权级最高的（0级）内核代码中执行，CPU可执行任何指令。当进程在执行用户自己的代码时，则称其处于用户运行态（用户态）。 32位Linux的虚拟地址空间为0～4G。Linux内核将这4G字节的空间分为两部分。将最高的1G字节（从虚拟地址0xC0000000到0xFFFFFFFF），供内核使用，称为“内核空间”。而将较低的3G字节（从虚拟地址 0x00000000到0xBFFFFFFF），供各个进程使用，称为“用户空间）。每个进程有各自的私有用户空间（0～3G），这个空间对系统中的其他进程是不可见的。最高的1GB字节虚拟内核空间则为所有进程以及内核所共享。 12345str = "my string" // 用户空间x = x + 2file.write(str) // 切换到内核空间 y = x + 4 // 切换回用户空间 上面代码中，第一行和第二行都是简单的赋值运算，在 User space 执行。第三行需要写入文件，就要切换到 Kernel space，因为用户不能直接写文件，必须通过内核安排。第四行又是赋值运算，就切换回 User space。 分页存储操作系统在运行程序时，需要为每一个进程分配内存。比如A进程需要200m，B进程需要300m，c进程需要100m。那么操作系统应该如何为他们分配这些内存呢？ 一种想法是直接分配连续的内存。操作系统维护一个内存列表，每次申请内存时就去这个列表中寻找合适的连续内存块，分配给用户进程。这样会带来一个问题，那就是内存碎片化。由于程序申请内存的大小是不规律的，在经过多次分配之后，内存空间就会变得零碎，产生很多不连续的小的内存碎片，这些碎片无法被程序使用(因为碎片化的内存不是连续的，也不够大)。 可以通过‘紧凑’的方法将这些碎片拼接成可用的大块内存空间，但是必须要付出很大的开销。因此产生了离散化的分配方式：允许直接将一个紧凑直接分散的装入到许多不相邻的内存块当中。就可以充分的利用内存空间。 离散分配其中之一的分配方式就是分页：将用户程序的地址空间分为若干个固定大小的区域，称为页。比如，每个页为1kb。相应的将内存空间也分为若干个物理块，和页的大小相同。这样就可以将用户程序的任一页放入任一物理块当中，实现了离散分配。 在分页系统中，允许将进程的各个页离散的存储在内存的任一物理块当中，为了保证进程能够正确运行，即能够在内存中找到每个页面所对应的物理块，系统为每一个进程建立了一张页面映像表，简称页表。在进程地址空间内的所有页，依次在页表中有一页表项，其中记录了相应页在内存中的物理块号。 在配置了页表之后，进程执行时，通过查找该表，即可找到每页在内存中的物理块号。可见，页表的作用是实现从页号到物理块号的地址映射。 虚拟内存所有现代操作系统都使用虚拟内存。虚拟内存意为使用虚假(或虚拟)地址取代物理(硬件RAM)内存地址。这样做好处颇多，总结起来可分为两大类： 一个以上的虚拟地址可指向同一个物理内存地址。 虚拟内存空间可大于实际可用的硬件内存。 那么，这是如何做到的呢？ 我们会同时运行多个进程，而每个进程占用的内存大小不固定，但是这些进程所需要的内存大小加起来却会超过我们实际的物理内存(比如4g内存)，用户感觉到的内存容量会比实际内存容量大的多。这是因为： 应用程序在运行之前没有必要将之全部装入内存，而仅需将那些当前要运行的少数页面装入内存便可运行，其余部分暂留在磁盘上。程序在运行时，如果他要访问的页已经调入内存，便可继续执行下去；但如果程序所要访问的页面尚未调入内存(缺页)，便发出缺页请求(页错误)，此时操作系统将利用请求调页功能将他们调入内存，以便程序能够继续执行下去。如果此时内存已满，无法再装入新的页，操作系统还需再利用页的置换功能，将内存中暂时不用的页调到磁盘上，腾出足够的内存空间后，再将要访问的页调入内存，使程序继续执行下去。这样，可以使一个或多个大的用户程序在较小的内存空间中运行。 联想一下Linux系统在硬盘分区时需要让我们选择一个swap分区，结合上面的知识，可知这个swap分区就是上面置换时提到的磁盘。摘抄一段百度百科对swap的定义： Swap分区在系统的物理内存不够用的时候，把硬盘空间中的一部分空间释放出来，以供当前运行的程序使用。那些被释放的空间可能来自一些很长时间没有什么操作的程序，这些被释放的空间被临时保存到Swap分区中，等到那些程序要运行时，再从Swap分区中恢复保存的数据到内存中。 因此，虚拟内存的实现利用了上面提到的分页存储的方法，同时，需要存储系统需要增加页面置换和页面调度功能。 我们知道页表的基本作用就是将用户地址空间中的逻辑地址映射为内存空间中的物理地址，为了满足页面的换进换出功能，在页表中增加几个字段： 对上面字段的解释： 状态位P: 由于在请求分页系统中，只将应用程序的一部分调入内存，还有一部分在磁盘上，所以需要在页表中增加一个存在位字段，指示该夜是否已调入内存，供应用程序参考。 访问字段A：用于记录本页在一段时间内的访问次数，或已有多长时间未被访问，提供给置换算法在选择换出页面时参考。 修改位M：标识该页在调入内存后是否被修改过。由于内存中的每一页都在外存上保留一个副本，因此，在置换该页时，若未被修改，就不需要将该页再写回到外存，减少磁盘交互的次数；若已被修改，则必须将该页重写到外存上，保证外存中所保留的副本是最新的。 外存地址：指出该页在外存上的地址，通常是物理块号，供调入该页时参考。 回想一下，在前面 **内核空间与用户空间 这一节当中，提到了 Linux的虚拟地址空间为0～4G，从0x00000000到0xFFFFFFFF。这里的虚拟地址，经过MMU的转换，可以映射为物理页号。每一个进程都维护自己的虚拟地址，从虚拟地址中分配内存，实际上底层将这些虚拟地址，通过查询页表映射到物理块号，然后进行相应的置换或者读入。实际上，是所有的进程共享这些物理内存，此时的物理内存相当于一个池(联想 线程池？)。 IO原理有了上面的基础，我们再来看一下操作系统中的IO： 进程使用read()系统调用，要求其缓冲区被填满。内核随即向磁盘控制硬件发出命令，要求其从磁盘读取数据。磁盘控制器把数据直接写入内核内存缓冲区，这一步通过 DMA 完成，无需主CPU协助。一旦磁盘控制器把缓冲区装满，内核即把数据从内核空间的临时缓冲区拷贝到进程执行read()调用时指定的缓冲区。 我们可能会觉得，把数据从内核空间拷贝到用户空间似乎有些多余。为什么不直接让磁盘控制器把数据送到用户空间的缓冲区呢？这样做有几个问题。首先，硬件通常不能直接访问用户空间。其次，像磁盘这样基于块存储的硬件设备操作的是固定大小的数据块，而用户进程请求的可能是任意大小的或非对齐的数据块。在数据往来于用户空间与存储设备的过程中，内核负责数据的分解、再组合工作，因此充当着中间人的角色。 采用分页技术的操作系统执行 I/O 的全过程可总结为以下几步： 确定请求的数据分布在文件系统的哪些页(磁盘扇区组)。磁盘上的文件内容和元数据可能跨越多个文件系统页，而且这些页可能也不连续。 在内核空间分配足够数量的内存页，以容纳得到确定的文件系统页。 在内存页与磁盘上的文件系统页之间建立映射。 为每一个内存页产生页错误。 虚拟内存系统俘获页错误，安排页面调入，从磁盘上读取页内容，使页有效。 一旦页面调入操作完成，文件系统即对原始数据进行解析，取得所需文件内容或属性信息。 内存映射文件传统的文件 I/O 是通过用户进程发布read()和write()系统调用来传输数据的。比如FileInputStream.read(byte b[])，实际上是调用了read()系统调用完成数据的读取。回想上一篇文章，FileInputStream.read(byte b[])会造成几次数据拷贝呢？ 从磁盘到内核缓冲区的拷贝 内核缓冲区到JVM进程直接缓冲区的拷贝 JVM直接缓冲区到FileInputStream.read(byte b[])中byte数组b指向的堆内存的拷贝 可见，传统的IO要经历至少三次数据拷贝才可以把数据读出来，即使是使用直接缓冲区DirectBuffer，也需要至少两次拷贝过程。 我们知道，设备控制器不能通过 DMA 直接存储到用户空间，但是利用虚拟内存一个以上的虚拟地址可指向同一个物理内存地址这个特点，则可以把内核空间地址与用户空间的虚拟地址映射到同一个物理地址，这样，DMA 硬件(只能访问物理内存地址)就可以填充对内核与用户空间进程同时可见的缓冲区。 这样的话，就省去了内核与用户空间的往来拷贝，但前提条件是，内核与用户缓冲区必须使用相同的页对齐，缓冲区的大小还必须是磁盘控制器块大小的倍数。 内存映射 I/O 使用文件系统建立从用户空间直到可用文件系统页的虚拟内存映射。这样做有几个好处： 用户进程把文件数据当作内存，所以无需发布read()或write()系统调用。 当用户进程碰触到映射内存空间，页错误会自动产生，从而将文件数据从磁盘读进内存。如果用户修改了映射内存空间，相关页会自动标记为脏，随后刷新到磁盘，文件得到更新。 操作系统的虚拟内存子系统会对页进行智能高速缓存，自动根据系统负载进行内存管理。 数据总是按页对齐的，无需执行缓冲区拷贝。 大型文件使用映射，无需耗费大量内存，即可进行数据拷贝。 MappedByteBuffer了解了上面的内容，我们知道在操作系统和硬件层面实际上是为我们提供了内存映射文件这样的机制的。在java1.4之后，java也提供了对应的接口，可以让我们利用操作系统这一特性，提高文件读写性能，那就是MappedByteBuffer。 MappedByteBuffer继承自ByteBuffer，MappedByteBuffer被abstract修饰，所以他不能被实例化。我们可以调用FileChannel.map()方法获取一个MappedByteBuffer： 123FileInputStream inputStream = new FileInputStream(file);FileChannel channel = inputStream.getChannel();MappedByteBuffer map = channel.map(MapMode.READ_WRITE, 0, file.length()); 这个MappedByteBuffer实际上是其子类DirectByteBuffer实例的引用。也就是说，我们获得的MappedByteBuffer实际上是DirectBuffer类型的缓冲区。也就是说，使用MappedByteBuffer并不会消耗Java虚拟机内存堆。 12345678910public abstract class FileChannel extends AbstractChannel implements ByteChannel, GatheringByteChannel, ScatteringByteChannel &#123; // 这里仅列出部分API public abstract MappedByteBuffer map(MapMode mode, long position, long size) public static class MapMode &#123; public static final MapMode READ_ONLY public static final MapMode READ_WRITE public static final MapMode PRIVATE &#125;&#125; 我们可以创建一个MappedByteBuffer来代表一个文件中字节的某个子范围。例如，要映射100到299(包含299)位置的字节，可以使用下面的代码：buffer = fileChannel.map(FileChannel.MapMode.READ_ONLY, 100, 200); 如果要映射整个文件则使用：buffer = fileChannel.map(FileChannel.MapMode.READ_ONLY, 0, fileChannel.size()); 文件映射可以是可写的或只读的。前两种映射模式MapMode.READ_ONLY和MapMode.READ_WRITE意义是很明显的，它们表示希望获取的映射只读还是允许修改映射的文件。请求的映射模式将受被调用map()方法的FileChannel对象的访问权限所限制。如果通道是以只读的权限打开的却请求MapMode.READ_WRITE模式，那么map()方法会抛出一个NonWritableChannelException异常；如果在一个没有读权限的通道上请求MapMode.READ_ONLY映射模式，那么将产生NonReadableChannelException异常。 第三种模式MapMode.PRIVATE表示想要一个写时拷贝(copy-on-write)的映射。这意味着通过put()方法所做的任何修改都会导致产生一个私有的数据副本并且该副本中的数据只有MappedByteBuffer实例可以看到。该过程不会对底层文件做任何修改。尽管写时拷贝的映射可以防止底层文件被修改，但也必须以read/write权限来打开文件以建立MapMode.PRIVATE映射。只有这样，返回的MappedByteBuffer对象才能允许使用put()方法。 一个映射一旦建立之后将保持有效，直到MappedByteBuffer对象被施以垃圾收集动作为止。关闭相关联的FileChannel不会破坏映射，只有丢弃缓冲区对象本身才会破坏该映射。 MappedByteBuffer主要用在对大文件的读写或对实时性要求比较高的程序当中。 For most operating systems, mapping a file into memory is more expensive than reading or writing a few tens of kilobytes of data via the usual read and write methods. From the standpoint of performance it is generally only worth mapping relatively large files into memory. 参考java doc FileChannel.map 参考Java nio入门教程详解(三) Java nio入门教程详解(二十一) 《计算机操作系统(第四版)》 西安电子科技大学出版社]]></content>
      <categories>
        <category>编程</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>NIO</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java-NIO-Buffer]]></title>
    <url>%2F2017%2F06%2F28%2Fjava-NIO-Buffer%2F</url>
    <content type="text"><![CDATA[最近在看java nio方面的知识，打算写几篇博客总结一下，就从Buffer开始吧 Bufferjava NIO库是在jdk1.4中引入的，NIO与IO之间的第一个区别在于，IO是面向流的，而NIO是面向块的。 所谓的面向流是指：系统一次一个字节的处理数据，一个输入流产生一个字节的数据，一个输出流消费一个字节的数据。 所谓的面向块是指：以块的形式处理数据。每一个操作都在一步中产生或者消费一个数据块。 按块的方式处理数据要比按流的方式处理数据快，因为按块的方式读取或写入数据所执行的系统调用要远少于一次一个字节的方式，类似于BufferedInputStream的方式。 上面所说的块，在NIO中就是Buffer对象。 一个 Buffer(缓冲区) 实质上是一个容器对象，它包含一些要写入或者刚读出的数据。在 NIO 库中，所有数据都是用缓冲区处理的。在读取数据时，它是直接读到缓冲区中的。在写入数据时，它是写入到缓冲区中的。缓冲区实质上是一个数组。通常它是一个字节数组，但是也可以使用其他种类的数组。但是一个缓冲区不 仅仅 是一个数组。缓冲区提供了对数据的结构化访问，而且还可以跟踪系统的读/写进程。 举例来说，ByteBuffer实质上是对byte数组进行了封装，其内部是一个byte数组，ByteBuffer对象提供了一些实用的API供我们去操作这个数组，完成一些读取或写入的功能。我们所要学习的，就是理解在调用这些API的时候，Buffer处理数组的方式。 除了boolean类型之外，java为每种基本类型都封装了对应的Buffer对象。 状态变量Buffer使用四个值指定了缓冲区在某个时刻的状态： 容量(Capacity)：缓冲区能够容纳的数据元素的最大数量 实际上，这个值指定了底层数组的大小。这一值在缓冲区创建时被设定，并且永远不能被改变。 位置(Position)：下一个要被读或写的元素的索引 position 变量跟踪已经写了多少数据。更准确地说，它指定了下一个字节将放到数组的哪一个元素中。比如，从通道中读三个字节到缓冲区中，那么缓冲区的 position 将会设置为3，指向数组中第四个元素。 初始的position值为0。 边界(Limit)：缓冲区的第一个不能被读或写的元素。或者说，缓冲区中现存元素的计数。 在写模式下，Buffer的limit表示你最多能往Buffer里写多少数据。 当切换Buffer到读模式时， limit表示你最多能读到多少数据。因此，当切换Buffer到读模式时，limit会被设置成写模式下的position值。 标记(Mark)：一个备忘位置。 调用 mark()来设定 mark = postion。调用 reset()设定 position = mark。 初始的mark值为-1。 上面四个属性遵循以下的关系： 0 &lt;= mark &lt;= position &lt;= limit &lt;= capacity API 创建 在了解这些api之前，首先需要知道如何创建一个Buffer对象： 在上一个小节中提到的7种缓冲区类没有一种是可以直接实例化的，他们都是抽象类，但都包含了静态工厂方法创建相应的实例。以ByteBuffer为例：(对于其他六中缓冲区类也适用) ByteBuffer buffer = ByteBuffer.allocate(1024); allocate方法分配了一个具有指定大小底层数组的缓冲区对象，这个大小也就是上面提到的Capacity。 我们也可以使用已经存在的数组来作为缓冲区对象的底层数组： 12byte array[] = new byte[1024];ByteBuffer buffer = ByteBuffer.wrap(array); 此时，buffer对象的底层数组指向了array，这意味着直接修改array数组也会使buffer对象读取的数据产生变化。 123byte[] bs = new byte[10];ByteBuffer buffer = ByteBuffer.wrap(bs);System.out.println(buffer.toString()); 打印如下： 1java.nio.HeapByteBuffer[pos=0 lim=10 cap=10] 可见，新初始化的Buffer实例中，position = 0，limit=capacity=10 存取 注意到Buffer类中并没有提供get或者put函数。实际上每一个Buffer对象都有这两个函数，但它们所采用的参数类型，以及它们返回的数据类型，对每个子类来说都是唯一的，所以它们不能在顶层Buffer类中被抽象地声明。这些存取方法被定义在Buffer类的子类当中，我们一ByteBuffer为例： 1234public abstract byte get();public abstract byte get (int index);public abstract ByteBuffer put (byte b);public abstract ByteBuffer put (int index, byte b); ByteBuffer实际上还提供了 get(byte[] dst, int offset, int length)这样的接口，其内部实现也是循环调用了get()方法。 get和put可以是相对的或者是绝对的。 相对方案是不带有索引参数的函数。当相对函数被调用时，位置在返回时前进一。 绝对存取不会影响缓冲区的位置属性(Position、Limit、Capacity、Mark)。 123456789101112131415161718buffer.put((byte)'h').put((byte)'e').put((byte)'l').put((byte)'l').put((byte)'o');print(buffer, bs);buffer.put(0, (byte)'y').put((byte)'y');print(buffer, bs);//观察Buffer底层存储情况public static void print(Buffer buffer, byte[] bs) &#123; System.out.println(buffer.toString()); for (int i = 0; i &lt; bs.length; i++) &#123; if (bs[i] != 0) &#123; char c = (char)bs[i]; System.out.print(c); &#125; else &#123; System.out.print("$"); &#125; &#125; System.out.println(""); &#125; 打印如下： 1234java.nio.HeapByteBuffer[pos=5 lim=10 cap=10]hello$$$$$java.nio.HeapByteBuffer[pos=6 lim=10 cap=10]yelloy$$$$ 可以看到，存入5个字节之后，position增加为5，limit与capacity不变。调用buffer.put(0, (byte)’y’)，将bs[0]的数据改写为(byte)’y’，position并没有改变。 Buffer.flip() 我们想要将刚刚写入的数据读出的话应该怎么做？应该将position设为0：buffer.position(0)，就可以从正确的位置开始获取数据。但是它是怎样知道何时到达我们所插入数据末端的呢？这就是边界属性被引入的目的。边界属性指明了缓冲区有效内容的末端。我们需要将limit设置为当前位置：buffer.limit(buffer.position())。 buffer.limit(buffer.position()).position(0); Buffer已经提供了一个方法封装了这些操作： 123456public final Buffer flip() &#123; limit = position; position = 0; mark = -1; return this;&#125; 12buffer.flip();print(buffer, bs); 打印如下： 12java.nio.HeapByteBuffer[pos=0 lim=6 cap=10]yelloy$$$$ 调用buffer.flip()后，limit设置为当前position值，position重置为0. Buffer.rewind() 紧接着上面的程序： 123456System.out.println((char)buffer.get());System.out.println((char)buffer.get(3));print(buffer, bs); buffer.rewind();print(buffer, bs); 打印如下： 123456yljava.nio.HeapByteBuffer[pos=1 lim=6 cap=10]yelloy$$$$java.nio.HeapByteBuffer[pos=0 lim=6 cap=10]yelloy$$$$ 可以看到，rewind()方法与filp()相似，但是不影响limit，他只是将position设为0，这样就可以从新读取已经读过的数据了。 12345public final Buffer rewind() &#123; position = 0; mark = -1; return this;&#125; Buffer.mark()、Buffer.reset() 123456789101112public final Buffer mark() &#123; mark = position; return this;&#125;public final Buffer reset() &#123; int m = mark; if (m &lt; 0) throw new InvalidMarkException(); position = m; return this;&#125; Buffer.mark(),使缓冲区能够记住一个位置并在之后将其返回。 缓冲区的标记在mark()函数被调用之前是未定义的，调用时标记被设为当前位置的值。reset()函数将位置设为当前的标记值。如果标记值未定义，调用reset()将导致InvalidMarkException异常。 1234567buffer.position(2);buffer.mark();print(buffer, bs);buffer.position(4);print(buffer, bs);buffer.reset();print(buffer, bs); 打印如下： 123456java.nio.HeapByteBuffer[pos=2 lim=6 cap=10]yelloy$$$$java.nio.HeapByteBuffer[pos=4 lim=6 cap=10]yelloy$$$$java.nio.HeapByteBuffer[pos=2 lim=6 cap=10]yelloy$$$$ Buffer.remaining()、Buffer.hasRemaining() remaining()函数将返回从当前位置到上界还剩余的元素数目。 hasRemaining()会返回是否已经达到缓冲区的边界。 1234567public final int remaining() &#123; return limit - position;&#125;public final boolean hasRemaining() &#123; return position &lt; limit;&#125; 有两种方法读取缓冲区的所有剩余数据： 12345678910// 第一种for (int i = 0; buffer.hasRemaining(), i++) &#123; myByteArray [i] = buffer.get();&#125;// 第二种int count = buffer.remaining();for (int i = 0; i &lt; count, i++) &#123; myByteArray [i] = buffer.get();&#125; Buffer.clear() clear()函数将缓冲区重置为空状态。它并不改变缓冲区中的任何数据元素，而是仅仅将上界设为容量的值，并把位置设回 0。 123456public final Buffer clear() &#123; position = 0; limit = capacity; mark = -1; return this;&#125; ByteBuffer.compact() compact()方法并不是Buffer接口中定义的，而是属于ByteBuffer。 如果Buffer中仍有未读的数据，且后续还需要这些数据，但是此时想要先写些数据，那么使用compact()方法。 compact()方法将所有未读的数据拷贝到Buffer起始处。然后将position设到最后一个未读元素正后面。limit属性依然像clear()方法一样，设置成capacity。现在Buffer准备好写数据了，但是不会覆盖未读的数据。 1234print(buffer, bs);System.out.println(buffer.remaining());buffer.compact();print(buffer, bs); 打印如下： 12345java.nio.HeapByteBuffer[pos=2 lim=6 cap=10]yelloy$$$$4java.nio.HeapByteBuffer[pos=4 lim=10 cap=10]lloyoy$$$$ ByteBuffer.equals()、ByteBuffer.compareTo() 可以使用equals()和compareTo()方法两个Buffer。 下面提到的剩余元素是从 position到limit之间的元素。 equals() 当满足下列条件时，表示两个Buffer相等： 有相同的类型（byte、char、int等）。 Buffer中剩余的byte、char等的个数相等。 Buffer中所有剩余的byte、char等都相同。 在每个缓冲区中应被get()函数返回的剩余数据元素序列必须一致。 equals只是比较Buffer的一部分，不是每一个在它里面的元素都比较。实际上，它只比较Buffer中的剩余元素。 compareTo() compareTo()方法比较两个Buffer的剩余元素(byte、char等)， 如果满足下列条件，则认为一个Buffer“小于”另一个Buffer： 第一个不相等的元素小于另一个Buffer中对应的元素 。 所有元素都相等，但第一个Buffer比另一个先耗尽(第一个Buffer的元素个数比另一个少)。 只读缓冲区可以使用asReadOnlyBuffer()函数来生成一个只读的缓冲区视图。 这个新的缓冲区不允许使用put()，并且其isReadOnly()函数将会返回true。对这一只读缓冲区的put()函数的调用尝试会导致抛出ReadOnlyBufferException异常。 两个缓冲区共享数据元素，拥有同样的容量，但每个缓冲区拥有各自的位置，上界和标记属性。对一个缓冲区内的数据元素所做的改变会反映在另外一个缓冲区上。 复制缓冲区duplicate()函数创建了一个与原始缓冲区相似的新缓冲区。两个缓冲区共享数据元素，拥有同样的容量，但每个缓冲区拥有各自的位置，上界和标记属性。对一个缓冲区内的数据元素所做的改变会反映在另外一个缓冲区上。这一副本缓冲区具有与原始缓冲区同样的数据视图。如果原始的缓冲区为只读，或者为直接缓冲区，新的缓冲区将继承这些属性。 复制一个缓冲区会创建一个新的Buffer对象，但并不复制数据。原始缓冲区和副本都会操作同样的数据元素。 直接缓冲区直接ByteBuffer是通过调用ByteBuffer.allocateDirect(int capacity)函数来创建的。 什么是直接缓冲区(DirectByteBuffer)呢？直接缓冲区意味着所分配的这段内存是堆外内存，而我们通过ByteBuffer.allocate(int capacity)或者ByteBuffer.wrap(byte[] array)分配的内存是堆内存，其返回的实例为HeapByteBuffer，HeapByteBuffer中持有一个byte数组，这个数组所占有的内存是堆内内存。 Netty之Java堆外内存扫盲贴了解java堆外内存。 sun.nio.ch.FileChannelImpl.read(ByteBuffer dst) sun.nio.ch.IOUtil.read(FileDescriptor fd, ByteBuffer dst, long position,NativeDispatcher nd, Object lock) 观察上面两段代码发现，我们通过一个文件通道去填充一个ByteBuffer时，先执行sun.nio.ch.FileChannelImpl.read(ByteBuffer dst)方法，其中调用了sun.nio.ch.IOUtil.read(FileDescriptor fd, ByteBuffer dst, long position,NativeDispatcher nd, Object lock)方法，观察这个方法，发现其中会做一个判断：如果是直接缓冲区(DirectBuffer)，直接调用readIntoNativeBuffer(fd, dst, position, nd, lock)并返回；如果是非直接缓冲区(HeapByteBuffer)，先获取一个直接缓冲区，然后使用该直接缓冲区作为参数调用readIntoNativeBuffer(fd, dst, position, nd, lock)，然后将填充完毕的DirectBuffer的内容复制到HeapByteBuffer当中，然后返回。 直接缓冲区的内存分配调用了sun.misc.Unsafe.allocateMemory(size),返回了内存基地址，实际上就是malloc。 看一下java doc对DirectBuffer的说明： A byte buffer is either direct or non-direct. Given a direct byte buffer, the Java virtual machine will make a best effort to perform native I/O operations directly upon it. That is, it will attempt to avoid copying the buffer’s content to (or from) an intermediate buffer before (or after) each invocation of one of the underlying operating system’s native I/O operations. 给定一个直接字节缓冲区，Java 虚拟机将尽最大努力直接对它执行本机 I/O 操作。也就是说，它会在每一次调用底层操作系统的本机 I/O 操作之前(或之后)，尝试避免将缓冲区的内容拷贝到一个中间缓冲区中(或者从一个中间缓冲区中拷贝数据)。 结合上面的代码，就可以理解这段话的含义。 那么，为什么需要直接缓冲区，也就是堆外内存来执行IO呢？ 以读操作为例，数据从底层硬件读到内核缓冲区之后，操作系统会从内核空间复制数据到用户空间，此时的用户进程空间就是jvm，这意味着 I/O 操作的目标内存区域必须是连续的字节序列。在 Java 中，数组是对象，在 JVM 中，字节数组可能不会在内存中连续存储。因此，这个连续的字节序列就是直接缓冲区中分配的内存空间。需要直接缓冲区来当一个中间人，完成数据的写入或者读取。 其实，在传统BIO中，也是这么做的，同样需要一个堆外内存来充当这个中间人：比如FileInputStream.read(byte b[], int off, int len): FileInputStream.read(byte b[], int off, int len)调用了readBytes(byte b[], int off, int len)方法，这个方法是一个本地方法： 12345JNIEXPORT jint JNICALL Java_java_io_FileInputStream_readBytes(JNIEnv *env, jobject this, jbyteArray bytes, jint off, jint len) &#123;//除了前两个参数，后三个就是readBytes方法传递进来的，字节数组、起始位置、长度三个参数 return readBytes(env, this, bytes, off, len, fis_fd); &#125; 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253jintreadBytes(JNIEnv *env, jobject this, jbyteArray bytes, jint off, jint len, jfieldID fid)&#123; jint nread; char stackBuf[BUF_SIZE]; char *buf = NULL; FD fd; if (IS_NULL(bytes)) &#123; JNU_ThrowNullPointerException(env, NULL); return -1; &#125; if (outOfBounds(env, off, len, bytes)) &#123; JNU_ThrowByName(env, "java/lang/IndexOutOfBoundsException", NULL); return -1; &#125; if (len == 0) &#123; return 0; &#125; else if (len &gt; BUF_SIZE) &#123; buf = malloc(len);// buf的分配 if (buf == NULL) &#123; JNU_ThrowOutOfMemoryError(env, NULL); return 0; &#125; &#125; else &#123; buf = stackBuf; &#125; fd = GET_FD(this, fid); if (fd == -1) &#123; JNU_ThrowIOException(env, "Stream Closed"); nread = -1; &#125; else &#123; nread = IO_Read(fd, buf, len);// buf是使用malloc分配的直接缓冲区，也就是堆外内存 if (nread &gt; 0) &#123; (*env)-&gt;SetByteArrayRegion(env, bytes, off, nread, (jbyte *)buf);// 将直接缓冲区的内容copy到bytes数组中 &#125; else if (nread == JVM_IO_ERR) &#123; JNU_ThrowIOExceptionWithLastError(env, "Read error"); &#125; else if (nread == JVM_IO_INTR) &#123; JNU_ThrowByName(env, "java/io/InterruptedIOException", NULL); &#125; else &#123; /* EOF */ nread = -1; &#125; &#125; if (buf != stackBuf) &#123; free(buf); &#125; return nread;&#125; 可以看到，这个方法其实最关键的就是IO_Read这个宏定义的处理，而IO_Read其实只是代表了一个方法名称叫handleRead，我们去看一下handleRead的源码。 123456789101112131415161718192021222324JNIEXPORT size_t handleRead(jlong fd, void *buf, jint len) &#123; DWORD read = 0; BOOL result = 0; HANDLE h = (HANDLE)fd; if (h == INVALID_HANDLE_VALUE) &#123; return -1; &#125; result = ReadFile(h, buf, len, &amp;read, NULL); if (result == 0) &#123; int error = GetLastError(); if (error == ERROR_BROKEN_PIPE) &#123; return 0; &#125; return -1; &#125; return read; &#125; 通过上面的代码可以发现，传统的BIO也是把操作系统返回的数据放到直接缓冲区当中，然后在copy回我们传入的byte数组当中。 所有的缓冲区都提供了一个叫做isDirect()的boolean函数，来测试特定缓冲区是否为直接缓冲区。 A direct byte buffer may be created by invoking the allocateDirect factory method of this class. The buffers returned by this method typically have somewhat higher allocation and deallocation costs than non-direct buffers. The contents of direct buffers may reside outside of the normal garbage-collected heap, and so their impact upon the memory footprint of an application might not be obvious. It is therefore recommended that direct buffers be allocated primarily for large, long-lived buffers that are subject to the underlying system’s native I/O operations. In general it is best to allocate direct buffers only when they yield a measureable gain in program performance. 直接缓冲区虽然避免了复制内存带来的消耗，但直接缓冲区使用的内存是通过调用本地操作系统方面的代码分配的，绕过了标准 JVM 堆栈。建立和销毁直接缓冲区会明显比具有堆栈的缓冲区更加破费，并且可能带来不易察觉的内存泄漏，或oom问题。所以，如果对于性能要求不是很严格，一般情况下，使用非直接缓冲区就足够了。 缓冲区分片slice() 方法根据现有的缓冲区创建一种 子缓冲区 。也就是说，它创建一个新的缓冲区，新缓冲区与原来的缓冲区的一部分共享数据。 现在我们对这个缓冲区 分片 ，以创建一个包含槽 3 到槽 6 的子缓冲区。在某种意义上，子缓冲区就像原来的缓冲区中的一个 窗口。 窗口的起始和结束位置通过设置 position 和 limit 值来指定，然后调用 Buffer 的 slice() 方法： 1234print(buffer, bs);buffer.position( 3 ).limit( 7 );ByteBuffer slice = buffer.slice();print(slice, slice.array()); 打印如下： 1234java.nio.HeapByteBuffer[pos=4 lim=10 cap=10]lloyoy$$$$java.nio.HeapByteBuffer[pos=0 lim=4 cap=4]lloyoy$$$$ slice 是缓冲区的 子缓冲区 。不过， slice 和 buffer 共享同一个底层数据数组。 类型视图缓冲区我们知道，Buffer可以作为通道执行IO的源头或者目标，但是通道只接受ByteBuffer类型的参数。比如read(ByteBuffer dst)。 我们在进行IO操作时，可能会使用各种ByteBuffer类去读取文件内容，接收来自网络连接的数据使用各种ByteBuffer类去读取文件内容，接收来自网络连接的数据等。一旦数据到达了您的 ByteBuffer，我们需要对他进行一些操作。ByteBuffer类允许创建视图来将byte型缓冲区字节数据映射为其它的原始数据类型。例如，asLongBuffer()函数创建一个将八个字节型数据当成一个 long 型数据来存取的视图缓冲区。 123456789public abstract class ByteBuffer extends Buffer implements Comparable&#123; // 这里仅列出部分API public abstract CharBuffer asCharBuffer(); public abstract ShortBuffer asShortBuffer(); public abstract IntBuffer asIntBuffer(); public abstract LongBuffer asLongBuffer(); public abstract FloatBuffer asFloatBuffer(); public abstract DoubleBuffer asDoubleBuffer();&#125; 12345678910111213buffer.clear();buffer.order(ByteOrder.BIG_ENDIAN);//指定字节序buffer.put (0, (byte)0);buffer.put (1, (byte)'H');buffer.put (2, (byte)0);buffer.put (3, (byte)'i');buffer.put (4, (byte)0);buffer.put (5, (byte)'!');buffer.put (6, (byte)0);CharBuffer charBuffer = buffer.asCharBuffer();System.out.println("pos=" + charBuffer.position() + " limit=" + charBuffer.limit() + " cap=" + charBuffer.capacity());;print(charBuffer, bs); 打印如下： 123pos=0 limit=5 cap=5Hi! $H$i$!$$$$ 新的缓冲区的容量是字节缓冲区中存在的元素数量除以视图类型中组成一个数据类型的字节数。视图缓冲区的第一个元素从创建它的ByteBuffer对象的位置开始(positon()函数的返回值)。 测试代码前面提到的测试代码汇总： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475import java.nio.Buffer;import java.nio.ByteBuffer;import java.nio.ByteOrder;import java.nio.CharBuffer;public class Test &#123; public static void main(String[] args) &#123; byte[] bs = new byte[10]; ByteBuffer buffer = ByteBuffer.wrap(bs); System.out.println(buffer.toString()); // put buffer.put((byte)'h').put((byte)'e').put((byte)'l').put((byte)'l').put((byte)'o'); print(buffer, bs); buffer.put(0, (byte)'y').put((byte)'y'); print(buffer, bs); //flip buffer.flip(); print(buffer, bs); // rewind System.out.println((char)buffer.get()); System.out.println((char)buffer.get(3)); print(buffer, bs); buffer.rewind(); print(buffer, bs); // mark reset buffer.position(2); buffer.mark(); print(buffer, bs); buffer.position(4); print(buffer, bs); buffer.reset(); print(buffer, bs); // compact System.out.println(buffer.remaining()); buffer.compact(); print(buffer, bs); // slice buffer.position( 3 ).limit( 7 ); ByteBuffer slice = buffer.slice(); print(slice, slice.array()); // asCharBuffer buffer.clear(); buffer.order(ByteOrder.BIG_ENDIAN); buffer.put (0, (byte)0); buffer.put (1, (byte)'H'); buffer.put (2, (byte)0); buffer.put (3, (byte)'i'); buffer.put (4, (byte)0); buffer.put (5, (byte)'!'); buffer.put (6, (byte)0); CharBuffer charBuffer = buffer.asCharBuffer(); System.out.println("pos=" + charBuffer.position() + " limit=" + charBuffer.limit() + " cap=" + charBuffer.capacity());; print(charBuffer, bs); &#125; public static void print(Buffer buffer, byte[] bs) &#123; System.out.println(buffer.toString()); for (int i = 0; i &lt; bs.length; i++) &#123; if (bs[i] != 0) &#123; char c = (char)bs[i]; System.out.print(c); &#125; else &#123; System.out.print("$"); &#125; &#125; System.out.println(""); &#125;&#125; 参考Why is Traditional Java I/O Uninterruptable? JNI探秘—–FileInputStream的read方法详解 NIO 入门 Java NIO Buffer]]></content>
      <categories>
        <category>编程</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>NIO</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[并发场景下缓存的创建]]></title>
    <url>%2F2017%2F06%2F24%2F%E5%B9%B6%E5%8F%91%E5%9C%BA%E6%99%AF%E4%B8%8B%E7%BC%93%E5%AD%98%E7%9A%84%E5%88%9B%E5%BB%BA%2F</url>
    <content type="text"><![CDATA[问题背景：现场提了一个新的需求：jdbc需要提供一个新的接口，用于查询session的执行进度。后台提供了查询视图，jdbc要做的只是在这个接口中查询这个视图，获得当前session的执行进度返回给客户。查询当前session的执行进度，说明当前session很有可能正在执行某条sql，是阻塞的。所以需要通过创建新的session并以当前session的sessionID作为条件在视图中查找当前session的执行情况。这个接口的调用在某些特定场景下是比较频繁的，比如用户每隔5秒就需要调用一次，那么每次都创建新的session去查询是不是显得太low？是不是可以在第一次查询时创建新的session，然后缓存起来，下次可以直接用？于是涉及到了缓存session的问题。（其实完全可以使用连接池来做到缓存，这次讨论的是并发场景下缓存的创建问题~~思路主要来自于《java并发编程实战》） 使用HashMap建立缓存123456789101112131415161718192021public class ConnCache &#123; private final Map&lt;String, Connection&gt; cache; private final ConnFactory factory; public ConnCache(ConnFactory factory) &#123; cache = new HashMap&lt;&gt;(); this.factory = factory; &#125; public synchronized Connection get(String key) throws SQLException &#123; Connection connection = cache.get(key); if (connection == null) &#123; connection = factory.getConn(); cache.put(key, connection); &#125; return connection; &#125;&#125;interface ConnFactory &#123; Connection getConn() throws SQLException;&#125; 上面的ConnFactory.getConn()创建新的session，是一个相对耗时的操作。用户需要获得session时调用ConnCache.get()方法，先从map中查找是否有对应的session(key可以设计为连接串+用户名映射到指定的session)，如果没有，那么创建一个新的session，放到map里面，然后返回。 注意到整个get方法是被synchronized修饰的，因为HashMap不是线程安全的，如果有多个线程同时访问HashMap会出现并发问题。synchronized确保了两个线程不会同时访问HashMap。但是这么做也有一个问题，对整个get方法同步会使访问同一ConnCache对象get方法的线程串行化，如果一个线程正在调用这个方法，那么其他想要调用get方法的线程需要排队等候，很有可能被阻塞很长时间(创建session是个耗时的动作)。这种情况是由于锁的粒度较大带来的伸缩性问题。 使用ConcurrentHashMap建立缓存我们很容易想到使用ConcurrentHashMap来代替HashMap，ConcurrentHashMap本身就是线程安全的，采用了分段锁的技术，并发性能相对于加锁的HashMap要好上很多。使用ConcurrentHashMap后，我们就不需要在访问底层的Map时进行同步了。 123456789101112131415161718192021public class ConnCache &#123; private final Map&lt;String, Connection&gt; cache; private final ConnFactory factory; public ConnCache(ConnFactory factory) &#123; cache = new ConcurrentHashMap&lt;&gt;(); this.factory = factory; &#125; public Connection get(String key) throws SQLException &#123; Connection connection = cache.get(key); if (connection == null) &#123; connection = factory.getConn(); cache.put(key, connection); &#125; return connection; &#125;&#125;interface ConnFactory &#123; Connection getConn() throws SQLException;&#125; 上面这种方法相对于第一种方法，减小了锁的粒度，有着更好的并发性能。但是他也有一个严重的问题：如果一个线程在调用get方法时没有命中缓存，那么他会去创建一个新的session，然后放到map里面。如果在创建session的过程中，另一个线程也调用了get方法传入同样的key，那么就会导致重复创建的问题(这种情况很有可能出现，因为创建session是个耗时的操作)。 所以，我们需要某种方法来知道当前是否有其他线程在创建指定的session，如果有，则等待这个线程创建完毕，然后直接获取创建好的session。这样就能避免一次session多余的创建。 这时，我们就需要FutureTask来实现这个功能。FutureTask表示一个计算过程，这个过程可能计算完成，也可能正在运行。如果计算完毕，那么调用FutureTask.get()就会立即返回结果，否则，该方法会一直阻塞，直到有结果可用。categories: 生活tags: 食物 基于FutureTask建立缓存12345678910111213141516171819202122232425262728293031323334353637public class ConnCache &#123; private final Map&lt;String, Future&lt;Connection&gt;&gt; cache; private final ConnFactory factory; public ConnCache(ConnFactory factory) &#123; cache = new ConcurrentHashMap&lt;&gt;(); this.factory = factory; &#125; public Connection get(String key) throws SQLException &#123; Future&lt;Connection&gt; future = cache.get(key); if (future == null) &#123; Callable&lt;Connection&gt; eval = new Callable&lt;Connection&gt;() &#123; @Override public Connection call() throws Exception &#123; return factory.getConn(); &#125; &#125;; FutureTask&lt;Connection&gt; task = new FutureTask&lt;&gt;(eval); future = task; cache.put(key, task); task.run(); &#125; try &#123; return future.get(); &#125; catch (InterruptedException e) &#123; throw new SQLException(e); &#125; catch (ExecutionException e) &#123; throw new SQLException(e); &#125; &#125;&#125;interface ConnFactory &#123;categories: 生活tags: 食物 Connection getConn() throws SQLException;&#125; 与第二种方法相反，上面的方法是先检查创建session的动作是否开始(第二种方法是检查session创建是否完成)，如果已经有线程在创建指定的session，就等待其创建完毕，然后获取结果。 看起来已经很完美了，但是还有一个并发缺陷: if代码块中不是原子的先检查再执行操作，两个线程很有可能同时检查到缓存为空，然后重复创建了session。 解决这个问题的方法有一种思路：把创建好的FutureTask放入到Map这一步需要是一个原子操作，如果对应的FutureTask已经存在了，调用已存在的FutureTask.get()方法即可。 最终的实现ConcurrentHashMap提供了一个同步方法：putIfAbsent() 12345678910111213141516171819202122232425262728293031323334353637383940public class ConnCache &#123; private final Map&lt;String, Future&lt;Connection&gt;&gt; cache; private final ConnFactory factory; public ConnCache(ConnFactory factory) &#123; cache = new ConcurrentHashMap&lt;&gt;(); this.factory = factory; &#125; public Connection get(String key) throws SQLException &#123; Future&lt;Connection&gt; future = cache.get(key); if (future == null) &#123; Callable&lt;Connection&gt; eval = new Callable&lt;Connection&gt;() &#123; @Override public Connection call() throws Exception &#123; return factory.getConn(); &#125; &#125;; FutureTask&lt;Connection&gt; task = new FutureTask&lt;&gt;(eval); future = cache.putIfAbsent(key, task); if (future == null) &#123; future = task; task.run(); &#125; &#125; try &#123; return future.get(); &#125; catch (InterruptedException e) &#123; cache.remove(future); throw new SQLException(e); &#125; catch (ExecutionException e) &#123; cache.remove(future); throw new SQLException(e); &#125; &#125;&#125;interface ConnFactory &#123; Connection getConn() throws SQLException;&#125; 上面的演示是对并发场景的一个思考。实际的缓存在使用中还要考虑缓存过期时间(可以在FutureTask的子类中实现)，缓存清理算法等问题。我们也可以通过泛型将上面的代码设计为一个通用的缓存框架： 1234567891011121314151617181920212223242526272829303132333435363738public class Cache&lt;K, V&gt; implements Factory&lt;K, V&gt;&#123; private final Map&lt;K, Future&lt;V&gt;&gt; cache; private final Factory&lt;K,V&gt; factory; public Cache(Factory&lt;K, V&gt; factory) &#123; cache = new ConcurrentHashMap&lt;&gt;(); this.factory = factory; &#125; public V get(K key) throws InterruptedException &#123; Future&lt;V&gt; future = cache.get(key); if (future == null) &#123; Callable&lt;V&gt; eval = new Callable&lt;V&gt;() &#123; @Override public V call() throws Exception &#123; return factory.get(key); &#125; &#125;; FutureTask&lt;V&gt; task = new FutureTask&lt;&gt;(eval); future = cache.putIfAbsent(key, task); if (future == null) &#123; future = task; task.run(); &#125; &#125; try &#123; return future.get(); &#125; catch (ExecutionException e) &#123; cache.remove(future); throw new IllegalStateException(e); &#125; &#125;&#125;interface Factory&lt;K, V&gt; &#123; V get(K key) throws InterruptedException;&#125;]]></content>
      <categories>
        <category>编程</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>多线程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[如何从外网访问家里的电脑]]></title>
    <url>%2F2017%2F06%2F05%2F%E5%A6%82%E4%BD%95%E4%BB%8E%E5%A4%96%E7%BD%91%E8%AE%BF%E9%97%AE%E5%AE%B6%E9%87%8C%E7%9A%84%E7%94%B5%E8%84%91%2F</url>
    <content type="text"><![CDATA[今天逛论坛的时候偶然间看到了电信用户可以轻松获得公网IP的一条内容，于是看了下自己的(本人用电信)路由器ip，惊喜的发现竟然是公网ip…之前都没有注意到….有了公网IP，就可以做一些好玩的事了。最直接的就是可以把自己的主机当服务器来用了，省去了购买VPS的费用，在公司或者其他地方也可以连到家里的主机，传东西什么的也很方便… 判断是否是公网IP首先要判断运营商分配给自己的IP是否是公网IP，如果没有公网IP，一切都是白搭…移动和联通的不太清楚，电信用户是可以直接获取到公网IP的。 我的路由器是TP-LINK，在电脑地址栏输入路由器地址192.168.1.1，进入路由器web界面 在路由设置-&gt;上网设置界面，可以看到WAN口的IP地址。 此时，打开google，查询一下外网IP(或者直接打开http://www.ip138.com/)。 如果路由器WAN口的IP地址和查到的外网IP地址相同，可以确定这个ip地址就是运营商分配给你的公网IP，可以拿来使用。 PS：我们在自己的机器上用ipconfig查询得到的IP地址，往往是路由器分配给我们主机的私有IP地址，有以下几类： 10.0.0.0～10.255.255.255 172.16.0.0～172.31.255.255 192.168.0.0～192.168.255.255 这样的IP地址是属于本地局域网的，因特网中的所有路由器，对于目的地址是上面几类的数据报一律不进行转发。所以，因特网上的机器是无法访问我们的主机的。 当然，如果你没有使用路由器，而是直接把应当插在路由器WAN口的网线插在电脑上的话，ping出来的地址就直接就是公网IP… 动态域名解析实际上，运营商每次分配给我们的公网IP是不一样的，都是从IP池里随机取的。可以重启路由器观察一下，每当你重启一次路由器之后，公网IP就会切换。这样就会造成一个问题：假如我们要通过公网IP来访问我们在家里的主机，但是这个IP不是固定的，随时有可能切换，我们不可能在他切换的时候感知到(其实是可以的)，即使可以，每次还要确认这个公网IP，是不是太low了？ 这就需要动态域名解析来解决。简单来说就是将这些公网IP映射到一个域名上，无论IP怎么切换，我们只要通过这个域名就能得到IP，并进行访问，至于域名和动态IP怎么映射，我们不必关心，只要记住这个域名就好了。 TP-LINK本身有自己动态域名解析服务，还支持花生壳的动态域名解析服务。在路由器应用管理-&gt;DDNS 界面可以选择动态域名解析服务提供方，以及免费域名。我这里就选择了TP-LINK的域名解析服务，简单快捷。 填写好域名信息并保存之后，打开控制台，ping一下这个域名。如果ping返回的响应结果ip地址就是我们的公网IP，那么动态域名配置成功。 端口映射试想一下，连接到路由器上的设备往往不止一个，有电脑，平板，手机…路由器会为每个设备分配一个私有地址，而这些设备共享一个公网IP，大家轮换使用(NAT映射)。那么，我们要从外网访问家里的主机时，只有公网IP，如何在这众多的设备中选择出我们的主机呢？ 端口映射解决了这个问题。先看看怎么配置端口映射。在应用管理-&gt;虚拟服务器 中添加一行映射。 上图中，外部端口是在外网访问我们局域网主机提供的服务时指定的端口，内部端口是局域网主机提供服务的真实端口，IP地址是要访问的局域网主机的私有IP地址，可以通过ipconfig获得，协议类型是传输层协议，一般选ALL即可。 举个例子，我们想要访问局域网主机的ssh服务，ssh:yukai@debiao.tpddns.cn:8888， 8888是外部端口，路由器拿到这个端口，去查端口映射表，将请求转发到192.168.1.105的22端口，也就是内部端口，也是我们主机ssh服务的端口。这样便完成了外网与局域网主机的通信。 还有一个问题，如果路由器采用DHCP的方式为局域网内的设备分配私有IP，那么这个IP往往是有时效性的，这一次你的主机是192.168.1.105，说不定过一会就自动切换到其他IP了。这样的话对我们的端口映射会有影响。可以修改路由器设置，为局域网主机分配固定的私有IP地址。 进入应用管理-&gt;IP与MAC绑定，在IP与MAC映射表中，选择要绑定的IP与主机。主机的mac地址可以使用ipconfig查询。 效果 上图是在自己的电脑上开了一个web服务，可以看到，通过域名+端口可以访问到自己主机提供的这个服务。 ssh的22端口映射一到8888，在外网通过域名+端口8888可以连接到主机的ssh。 最后计划买个树莓派研究研究，在上面搭建博客或者爬虫什么的，通过上面的设置就可以直接访问树莓派啦～～美滋滋]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[建造者模式的使用]]></title>
    <url>%2F2017%2F05%2F29%2F%E5%BB%BA%E9%80%A0%E8%80%85%E6%A8%A1%E5%BC%8F%E7%9A%84%E4%BD%BF%E7%94%A8%2F</url>
    <content type="text"><![CDATA[因为一个新项目的原因，去北京呆了半个多月，所以有好长时间没有写博客了。这段时间在写代码的过程中，学习到了建造者模式的一种用法，记录下来(设计模式在平时也会用到，网上文章多如牛毛，所以没怎么写关于设计模式这方面的日志) 建造者模式建造者模式用来创建一个内部结构复杂的对象，拥有多个组成部分。建造者模式可以使用户无需知道这些组件的装配细节，只需要指定复杂对象的类型就可以得到该对象。 有的复杂对象的组装还可能有一些限制条件，比如，某些属性必须存在，某些属性的初始化需要遵从一定的顺序等等。举一个修两层楼的比方：必须打好地基才能盖第一层楼，第一层盖好后才能盖第二层。 复杂对象的创建过程被封装到一个建造者对象里面，用户可以直接使用建造者建造完毕的对象，而不必关心建造过程。 建造者模式包含上面几个对象： Builder：抽象建造者 ConcreteBuilder：具体建造者 Director：指挥者 Product：产品角色 还是用修楼那个例子来分析： Client:1234567891011package space.kyu.mode.builder;public class Client &#123; public static void main(String[] args) &#123; Builder builder = new OneBuilder(); Director director = new Director(); director.build(builder); Building building = builder.getResult(); System.out.println(building); &#125;&#125; Director:123456789package space.kyu.mode.builder;public class Director &#123; public void build(Builder builder) &#123; builder.buildFoundation(); builder.buildLayer(); builder.buildSecondLayer(); &#125;&#125; Building:12345678910111213141516171819202122232425262728293031package space.kyu.mode.builder;public class Building &#123; private int foundation;//地基深度 private int layer;//一层高度 private int secondLayer;//二层高度 public int getFoundation() &#123; return foundation; &#125; public void setFoundation(int foundation) &#123; this.foundation = foundation; &#125; public int getLayer() &#123; return layer; &#125; public void setLayer(int layer) &#123; this.layer = layer; &#125; public int getSecondLayer() &#123; return secondLayer; &#125; public void setSecondLayer(int secondLayer) &#123; this.secondLayer = secondLayer; &#125; @Override public String toString() &#123; return "Building [foundation=" + foundation + ", layer=" + layer + ", secondLayer=" + secondLayer + "]"; &#125; &#125; Builder:12345678package space.kyu.mode.builder;interface Builder &#123; void buildFoundation(); void buildLayer(); void buildSecondLayer(); Building getResult();&#125; OneBuilder:12345678910111213141516171819202122232425package space.kyu.mode.builder;public class OneBuilder implements Builder &#123; Building building = new Building(); @Override public void buildFoundation() &#123; building.setFoundation(5);对象 &#125; @Override public void buildLayer() &#123; building.setLayer(3); &#125; @Override public void buildSecondLayer() &#123; building.setSecondLayer(3); &#125; @Override public Building getResult() &#123; return building; &#125;&#125; TwoBuilder:12345678910111213141516171819202122232425package space.kyu.mode.builder;public class TwoBuilder implements Builder &#123; Building building = new Building(); @Override public void buildFoundation() &#123; building.setFoundation(4); &#125; @Override public void buildLayer() &#123; building.setLayer(2); &#125; @Override public void buildSecondLayer() &#123; building.setSecondLayer(2); &#125; @Override public Building getResult() &#123; return building; &#125;&#125; 上面的例子中： 类Client就是用户 类Director就是指挥者Director 类Builder就是抽象建造者Builder 类Building就是产品Product 类OneBuilder、TwoBuilder就是实际建造者 可以看到，我们在客户端中只需要指定实际建造者，指挥类就可以为我们生成想要的产品。我们完全不需要知道这个二层小楼的建造过程，使用者与建造过程顺利解藕。并且，如果需要不同设计方案的二层小楼，我们只需要再实现一个实际建造者，并在客户端中指定即可。而且，修改一个实际建造者不会影响到其他的实现。 建造者模式与工厂方法模式很类似，如果把上面的指挥类当作客户端的话，那么他基本上就是一个工厂方法模式了。 建造者模式 与工厂方法模式的区别就在于增加了这个指挥类，因此建造者模式适用于创建过程更加复杂的对象。 扩展其实这个扩展才是这篇日志的重点，是建造者模式的一种延伸，也是我在这段时间里面学习到的一种用法。 这个用法一开始是在使用org.apache.http.client.utils.URIBuilder的时候学到的，当时用到的时候就觉得眼前一亮，马上想到了建造者模式的Builder，而且使用了流式接口，用起来很顺畅的感觉… 后来看到了网上的一篇文章设计模式（十）——建造者模式的实践讲的就是这个用法，也是翻译了老外的一篇博客。原文已经分析的很好了，所以直接转载过来了。(作者的其他博客也是很通俗易懂的，值的学习) 以下内容引用自设计模式（十）——建造者模式的实践 我不打算深入介绍设计模式的细节内容，因为有很多这方面的文章和书籍可供参考。 本文主要关注于告诉你为什么以及在什么情况下你应该考虑使用建造者模式。 然而，值得一提的是本文中的模式和GOF中的提出的有点不一样。那种原生的模式主要侧重于抽象构造的过程以达到通过修改builder的实现来得到不同的结果的目的。本文中主要介绍的这种模式并没有那么复杂，因为我删除了不必要的多个构造函数、多个可选参数以及大量的setter/getter方法。 假设你有一个类，其中包含大量属性。就像下面的User类一样。假设你想让这个类是不可变的。 12345678public class User &#123; private final String firstName; //required private final String lastName; //required private final int age; //optional private final String phone; //optional private final String address; //optional ...&#125; 在这样的类中，有一些属性是必须的（required）而另外一些是可选的（optional）。如果你想要构造这个类的实例，你会怎么做？把所有属性都设置成final类型，然后使用构造函数初始化他们嘛？但是，如果你想让这个类的调用者可以从众多的可选参数中选择自己想要的进行设置怎么办？ 第一个可想到的方案可能是重载多个构造函数，其中有一个只初始化必要的参数，还有一个会在初始化必要的参数同时初始化所有的可选参数，还有一些其他的构造函数介于两者之间，就是一次多初始化一个可选参数。就像下面的代码： 12345678910111213141516171819public User(String firstName, String lastName) &#123; this(firstName, lastName, 0);&#125;public User(String firstName, String lastName, int age) &#123; this(firstName, lastName, age, "");&#125;public User(String firstName, String lastName, int age, String phone) &#123; this(firstName, lastName, age, phone, "");&#125;public User(String firstName, String lastName, int age, String phone, String address) &#123; this.firstName = firstName; this.lastName = lastName; this.age = age; this.phone = phone; this.address = address;&#125; 首先可以肯定的是，这样做是可以满足要求的。 当然，这种方式的缺点也是很明显的。当一个类中只有几个参数的时候还好，如果一旦类中的参数逐渐增大，那么这个类就会变得很难阅读和维护。更重要的是，这样的一个类，调用者会很难使用。我到底应该使用哪个构造方法？是包含两个参数的还是包含三个参数的？如果我没有传递值的话那些属性的默认值是什么？如果我只想对address赋值而不对age和phone赋值怎么办？遇到这种情况可能我只能调用那个参数最全的构造函数，然后对于我不想要的参数值传递一个默认值。 此外，如果多个参数的类型都相同那就很容易让人困惑，第一个String类型的参数到底是number还是address呢？ 还有没有其他方案可选择呢？我们可以遵循JaveBean规范，定义一个只包含无参数的构造方法和getter、setter方法的JavaBean。 1234567891011121314151617181920212223242526272829303132333435363738public class User &#123; private String firstName; // required private String lastName; // required private int age; // optional private String phone; // optional private String address; //optional public String getFirstName() &#123; return firstName; &#125; public void setFirstName(String firstName) &#123; this.firstName = firstName; &#125; public String getLastName() &#123; return lastName; &#125; public void setLastName(String lastName) &#123; this.lastName = lastName; &#125; public int getAge() &#123; return age; &#125; public void setAge(int age) &#123; this.age = age; &#125; public String getPhone() &#123; return phone; &#125; public void setPhone(String phone) &#123; this.phone = phone; &#125; public String getAddress() &#123; return address; &#125; public void setAddress(String address) &#123; this.address = address; &#125;&#125; 这种方式看上去很容易阅读和维护。对于调用者来说，我只需要创建一个空的对象，然后对于我想设置的参数调用setter方法设置就好了。这难道还有什么问题吗？其实存在两个问题。第一个问题是该类的实例状态不固定。如果你想创建一个User对象，该对象的5个属性都要赋值，那么直到所有的setXX方法都被调用之前，该对象都没有一个完整的状态。这意味着在该对象状态还不完整的时候，一部分客户端程序可能看见这个对象并且以为该对象已经构造完成。 这种方法的第二个不足是User类是易变的（因为没有属性是final的）。你将会失去不可变对象带来的所有优点。 幸运的是应对这种场景我们有第三种选择，建造者模式。解决方案类似如下所示： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768public class User &#123; private final String firstName; // required private final String lastName; // required private final int age; // optional private final String phone; // optional private final String address; // optional private User(UserBuilder builder) &#123; this.firstName = builder.firstName; this.lastName = builder.lastName; this.age = builder.age; this.phone = builder.phone; this.address = builder.address; &#125; public String getFirstName() &#123; return firstName; &#125; public String getLastName() &#123; return lastName; &#125; public int getAge() &#123; return age; &#125; public String getPhone() &#123; return phone; &#125; public String getAddress() &#123; return address; &#125; public static class UserBuilder &#123; private final String firstName; private final String lastName; private int age; private String phone; private String address; public UserBuilder(String firstName, String lastName) &#123; this.firstName = firstName; this.lastName = lastName; &#125; public UserBuilder age(int age) &#123; this.age = age; return this; &#125; public UserBuilder phone(String phone) &#123; this.phone = phone; return this; &#125; public UserBuilder address(String address) &#123; this.address = address; return this; &#125; public User build() &#123; return new User(this); &#125; &#125;&#125; 值得注意的几个要点: User类的构造函数是私有的，这意味着你不能在外面直接创建这个类的对象。 该类是不可变的。所有属性都是final类型的，在构造方法里面被赋值。另外，我们只为它们提供了getter方法。 builder类使用流式接口风格，让客户端代码阅读起来更容易（我们马上就会看到一个它的例子） builder的构造方法只接收必要的参数，为了确保这些属性在构造方法里赋值，只有这些属性被定义成final类型。 使用建造者模式有在本文开始时提到的两种方法的所有优点，并且没有它们的缺点。客户端代码写起来更简单，更重要的是，更易读。我听过的关于该模式的唯一批判是你必须在builder类里面复制类的属性。然而，考虑到这个事实，builder类通常是需要建造的类的一个静态类成员，它们一起扩展起来相当容易。（译者表示没明白为设定为静态成员扩展起来就容易了。设为静态成员我认为有一个好处就是可以避免出现is not an enclosing class的编译问题，创建对象时候更加方便） 现在，试图创建一个新的User对象的客户端代码看起来如何那？让我们来看一下： 12345678public User getUser() &#123; return new User.UserBuilder("Jhon", "Doe") .age(30) .phone("1234567") .address("Fake address 1234") .build();&#125; 译者注：如果UserBuilder没有设置为static的，以上代码会有编译错误。错误提示：User is not an enclosing class 以上代码看上去相当整洁。我们可以只通过一行代码就可以创建一个User对象，并且这行代码也很容易读懂。除此之外，这样还能确保无论何时你想获取该类的对象都不会是不完整的（译者注：因为创建对象的过程是一气呵成的，一旦对象创建完成之后就不可修改了）。 这种模式非常灵活，一个单独的builder类可以通过在调用build方法之前改变builder的属性来创建多个对象。builder类甚至可以在每次调用之间自动补全一些生成的字段，例如一个id或者序列号。 值得注意的是，像构造函数一样，builder可以对参数的合法性进行检查，一旦发现参数不合法可以抛出IllegalStateException异常。 但是，很重要的一点是，如果要检查参数的合法性，一定要先把参数传递给对象，然后在检查对象中的参数是否合法。其原因是因为builder并不是线程安全的。如果我们在创建真正的对象之前验证参数，参数值可能被另一个线程在参数验证完和参数被拷贝完成之间的时间修改。这段时间周期被称作“脆弱之窗”。我们的例子中情况如下： 1234567public User build() &#123; User user = new user(this); if (user.getAge() &gt; 120) &#123; throw new IllegalStateException(“Age out of range”); // thread-safe &#125; return user;&#125; 上一个代码版本是线程安全的因为我们首先创建user对象，然后在不可变对象上验证条件约束。下面的代码在功能上看起来一样但是它不是线程安全的，你应该避免这么做： 1234567public User build() &#123; if (age &gt; 120) &#123; throw new IllegalStateException(“Age out of range”); // bad, not thread-safe &#125; // This is the window of opportunity for a second thread to modify the value of age return new User(this);&#125; 建造者模式最后的一个优点是builder可以作为参数传递给一个方法，让该方法有为客户端创建一个或者多个对象的能力，而不需要知道创建对象的任何细节。为了这么做你可能通常需要一个如下所示的简单接口：123public interface Builder &#123; T build();&#125; 借用之前的User例子，UserBuilder类可以实现Builder。如此，我们可以有如下的代码： UserCollection buildUserCollection(Builder userBuilder){…} 译者注：关于这这最后一个优点的部分内容并没太看懂，希望有理解的人能过不吝赐教。]]></content>
      <categories>
        <category>编程</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>设计模式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[java线程池的使用]]></title>
    <url>%2F2017%2F05%2F08%2Fjava%E7%BA%BF%E7%A8%8B%E6%B1%A0%E7%9A%84%E4%BD%BF%E7%94%A8%2F</url>
    <content type="text"><![CDATA[在并发应用程序中，线程池是很重要的一块。读完《java并发编程实战》以及研究了一遍jdk源代码之后，总结一下线程池方面的知识~ 使用线程池的原因 无线创建线程的不足 在生产环境中，为每一个任务都分配一个线程这种方法存在一些缺陷： 线程生命周期的开销：线程的创建与销毁都会消耗大量资源，频繁创建与销毁线程会带来很大的资源开销 资源消耗：活跃的线程会消耗系统资源。如果可运行的线程数量大于可用的处理器数量，闲置的线程会占用许多内存，并且频繁的线程上下文切换也会带来很大的性能开销 稳定性：操作系统在可创建的线程数量上有一个限制。在高负载情况下，应用程序很有可能突破这个限制，资源耗尽后很可能抛出OutOfMemoryError异常 提高响应速度 任务到达时，不再需要创建线程就可以立即执行 线程池提供了管理线程的功能 比如，可以统计任务的完成情况，统计活跃线程与闲置线程的数量等 使用场景 不适用场合 依赖性任务 在线程池中，如果任务依赖于其他任务，那么可能产生死锁。比如，在单线程的Executor中，如果一个任务将另一个任务提交到同一个Executor，并且等待这个被提交任务的结果，那么通常会引发死锁 使用ThreadLocal的任务 ThreadLocal可以存储线程级变量，将变量封闭到特定的线程当中。然而使用线程池时，这些线程都会被自由的重用，在线程池的线程中不应该使用ThreadLocal在任务之间传递值。 当线程本地值的生命周期受限于任务的生命周期时，可以在线程池的线程中使用ThreadLocal，任务结束后调用ThreadLocal.remove方法将已存储的值清除。 使用线程封闭机制的任务 在单线程应用程序中，不用考虑对象的并发安全问题，他们都被很好的封闭在单个线程当中。如果将单线程的环境换成线程池，那么这些对象有可能造成并发安全问题，失去线程安全性 不同类型或运行时长差异较大的任务 不同类型任务之间很可能存在依赖，并且他们执行的时长也不相同，在线程池中运行时很有可能造成拥塞，甚至死锁 适用场合 当任务是同类型且相互独立时，线程池的性能可以达到最佳 网页服务器、文件服务器、邮件服务器，他们的请求往往是同类型且相互独立的 架构在线程池异常处理方案这篇博客中已经提到了线程池的架构，如图： Executor：异步任务执行框架的基础 123public interface Executor &#123; void execute(Runnable command);&#125; 通过使用Executor，将请求处理任务的提交与任务的实际执行解耦，只需要采用另一种不同的Executor实现，就可以改变服务器的行为。比如： 1234567891011121314// 为每个任务分配一个线程public class ThreadPerTaskExecutor implements Executor &#123; @Override public void execute(Runnable r) &#123; new Thread(r).start(); &#125;&#125;// 以同步的方式执行每个任务public class WithinThreadExecutor implements Executor&#123; @Override public void execute(Runnable r) &#123; r.run(); &#125;&#125; ExecutorService：ExecutorService扩展了Executor接口，添加了一些用于管理生命周期和任务提交的方法 12345678910111213141516171819202122232425262728293031323334public interface ExecutorService extends Executor &#123; // 生命周期管理 void shutdown(); List&lt;Runnable&gt; shutdownNow(); boolean isShutdown(); boolean isTerminated(); boolean awaitTermination(long timeout, TimeUnit unit) throws InterruptedException; // 任务提交 &lt;T&gt; Future&lt;T&gt; submit(Callable&lt;T&gt; task); &lt;T&gt; Future&lt;T&gt; submit(Runnable task, T result); Future&lt;?&gt; submit(Runnable task); &lt;T&gt; List&lt;Future&lt;T&gt;&gt; invokeAll(Collection&lt;? extends Callable&lt;T&gt;&gt; tasks) throws InterruptedException; &lt;T&gt; List&lt;Future&lt;T&gt;&gt; invokeAll(Collection&lt;? extends Callable&lt;T&gt;&gt; tasks, long timeout, TimeUnit unit) throws InterruptedException; &lt;T&gt; T invokeAny(Collection&lt;? extends Callable&lt;T&gt;&gt; tasks) throws InterruptedException, ExecutionException; &lt;T&gt; T invokeAny(Collection&lt;? extends Callable&lt;T&gt;&gt; tasks, long timeout, TimeUnit unit) throws InterruptedException, ExecutionException, TimeoutException;&#125; ExecutorService的生命周期有3中状态：运行、关闭、终止。ExecutorService在初始创建时处于运行状态。shutdown方法执行平缓的关闭过程：不再接受新任务，同时等待已提交的任务执行完成，包括在任务队列中尚未开始的任务。shutdownNow方法将尝试取消所有运行中的任务，并不再启动队列中尚未执行的任务。 所有任务完成后，ExecutorService将转入终止状态。可以调用awaitTermination来等待ExecutorService到达终止状态，或者通过轮询isTerminated来判断ExecutorService是否终止。 AbstractExecutorService ThreadPoolExecutor ScheduledThreadPoolExecutor: 线程池的实现 ThreadPoolExecutor扩展了ExecutorService接口，是线程池的具体实现。ScheduledThreadPoolExecutor支持定时以及周期性任务的执行。 ThreadPoolExecutor支持两种方式的任务提交：exec.execute(Runnable r)以及exec.submit(Runnable r)。关于任务的这两种提交方式在线程池异常处理方案已经提到过了，不再赘述。 定制线程池先来了解一下线程池的创建： 1234567ThreadPoolExecutor(int corePoolSize, int maximumPoolSize, long keepAliveTime, TimeUnit unit, BlockingQueue&lt;Runnable&gt; workQueue, ThreadFactory threadFactory, RejectedExecutionHandler handler) 以上是ThreadPoolExecutor的构造函数，看一下每个参数的含义： corePoolSize corePoolSize（线程池的基本大小）：当提交一个任务到线程池时，线程池会创建一个线程来执行任务，即使其他空闲的基本线程能够执行新任务也会创建线程，等到需要执行的任务数大于线程池基本大小时就不再创建。如果调用了线程池的prestartAllCoreThreads方法，线程池会提前创建并启动所有基本线程。 runnableTaskQueue（任务队列）：用于保存等待执行的任务的阻塞队列。 可以选择以下几个阻塞队列。 ArrayBlockingQueue：是一个基于数组结构的有界阻塞队列，此队列按 FIFO（先进先出）原则对元素进行排序。 LinkedBlockingQueue：一个基于链表结构的阻塞队列，此队列按FIFO （先进先出） 排序元素，吞吐量通常要高于ArrayBlockingQueue。静态工厂方法Executors.newFixedThreadPool()使用了这个队列。 SynchronousQueue：一个不存储元素的阻塞队列。每个插入操作必须等到另一个线程调用移除操作，否则插入操作一直处于阻塞状态，吞吐量通常要高于LinkedBlockingQueue，静态工厂方法Executors.newCachedThreadPool使用了这个队列。 PriorityBlockingQueue：一个具有优先级的无限阻塞队列。 maximumPoolSize（线程池最大大小）：线程池允许创建的最大线程数。如果队列满了，并且已创建的线程数小于最大线程数，则线程池会再创建新的线程执行任务。值得注意的是如果使用了无界的任务队列这个参数就没什么效果。 ThreadFactory：用于设置创建线程的工厂，可以通过线程工厂给每个创建出来的线程设置更有意义的名字。 RejectedExecutionHandler（饱和策略）：当队列和线程池都满了，说明线程池处于饱和状态，那么必须采取一种策略处理提交的新任务。下面会有介绍几种饱和策略。 keepAliveTime（线程活动保持时间）：线程池的工作线程空闲后，保持存活的时间。所以如果任务很多，并且每个任务执行的时间比较短，可以调大这个时间，提高线程的利用率。 TimeUnit（线程活动保持时间的单位）：可选的单位有天（DAYS），小时（HOURS），分钟（MINUTES），毫秒(MILLISECONDS)，微秒(MICROSECONDS, 千分之一毫秒)和毫微秒(NANOSECONDS, 千分之一微秒)。 设置线程池的大小线程池过大，会导致大量的线程在很少的cpu和内存资源上发生竞争，频繁的线程上下文切换也会带来额外的性能开销。线程池过小，导致许多空闲的处理器无法执行工作，降低吞吐率。 cpu密集型 对于计算密集型的任务，当系统拥有n个处理器时，将线程池大小设置为n+1通常可以实现最优利用率。 io密集型 对于包含io操作或其他阻塞操作的任务，由于线程不会一直执行，因此线程池的规模应该更大。有这么一个简单的公式： N[threads] = N[cpu] * U[cpu] * (1 + W/C) 其中，N[threads]是线程池的大小，U[cpu]是cpu的利用率，W/C是任务等待时间与任务执行时间的比值。 可以通过一些监控工具获得cpu利用率等，Runtime.getRuntime().availableProcessors()返回cpu的数目 资源依赖 如果任务还依赖一些其他的有限资源，比如数据库连接，文件句柄等，那么这些资源也会影响线程池的大小：计算每个任务对该资源的需求量，用该资源的可用总量除以每个任务的需求量，所得的结果就是线程池大小的上限。 ExecutorsExecutors提供了许多静态工厂方法来创建一个线程池： 12345678newCachedThreadPool创建一个可缓存线程池，如果线程池长度超过处理需要，可灵活回收空闲线程，若无可回收，则新建线程。newFixedThreadPool创建一个定长线程池，可控制线程最大并发数，超出的线程会在队列中等待。newSingleThreadExecutor创建一个单线程化的线程池，它只会用唯一的工作线程来执行任务，保证所有任务按照指定顺序(FIFO, LIFO, 优先级)执行。newScheduledThreadPool创建一个定长线程池，支持定时及周期性任务执行。 具体情况可以结合Executors源码和ThreadPoolExecutor的构造函数查看。我们也可以模仿Executors的这几个工厂方法来定制自己的线程池执行策略。 扩展ThreadPoolExecutor 在线程池异常处理方案这篇总结曾经提到重写ThreadPoolExecutor的afterExecute方法来处理未检测异常，这就是扩展ThreadPoolExecutor的一个例子。除此之外，还可以在这些方法中添加日志、计时、监视等功能。 线程池完成关闭操作后会调用方法terminated。terminated可以用来释放Executor在其生命周期中分配的各种资源，以及执行发送通知、记录日志等操作。 下面编写一个利用beforeExecute、afterExecute和terminated添加日志记录和统计信息收集的扩展ThreadPoolExecutor。 123456789101112131415161718192021222324252627282930313233343536373839404142public class TimingThreadPool extends ThreadPoolExecutor&#123; // 使用ThreadLocal存储任务起始时间，在beforeExecute设置起始时间，在afterExecute中可以看到这个值 private final ThreadLocal&lt;Long&gt; startTime = new ThreadLocal&lt;&gt;(); private final Logger logger = Logger.getLogger(TimingThreadPool.class.getName()); private final AtomicLong numTasks = new AtomicLong(); private final AtomicLong totalTime = new AtomicLong(); public TimingThreadPool(int corePoolSize, int maximumPoolSize, long keepAliveTime, TimeUnit unit, BlockingQueue&lt;Runnable&gt; workQueue, ThreadFactory threadFactory, RejectedExecutionHandler handler) &#123; super(corePoolSize, maximumPoolSize, keepAliveTime, unit, workQueue, threadFactory, handler); &#125; @Override protected void beforeExecute(Thread t, Runnable r) &#123; super.beforeExecute(t, r); logger.fine(String.format("Thread %s: start %s", t, r)); startTime.set(System.nanoTime()); &#125; @Override protected void afterExecute(Runnable r, Throwable t) &#123; try &#123; long endTime = System.nanoTime(); long taskTime = endTime - startTime.get(); numTasks.incrementAndGet(); totalTime.addAndGet(taskTime); logger.fine(String.format("Thread %s: end %s, time=%dns", t, r, taskTime)); &#125; finally &#123; super.afterExecute(r, t); &#125; &#125; @Override protected void terminated() &#123; try &#123; logger.fine(String.format("Terminated: avg time=%dns", totalTime.get()/numTasks.get())); &#125; finally &#123; super.terminated(); &#125; &#125;&#125; 扩展ThreadPoolExecutor的newTaskFor方法可以修改通过submit方法返回的默认Future实现FutureTask为自己的实现。在我们自己实现Future的类中可以针对任务做一些操作，比如定制任务的取消行为： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748public class CacellingExecutor extends ThreadPoolExecutor &#123; public CacellingExecutor(int corePoolSize, int maximumPoolSize, long keepAliveTime, TimeUnit unit, BlockingQueue&lt;Runnable&gt; workQueue, ThreadFactory threadFactory, RejectedExecutionHandler handler) &#123; super(corePoolSize, maximumPoolSize, keepAliveTime, unit, workQueue, threadFactory, handler); &#125; @Override protected &lt;T&gt; RunnableFuture&lt;T&gt; newTaskFor(Callable&lt;T&gt; callable) &#123; if (callable instanceof CancellableTask) &#123; return ((CancellableTask&lt;T&gt;)callable).newTask(); &#125; return super.newTaskFor(callable); &#125;&#125;interface CancellableTask&lt;T&gt; extends Callable&lt;T&gt; &#123; void cancel(); RunnableFuture&lt;T&gt; newTask();&#125;abstract class SocketUsingTask&lt;T&gt; implements CancellableTask&lt;T&gt; &#123; private Socket socket; public SocketUsingTask(Socket socket) &#123; this.socket = socket; &#125; @Override public void cancel() &#123;在并发应用程序中，线程池是很重要的一块。读完《java并发编程实战》以及研究了一遍jdk源代码之后，总结一下线程池方面的知识~ try &#123; this.socket.close(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125; @Override public RunnableFuture&lt;T&gt; newTask() &#123; return new FutureTask&lt;T&gt;(this)&#123; @Override public boolean cancel(boolean mayInterruptIfRunning) &#123; try &#123; SocketUsingTask.this.cancel(); &#125; finally &#123; return super.cancel(mayInterruptIfRunning); &#125; &#125; &#125;; &#125;&#125; 异常处理异常处理这部分，在前面的博客中已经总结过了：线程池异常处理方案 饱和策略当线程池达到饱和以后(maximumPoolSzie)，饱和策略开始发挥作用。ThreadPoolExecutor的饱和策略可以通过setRejectedExecutionHandler来修改。当某个任务被提交到一个已经关闭的Executor时，也会用到饱和策略。jdk提供了几种不同的RejectedExecutionHandler实现： AbortPolicy 12345678public static class AbortPolicy implements RejectedExecutionHandler &#123; public AbortPolicy() &#123; &#125; public void rejectedExecution(Runnable r, ThreadPoolExecutor e) &#123; throw new RejectedExecutionException("Task " + r.toString() + " rejected from " + e.toString()); &#125; &#125; AbortPolicy是默认的饱和策略，该饱和策略将抛出未检查的RejectedExecutionException。调用者可以处理这个异常。 CallerRunsPolicy 12345678public static class CallerRunsPolicy implements RejectedExecutionHandler &#123; public CallerRunsPolicy() &#123; &#125; public void rejectedExecution(Runnable r, ThreadPoolExecutor e) &#123; if (!e.isShutdown()) &#123; r.run(); &#125; &#125; &#125; CallerRunsPolicy将任务回退到调用者，他不会在线程池的某个线程中提交任务，而是在调用execute的线程中运行，从而降低新任务的流量。 DiscardPolicy 12345public static class DiscardPolicy implements RejectedExecutionHandler &#123; public DiscardPolicy() &#123; &#125; public void rejectedExecution(Runnable r, ThreadPoolExecutor e) &#123; &#125; &#125; DiscardPolicy会悄悄抛弃任务，什么也不做。 DiscardOldestPolicy 123456789public static class DiscardOldestPolicy implements RejectedExecutionHandler &#123; public DiscardOldestPolicy() &#123; &#125; public void rejectedExecution(Runnable r, ThreadPoolExecutor e) &#123; if (!e.isShutdown()) &#123; e.getQueue().poll(); e.execute(r); &#125; &#125; &#125; DiscardOldestPolicy会抛弃下一个将被执行的任务，然后重新尝试提交任务。 其他 CompletionService 如果向Executor提交了一组计算任务，并希望在计算完成后获取结果，那么可以保留与每个任务关联的Future，然后轮询这些future的get方法，判断任务是否完成。这种方法虽然可行，但是有些繁琐。 CompletionService将Executor和BlockingQueue的功能融合在一起，可以将任务提交给他执行，然后使用类似于队列的take或poll方法获取已完成结果。 ExecutorCompletionService 实现了CompletionService，他的实现很简单，在构造函数中创建一个BlockingQueue来保存计算完成的结果。当提交某个任务时，该任务首先包装成为一个QueueingFuture,这是FutureTask的一个子类，他改写了done方法，将结果放入BlockingQueue中。ExecutorCompletionService的take和poll方法委托给了BlockingQueue。 ScheduledThreadPoolExecutor ScheduledThreadPoolExecutor以延迟或定时的方式执行任务，类似于Timer。由于Timer的一些缺陷，可以使用ScheduledThreadPoolExecutor来代替Timer。 Timer在执行所有的定时任务时只会创建一个线程，如果某个任务执行时间过长，就会破坏其他TimerTask的定时准确性。TimerTask抛出异常后，Timer线程也不会捕获这个异常，从而终止定时线程。尚未执行的TimerTask不会再执行，新的任务也不会被调度。 参考java并发编程实战 聊聊并发（三）——JAVA线程池的分析和使用]]></content>
      <categories>
        <category>编程</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>多线程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[如何炒肉]]></title>
    <url>%2F2017%2F05%2F07%2F%E5%A6%82%E4%BD%95%E7%82%92%E8%82%89%2F</url>
    <content type="text"><![CDATA[这个炒肉是跟我妈学的，炒菜或者调面均可，很好吃～ 图比较丑，就不上了… 原料里脊肉、醋、生姜、葱、蒜、酱油、花椒面、盐、味精、清水 做法 将里脊肉洗净，切成小块或肉片均可 生姜切片、葱切段、蒜切片备用 锅中倒油，放入备用的里脊肉翻炒 倒入少许醋，继续翻炒 片刻后加入备用的生姜、葱蒜，花椒面(花椒水更好)、味精以及少许盐继续翻炒 倒入适量酱油，翻炒片刻后加入适量清水 小火，待水被熬的差不多时起锅，倒入碗中，完成]]></content>
      <categories>
        <category>生活</category>
      </categories>
      <tags>
        <tag>食物</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[凉拌黄瓜]]></title>
    <url>%2F2017%2F05%2F07%2F%E5%87%89%E6%8B%8C%E9%BB%84%E7%93%9C%2F</url>
    <content type="text"><![CDATA[天气热起来了，突然想吃黄瓜了，打电话给我妈问了凉拌黄瓜的做法，吃起来不错~ 忘记拍照了… 原料黄瓜、拉皮(粉皮)、醋、生抽、葱、蒜、盐、味精、辣椒面、香油 做法 黄瓜洗净切片，葱切片，蒜切末(或蒜水) 黄瓜，拉皮(粉皮)放到碗中，将葱、蒜末倒入(蒜水更佳) 放入盐适量，香油适量，少许味精，生抽适量 加入香醋(根据个人口味，喜欢吃醋多加)，喜欢吃辣的可以放入适量辣椒面 调匀，品尝口味后可以再适当的加入上述材料，大功告成]]></content>
      <categories>
        <category>生活</category>
      </categories>
      <tags>
        <tag>食物</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[java任务取消]]></title>
    <url>%2F2017%2F05%2F02%2Fjava%E4%BB%BB%E5%8A%A1%E5%8F%96%E6%B6%88%2F</url>
    <content type="text"><![CDATA[最近在用思维导图做读书笔记，虽然感觉没有网上所说的那么神奇，但是用来做笔记还是可以的。总结梳理了一下java取消任务执方面的一些内容，也是《java并发编程实战》的读书笔记。 取消原因取消一个任务执行的理由有很多，通常有以下几个 用户请求取消 通常用户点击“取消”按钮发出取消命令 有时间限制的操作 计时任务，超时时就会取消任务执行并返回 应用程序逻辑 比如有多个任务对一个问题进行分解和搜索解决方案，如果其中某个任务找到解决方案，其他并行的任务就可以取消了 发生错误 比如爬虫程序下载网页到本地硬盘，如果盘满了之后爬取任务应该被取消 关闭 程序或服务被关闭，则正在执行的任务也应该取消，而不是继续执行 取消线程执行任务的取消执行，其实最后都会落到线程的终止上(任务都是由线程来执行)。在java中没有一种安全的抢占式方法来终止线程(Thread.stop 是不安全的终止线程执行的方法，已经废弃掉了)，所以需要一种很好的协作机制来平滑的关闭任务。 自然结束中断线程的最好方法是让代码自然执行到结束，而不是从外部强制打断他。为此可以设置一个“任务取消标志”，任务代码会定期的查看这个标志，如果发现标志被设定了，则任务提前结束。 12345678910111213141516171819202122public class SomeJob &#123; private List&lt;String&gt; list = new ArrayList&lt;&gt;(); private volatile boolean canceled = false; public void run() &#123; while (!canceled) &#123; String res = getResult(); synchronized (this) &#123; list.add(res); &#125; &#125; &#125; private String getResult() &#123; // do something... return ""; &#125; public void cancel() &#123; this.canceled = true; &#125;&#125; 上面的代码中，设置了一个volatile类型的变量canceled，所以其他线程对这个变量的修改对所有线程都是可见的(可见性)。每次循环执行某个操作之前都会检查这个变量是否被其他线程设置为true，如果为true则提前退出。 这是很常见的一种取消任务执行的手段，但是也有他的弊端，比如： 1234567891011121314151617181920212223242526272829import java.util.concurrent.BlockingQueue;import java.util.concurrent.LinkedBlockingQueue;public class SomeJob &#123; private BlockingQueue&lt;String&gt; list = new LinkedBlockingQueue&lt;&gt;(100); private volatile boolean canceled = false; public void run() &#123; try &#123; while (!canceled) &#123; String res = getResult(); synchronized (this) &#123; list.put(res); &#125; &#125; &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; private String getResult() &#123; // do something... return ""; &#125; public void cancel() &#123; this.canceled = true; &#125;&#125; 上面将list替换为支持阻塞的BlockingQueue，他是一个有界队列，当调用list的put操作时，如果队列已经填满，那么将会一直阻塞直到队列有空余位置为止。如果恰好执行put操作是阻塞了，此时我们调用了cancel方法，那么什么时候检查canceled标志是不确定的，响应性很差，极端情况下，有可能永远也不会去再下一次轮询中检查canceled标志，试想我们执行了取消后，消费队列的线程已经停止，此时put操作又阻塞，那么将会一直阻塞下去，这个线程失去响应。 线程中断通过线程自己的中断机制，可以解决上述问题。 每个线程都有一个boolean类型的变量，表示中断状态。当中断线程时，这个线程的中断状态将被设置为true。在Thread中有三个方法可以设置或访问这个变量： Thread.interrupt: 中断目标线程 Thread.isInterrupted: 返回线程的中断状态 Thread.interrupted: 清除线程的中断状态，并返回之前的值 调用interrupt并不意味着立即停止目标线程正在进行的任务，而只是将中断状态设置为true：他并不会正真中断一个正在运行的线程，而只是发出了一种中断请求，线程可以看到这个中断状态，然后在合适的时刻处理。 中断请求响应中断阻塞上面提到的中断请求，有些方法会处理这些请求，从而结束现在正在进行的任务。像上面代码中的BlockingQueue.put方法，当他在阻塞状态时，依然能够发现中断请求并提前返回，所以解决上面代码中的问题只需要对执行代码的线程thread调用thread.interrupt方法，BlockingQueue.put就可以从阻塞状态中恢复回来，从而完成取消。类似这样的支持中断的阻塞就叫做响应中断阻塞，主要有以下几个： Thread.sleep Object.wait Thread.join 这些支持中断的阻塞在响应中断时执行的操作包括： 清除中断状态 抛出InterruptedException，表示阻塞操作由于中断而提前结束 jvm并不能保证这些阻塞方法检测到中断的速度，但在实际情况中响应速度还是很快的。 利用线程本身的中断状态作为取消机制，我们可以将上面的代码再改造一下： 12345678910111213141516171819202122232425public class SomeJob &#123; private BlockingQueue&lt;String&gt; list = new LinkedBlockingQueue&lt;&gt;(); public void run() &#123; try &#123; while (!Thread.currentThread().isInterrupted()) &#123; String res = getResult(); synchronized (this) &#123; list.put(res); &#125; &#125; &#125; catch (InterruptedException e) &#123; System.out.println("任务被取消..."); &#125; &#125; private String getResult() &#123; // do something... return ""; &#125; public void cancel(Thread thread) &#123; thread.interrupt(); &#125;&#125; 任务代码在每次轮询操作前检查当前线程的状态，如果被中断了就退出。cancel方法是对当前执行任务的线程进行中断。 注意，调用cancel方法的是另一线程，传入的线程实例则是执行run方法的工作者线程，故在执行cancel方法后run方法可以检测到中断。 不响应中断阻塞并非所有的阻塞方法和阻塞机制都能够响应中断请求，比如正在read或write上阻塞的socket就不会响应中断，调用线程的interrupt方法只能设置线程的中断状态，除此以外没有任何作用，因为这些阻塞方法并不会去检查线程中断状态，也不会处理中断。这些阻塞就是不响应中断阻塞。主要有以下几个： java.io包中的同步socket io: 从socket中获取的InputStream和OutputStream中的read或write方法都不会响应中断，解决办法是关闭这个socket，使得正在执行read或write方法而被阻塞的线程抛出一个SocketException java.io包中的同步IO: 当中断一个正在InterruptibleChannel上等待的线程时，将抛出ClosedByInterruptException并关闭链路。 Selector的异步IO: 如果一个线程在调用Selector.select方法时阻塞了，那么调用close或wakeup方法会使线程抛出ClosedSelectorException并返回 获得某个锁: 如果一个线程由于等待某个内置锁而阻塞，将无法响应中断。Lock类中提供了lockInterruptibly方法，该方法允许在等待一个锁的同时仍能响应中断。(BlockingQueue.put可以响应中断缘于此) 一个简单的例子，取消socket任务： 12345678910111213141516171819202122232425262728293031323334353637public class CanceledThread extends Thread &#123; private final Socket socket; private final InputStream stream; public CanceledThread(Socket socket) throws IOException &#123; this.socket = socket; this.stream = socket.getInputStream(); &#125; @Override public void interrupt() &#123; try &#123; socket.close(); &#125; catch (Exception e) &#123; // do nothing &#125; finally &#123; super.interrupt(); &#125; &#125; @Override public void run() &#123; try &#123; byte[] bytes = new byte[1024]; while (true) &#123; int count = stream.read(bytes); if (count &lt; 0) &#123; break; &#125; else if (count &gt; 0) &#123; // 处理读到 bytes &#125; &#125; &#125; catch (Exception e) &#123; // 可能捕捉到InterruptedException 或 SocketException // 线程退出 &#125; &#125;&#125; 在上面的代码中，即使socket的stream在read过程中阻塞了，也可以中断阻塞并返回。 中断处理上文提到，当调用可中断的阻塞库函数时，会抛出InterruptedException，这个异常会出现在我们的任务代码中(任务代码调用了这些阻塞方法)，有三种方法处理这个异常： 不处理，或者在捕捉到异常后打印日志以及做一些资源回收工作 确定我们的任务代码可以这么做时才这么做。这意味这这个任务完全可以在这个线程中取消，不必再向上层报告或需要更上层的代码处理。 传递异常，从而使你的方法也成为可中断的阻塞方法 简单的将异常抛出，让上层代码处理，这意味着需要上层代码再做一些资源回收等工作。 恢复中断状态，从而使调用栈中的上层代码能够对其进行处理 如果不想或无法(Runnable中)传递InterruptedException时，可以通过再次调用interrupt来恢复中断状态。此时上层代码就可以捕捉到这个中断，从而作出处理。 ThreadPoolExcutor就是处理中断的一个例子：当其拥有的工作者线程检测到中断时，他会检查线程池是否正在关闭。如果是，他会在结束前执行一些线程清理工作，否则他可能创建一个新线程将线程池恢复到合理的规模。 取消任务终止线程池线程池的生命周期是由ExcutorService控制的。ExcutorService提供了两种关闭线程池的方法： shutdownNow 强行关闭线程池，首先关闭当前正在执行的任务，然后返回所有尚未启动的任务清单(在任务队列当中的) 关闭速度快，但是有风险，正在执行中的任务可能在执行一半的时候被结束 shutdown 正常关闭线程池，一直等到队列中的所有任务都执行完后才关闭，在此期间不接受新任务 关闭速度慢，却更加安全 终止基于线程的服务在写程序时往往会用到日志，在代码中插入println也是一种日志行为。为了避免由于日志为服务带来性能损耗和并发风险(多个线程同时打印日志有可能引发并发问题)，我们往往将打印日志任务放到某个队列中，由专门的线程从队列中取出任务进行打印。下面设计这样一个日志服务： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657public class LogService &#123; private final BlockingQueue&lt;String&gt; queue; private final PrintWriter writer; private final LoggerThread thread; private boolean isShutDown = false; private int reservations = 0; public LogService(PrintWriter writer) &#123; this.writer = writer; thread = new LoggerThread(); queue = new LinkedBlockingQueue&lt;&gt;(); &#125; public void shutdown() &#123; synchronized (this) &#123; isShutDown = true; &#125; thread.interrupt(); &#125; public void log(String msg) throws InterruptedException &#123; synchronized (this) &#123; if (isShutDown) &#123; throw new IllegalStateException("日志服务已经关闭..."); &#125; reservations ++; &#125; queue.put(msg); &#125; class LoggerThread extends Thread &#123; @Override public void run() &#123; try &#123; while (true) &#123; try &#123; synchronized (LogService.this) &#123; if (isShutDown &amp;&amp; reservations == 0) &#123; break; &#125; String msg = queue.take(); synchronized (LogService.this) &#123; reservations--; &#125; writer.println(msg); &#125; &#125; catch (InterruptedException e) &#123; // retry &#125; &#125; &#125; finally &#123; writer.close(); &#125; &#125; &#125;&#125; 当关闭日志服务时，日志服务不再会接收新的日志打印请求，并且会将队列中剩余的所有打印任务执行完毕，最后结束。如果此时日志打印线程恰好在queue.take方法中阻塞了，关闭日志服务时也能很好的从阻塞中恢复过来，结束服务。]]></content>
      <categories>
        <category>编程</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>多线程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[线程池异常处理方案]]></title>
    <url>%2F2017%2F04%2F26%2F%E7%BA%BF%E7%A8%8B%E6%B1%A0%E5%BC%82%E5%B8%B8%E5%A4%84%E7%90%86%E6%96%B9%E6%A1%88%2F</url>
    <content type="text"><![CDATA[最近一直在看《java并发编程实战》这本书，之前看过一点，放弃了，现在重新拿过来学习一下。这本书是老外写的，我买的是翻译版。不得不吐槽这本书的翻译，句子晦涩难懂，而且已经读到有好几处错误，差不多跟谷歌翻译一个水平…但是没办法，谁让咱英语差呢？多读几遍，结合jdk源码也能看个大概… 执行多线程并发任务的时候，如果任务类型相同，一般会考虑使用线程池，一方面利用了并发的优势，一方面避免创建大量线程得不偿失。使用线程池执行的任务一般是我们自己的代码，或者第三方的代码，有没有想过，如果这些代码抛出异常时，线程池会怎么处理呢？如果不处理又会有什么影响？ 异常的影响Java 理论与实践: 嗨，我的线程到哪里去了？这篇文章列举了一个由于RuntimeException引发的线程泄漏问题： 考虑这样一个假设的中间件服务器应用程序，它聚合来自各种输入源的消息，然后将它们提交到外部服务器应用程序，从外部应用程序接收响应并将响应路由回适当的输入源。对于每个输入源，都有一个以其自己的方式接受其输入消息的插件（通过扫描文件目录、等待套接字连接、轮询数据库表等）。插件可以由第三方编写，即使它们是在服务器 JVM 上运行的。这个应用程序拥有（至少）两个内部工作队列 ― 从插件处接收的正在等待被发送到服务器的消息（“出站消息”队列），以及从服务器接收的正在等待被传递到适当插件的响应（“入站响应”队列）。通过调用插件对象上的服务例程 incomingResponse() ，消息被路由到最初发出请求的插件。 从插件接收消息后，就被排列到出站消息队列中。由一个或多个从队列读取消息的线程处理出站消息队列中的消息、记录其来源并将它提交给远程服务器应用程序（假定通过 Web 服务接口）。远程应用程序最终通过 Web 服务接口返回响应，然后我们的服务器将接收的响应排列到入站响应队列中。一个或多个响应线程从入站响应队列读取消息并将其路由到适当的插件，从而完成往返“旅程”。在这个应用程序中，有两个消息队列，分别用于出站请求和入站响应，不同的插件内可能也有另外的队列。我们还有几种服务线程，一个从出站消息队列读取请求并将其提交给外部服务器，一个从入站响应队列读取响应并将其路由到插件，在用于向套接字或其它外部请求源提供服务的插件中可能也有一些线程。 如果这些线程中的一个（如响应分派线程）消失了，将会发生什么？因为插件仍能够提交新消息，所以它们可能不会立即注意到某些方面出错了。消息仍将通过各种输入源到达，并通过我们的应用程序提交到外部服务。因为插件并不期待立即获得其响应，因此它仍没有意识到出了问题。最后，接收的响应将排满队列。如果它们存储在内存中，那么最终将耗尽内存。即使不耗尽内存，也会有人在某个时刻发现响应得不到传递 ― 但这可能需要一些时间，因为系统的其它方面仍能正常发挥作用。 当主要的任务处理方面由线程池而不是单个线程来处理时，对于偶然的线程泄漏的后果有一定程度的保护，因为一个执行得很好的八线程的线程池，用七个线程完成其工作的效率可能仍可以接受。起初，可能没有任何显著的差异。但是，系统性能最终将下降，虽然这种下降的方式不易被察觉。 服务器应用程序中的线程泄漏问题在于不是总是容易从外部检测它。因为大多数线程只处理服务器的部分工作负载，或可能仅处理特定类型的后台任务，所以当程序实际上遭遇严重故障时，在用户看来它仍在正常工作。这一点，再加上引起线程泄漏的因素并不总是留下明显痕迹，就会引起令人惊讶甚或使人迷惑的应用程序行为。 我们在使用线程池处理并行任务时，在线程池的生命周期当中，将通过某种抽象机制(Runnable)调用许多未知的代码，这些代码有可能是我们自己写的，也有可能来自第三方。任何代码都有可能抛出一个RuntimeException，如果这些提交的Runnable抛出了RuntimeException，线程池可以捕获他，线程池有可能会创建一个新的线程来代替这个因为抛出异常而结束的线程，也有可能什么也不做(这要看线程池的策略)。即使不会造成线程泄漏，我们也会丢失这个任务的执行情况，无法感知任务执行出现了异常。 所以，有必要处理提交到线程池运行的代码抛出的异常。 如何处理异常简单了解线程池 上面是我画的思维导图 先介绍一下jdk中线程池的实现： Executor定义了一个通用的并发任务框架，即通过execute方法执行一个任务。 ExecutorService定义了并发框架(线程池)的生命周期。 AbstractExecutorService、ThreadPoolExecutor、ScheduledThreadPoolExecutor实现了并发任务框架(线程池)。其中ScheduledThreadPoolExecutor支持定时及周期性任务的执行。 Executors相当于一个线程池工厂类，返回了不同执行策略的线程池对象。 我们一般使用Executors.new…方法来得到某种线程池： 1234567891011newCachedThreadPool创建一个可缓存线程池，如果线程池长度超过处理需要，可灵活回收空闲线程，若无可回收，则新建线程。newFixedThreadPool创建一个定长线程池，可控制线程最大并发数，超出的线程会在队列中等待。newSingleThreadExecutor创建一个单线程化的线程池，它只会用唯一的工作线程来执行任务，保证所有任务按照指定顺序(FIFO, LIFO, 优先级)执行。newScheduledThreadPool创建一个定长线程池，支持定时及周期性任务执行。 其中，前三者返回ExecutorService实例，他们的实现为ThreadPoolExecutor或其包装类；newScheduledThreadPool返回的是ScheduledExecutorService实例，他的实现为ScheduledThreadPoolExecutor或其包装类。 1ExecutorService exec = Executors.newFixedThreadPool(8); 以上述代码为例，得到ExecutorService实例后，我们可以通过两种方式提交任务(Runnable): exec.execute(runnable) exec.submit(runnable) 对于这两种不同的任务提交方式，我们有不同的异常处理办法。 exec.submit(runnable) 使用exec.submit(runnable)这种方式提交任务时，submit方法会将我们的Runnable包装为一个RunnableFuture对象，这个对象实际上是FutureTask实例，然后将这个FutureTask交给execute方法执行。 Future用来管理任务的生命周期，将Future实例提交给异步线程执行后，可以调用Future.get方法获取任务执行的结果。我们知道Runnable执行是没有返回结果的，那么这个结果是怎么来的？ 可以看到，在FutureTask的构造方法中，将Runnable包装成了一个Callable类型的对象。 FutureTask的run方法中，调用了callable对象的call方法，也就调用了我们传入的Runnable对象的run方法。可以看到，如果代码(Runnable)抛出异常，会被捕获并且把这个异常保存下来。 可以看到，在调用get方法时，会将保存的异常重新抛出。所以，我们在使用submit方法提交任务的时候，利用返回的Future对象，通过他的get方法可以得到任务运行中抛出的异常，然后针对异常做一些处理。 由于我们在调用submit时并没有给Runnable指定返回结果，所以在将Runnable包装为Callable的时候，会传入一个null，故get方法返回一个null. 当然，我们也可以直接传入Callable类型的任务，这样就可以获取任务执行返回结果，并且得到任务执行抛出的异常。 这就是使用线程池时处理任务中抛出异常的第一种方法：使用ExecutorService.submit执行任务，利用返回的Future对象的get方法接收抛出的异常，然后进行处理 exec.execute(runnable)利用Future.get得到任务抛出的异常的缺点在于，我们需要显式的遍历Future，调用get方法获取每个任务执行抛出的异常，然后处理。 很多时候我们仅仅是使用exec.execute(runnable)这种方法来提交我们的任务。这种情况下任务抛出的异常如何处理呢？ 在使用exec.execute(runnable)提交任务的时候(submit其实也是调用execute方法执行)，我们的任务最终会被一个Worker对象执行。这个Worker内部封装了一个Thread对象，这个Thread就是线程池的工作者线程。工作者线程会调用runWorker方法来执行我们提交的任务：(代码比较长，就直接粘过来了) 12345678910111213141516171819202122232425262728293031323334353637383940414243final void runWorker(Worker w) &#123; Thread wt = Thread.currentThread(); Runnable task = w.firstTask; w.firstTask = null; w.unlock(); // allow interrupts boolean completedAbruptly = true; try &#123; while (task != null || (task = getTask()) != null) &#123; w.lock(); // If pool is stopping, ensure thread is interrupted; // if not, ensure thread is not interrupted. This // requires a recheck in second case to deal with // shutdownNow race while clearing interrupt if ((runStateAtLeast(ctl.get(), STOP) || (Thread.interrupted() &amp;&amp; runStateAtLeast(ctl.get(), STOP))) &amp;&amp; !wt.isInterrupted()) wt.interrupt(); try &#123; beforeExecute(wt, task); Throwable thrown = null; try &#123; task.run(); &#125; catch (RuntimeException x) &#123; thrown = x; throw x; &#125; catch (Error x) &#123; thrown = x; throw x; &#125; catch (Throwable x) &#123; thrown = x; throw new Error(x); &#125; finally &#123; afterExecute(task, thrown); &#125; &#125; finally &#123; task = null; w.completedTasks++; w.unlock(); &#125; &#125; completedAbruptly = false; &#125; finally &#123; processWorkerExit(w, completedAbruptly); &#125;&#125; 上面代码的基本意思就是不停的从任务队列中取出任务执行，如果任务代码(task.run)抛出异常，会被最内层的try--catch块捕获，然后重新抛出。注意到最里面的finally块，在重新抛出异常之前，要先执行afterExecute方法，这个方法的默认实现为空，即什么也不做。我们可以在这个方法上做点文章，这就是我们的第二种方法，重写ThreadPoolExecutor.afterExecute方法，处理传递到afterExecute方法中的异常： 12345678910111213141516171819class ExtendedExecutor extends ThreadPoolExecutor &#123; // ... protected void afterExecute(Runnable r, Throwable t) &#123; super.afterExecute(r, t); if (t == null &amp;&amp; r instanceof Future&lt;?&gt;) &#123; try &#123; Object result = ((Future&lt;?&gt;) r).get(); &#125; catch (CancellationException ce) &#123; t = ce; &#125; catch (ExecutionException ee) &#123; t = ee.getCause(); &#125; catch (InterruptedException ie) &#123; Thread.currentThread().interrupt(); // ignore/reset &#125; &#125; if (t != null) System.out.println(t); &#125; &#125; When actions are enclosed in tasks (such as FutureTask) either explicitly or via methods such as submit, these task objects catch and maintain computational exceptions, and so they do not cause abrupt termination, and the internal exceptions are not passed to this method. If you would like to trap both kinds of failures in this method, you can further probe for such cases, as in this sample subclass that prints either the direct cause or the underlying exception if a task has been aborted: 上面是java doc给出的建议。可以看到，代码中还处理了task是FutureTask的情况。回想一下submit方式提交任务的情况： 在submit方法中，我们传入的Runnable/Callable(要执行的任务)被封装为FutureTask对象，交给execute方法执行 经过一系列操作，提交的FutureTask对象被Worker对象中的工作者线程所执行，也就是runWorker方法 此时的代码运行情况：runWorker-&gt;submit方法封装的FutureTask的run方法-&gt;我们提交的Runnable的run方法 此时从我们提交的Runnable的run方法中抛出了一个未检测异常RunnableException，被FutureTask的run方法捕获 FutureTask的run方法捕获异常后保存，不再重新抛出。同时意味着run方法执行结束。 runWorker方法没有检测到异常，task.run当作正常运行结束。但是还是会执行afterExecute方法。 经过这样的梳理，上面的代码为什么这么写就一目了然了。 上面已经提到了两种解决任务代码抛出未检测异常的方案。接下来是第三种： 当一个线程因为未捕获的异常而退出时，JVM会把这个事件报告给应用提供的UncaughtExceptionHandler异常处理器，如果没有提供任何的异常处理器，那么默认的行为就是将堆栈信息输送到System.err。 看一下上面的runWorker方法，如果task.run(任务代码)抛出了异常，异常会层层抛出，最终导致这个线程退出。此时这个抛出的异常就会传递到UncaughtExceptionHandler实例当中，由uncaughtException(Thread t,Throwable e)这个方法处理。 于是就有了第三种解决任务代码抛出异常的方案：为工作者线程设置UncaughtExceptionHandler，在uncaughtException方法中处理异常 注意，这个方案不适用与使用submit方式提交任务的情况，原因上面也提到了，FutureTask的run方法捕获异常后保存，不再重新抛出，意味着runWorker方法并不会捕获到抛出的异常，线程也就不会退出，也不会执行我们设置的UncaughtExceptionHandler。 如何为工作者线程设置UncaughtExceptionHandler呢？ThreadPoolExecutor的构造函数提供一个ThreadFactory，可以在其中设置我们自定义的UncaughtExceptionHandler，这里不再赘述。 至于第四中方案，就很简单了：在我们提供的Runnable的run方法中捕获任务代码可能抛出的所有异常，包括未检测异常。这种方法比较简单，也有他的局限性，不够灵活，我们的处理被局限在了线程代码边界之内。 总结通过上面的分析我们得到了四种解决任务代码抛异常的方案： 在我们提供的Runnable的run方法中捕获任务代码可能抛出的所有异常，包括未检测异常 使用ExecutorService.submit执行任务，利用返回的Future对象的get方法接收抛出的异常，然后进行处理 重写ThreadPoolExecutor.afterExecute方法，处理传递到afterExecute方法中的异常 为工作者线程设置UncaughtExceptionHandler，在uncaughtException方法中处理异常 要注意的是，使用最后一种方案时，无法处理以submit的方式提交的任务。]]></content>
      <categories>
        <category>编程</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>多线程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[土豆烧肉]]></title>
    <url>%2F2017%2F04%2F19%2F%E5%9C%9F%E8%B1%86%E7%83%A7%E8%82%89%2F</url>
    <content type="text"><![CDATA[原料土豆、五花肉、姜片、葱、酱油、料酒、盐、青椒、白糖、胡椒面 做法 五花肉切块洗净，土豆洗净、去皮，然后切块放到水中备用。青椒切片、葱切段、姜切片备用。 锅中水烧开，放两片姜片，倒入洗净的肉块，汆烫两分钟(注意时间不要太长)，捞出肉块沥干备用 锅中倒油，油七成热后加入加入姜片、葱段、胡椒面爆香，然后倒入肉块煸炒(注意时间不要太长，否则肉会变老) 倒入酱油、精盐、料酒，倒入土豆青椒和肉块一起翻炒几下 加入清水(高汤)刚好没过肉块，加入两小勺盐，适当的撒一点白糖，煮沸后转小火，盖上锅盖烧20分钟 汤锅中汤汁差不多的时候，大火收汁，撒点葱末装盘 成品]]></content>
      <categories>
        <category>生活</category>
      </categories>
      <tags>
        <tag>食物</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[maven学习笔记(二)]]></title>
    <url>%2F2017%2F04%2F19%2Fmaven%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B02%2F</url>
    <content type="text"><![CDATA[依赖dependency标签可以声明以下一些元素： 1234567891011&lt;dependency&gt; &lt;groupId&gt;...&lt;/groupId&gt; &lt;artifactId&gt;...&lt;/artifactId&gt; &lt;version&gt;...&lt;/version&gt; &lt;scope&gt;...&lt;/scope&gt; &lt;type&gt;...&lt;/type&gt; &lt;optional&gt;...&lt;/optional&gt; &lt;exclusions&gt; &lt;exclusion&gt;...&lt;/exclusion&gt; &lt;/exclusions&gt;&lt;/dependency&gt; groupId、artifactId、version：声明了依赖的基本坐标 type: 依赖的类型，对应于项目坐标定义中的packaging，比如说jar scope：依赖的范围 optional：是否是可选依赖 exclusions: 排除传递性依赖 依赖范围(scope) Maven有三套classpath，编译项目主代码、编译测试代码、实际运行。依赖范围就是用来控制依赖与这三种classpath的关系.有以下几个选项： 依赖范围 | 对主代码classpath有效 | 对测试classpath有效 | 对运行时classpath有效——–|———————-|——————–|———————-compile | Y | Y | Ytest | N | Y | Nprovided| Y | Y | Nruntime | N | Y | Ysystem | Y | Y | N 传递性依赖 我们在项目的pom.xml文件中声明了直接依赖，如果声明的这些依赖还依赖于其他第三方组件，在maven中，我们不用考虑这些间接依赖，也不用担心引入多余的依赖。Maven会解析各个直接依赖的pom，将那些必要的间接依赖以传递性依赖的方式引入到当前项目的classpath中。 依赖范围不仅能够控制依赖与三种classpath的关系，还会对传递性依赖产生影响。比如设A依赖于B，B依赖于C，A对于B是第一直接依赖，B对于C是第二直接依赖，A对与C是传递性依赖。第一直接依赖与第二直接依赖的依赖范围决定了传递性依赖的依赖范围。如下图，最左边第一列表示第一直接依赖范围，最上面一行表示第二直接依赖范围，中间交叉单元格表示传递性依赖范围 | compile | test | provided | runtime ——–|———|——|———-|———–compile | compile | | | runtimetest | test | | | testprovided| provided| | provided | providedruntime | runtime | | | runtime 比如，account-email 项目有一个com.icegree:greemail:1.3.1b的直接依赖，这是第一直接依赖，其依赖范围是test；而greemail又有一个javax.mail:mail:1.4的直接依赖，这是第二直接依赖，其依赖的范围是compile。根据上面的表格可以推断，javax.mail:mail:1.4是account-email的一个范围是test的传递依赖。 依赖调解 对于一个构件，存在于不同依赖路径上。选择哪个路径上的构件就是依赖调解要解决的问题，有两种策略： 路径近者优先。 比如，项目A有这样的依赖关系：A-&gt;B-&gt;C-&gt;x(1.0)、A-&gt;D-&gt;X(2.0)，对于两个版本的X，如果都引入就会造成依赖重复。根据路径近者优先的策略，X(2.0)会被引入； 第一声明者优先。 路径近者优先的策略不能解决所有问题，如果出现路径长度相同的情况，那么maven就会选择依赖声明在前的那个路径上的版本。 可选依赖(optional) 假设有这样的依赖关系：项目A依赖于项目B，项目B依赖于项目X，Y，B对于X和Y都是可选依赖：A-B、B-&gt;X(可选)、B-&gt;Y(可选)。那么此时，由于X、Y都是可选依赖，依赖性将不会传递，也就是说，A中不会引入X和Y。 有这样一种情况符合可选依赖的场景：项目B是一个持久层的工具包，支持多种数据库，X、Y就是其依赖的数据库驱动程序，但是我们的项目A在使用这个工具包B的时候，只依赖一种数据库，故我们不需要将X和Y全部引入。这种情况下需要我们在项目A中声明实际使用的数据库驱动依赖。 排除依赖(exclusions) 传递性依赖为我们的项目隐式的引入了很多依赖，如果我们不想引入某个传递性依赖(自己选择依赖版本)，就可以使用排除依赖。 12345678910111213141516&lt;dependency&gt;&lt;groupId&gt;org.slf4j&lt;/groupId&gt;&lt;artifactId&gt;slf4j-api&lt;/artifactId&gt;&lt;version&gt;1.7.7&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt;&lt;groupId&gt;org.slf4j&lt;/groupId&gt;&lt;artifactId&gt;slf4j-log4j12&lt;/artifactId&gt;&lt;version&gt;1.7.7&lt;/version&gt;&lt;exclusions&gt; &lt;exclusion&gt; &lt;groupId&gt;org.slf4j&lt;/groupId&gt; &lt;artifactId&gt;slf4j-api&lt;/artifactId&gt; &lt;/exclusion&gt;&lt;/exclusions&gt;&lt;/dependency&gt; 上面的代码声明了一个排除依赖。我们的项目所依赖的slf4j-log4j12会引入slf4j-api这个传递性依赖。出于版本或者其他考虑，现在不想引入这个依赖，而是由我们显示的声明，那么就可以像上面的代码那样做。 查看依赖 通过执行mvn dependency:list可以查看项目已经解析的依赖；通过执行mvn dependency:tree可以查看项目的依赖树；通过执行mvn dependency:analyze可以查看项目中没有使用，却显示声明的依赖和项目中显示使用了却没有显示声明的依赖。 在Eclispe中，可以双击pom.xml，在Dependencies和Dependency Hierarchy选项卡查看项目的依赖情况。 仓库 仓库分类 对于maven来说，仓库分为两类：本地仓库和远程仓库。本地仓库即存在于我们本地机器上的构件仓库，远程仓库就是远程机器上的构件仓库。我们的依赖(jar)都是从仓库当中下载得到的。 当maven对我们的项目执行编译或者测试时，如果需要使用依赖文件，他总是基于坐标使用本地仓库的依赖文件。如果本地仓库存在此构件，则直接使用；如果本地仓库不存在此构件，或者需要更新的版本，maven会去远程仓库查找，发现需要的构件之后，下载到本地仓库再使用。如果本地仓库和远程仓库都没有需要的构件，则报错。 中央仓库是Maven核心自带的远程仓库，包含了绝大部分开源构件。默认情况下，当本地仓库没有maven需要的构件时，他就会从中央仓库下载。 仓库配置 在linux上本地仓库的默认路径为：~/.m2/repository/ 如果想要自定义本地仓库地址，可以编辑 ~/.m2/setting.xml, 设置localRepository元素值为想要的地址： 1&lt;localRepository&gt;/path/to/local/repo&lt;/localRepository&gt; 某些情况下，中央仓库无法满足项目需求，项目需要的构件可能存在于另一个远程仓库上，这是，可以在pom中配置该仓库： 12345678910111213 &lt;repositories&gt; &lt;repository&gt; &lt;id&gt;JBOSS&lt;/id&gt; &lt;name&gt;Jboss&lt;/name&gt; &lt;url&gt;http://repository.jnoss.com/maven2&lt;/url&gt; &lt;releases&gt; &lt;enabled&gt;true&lt;/enabled&gt; &lt;/releases&gt; &lt;snapshots&gt; &lt;enabled&gt;false&lt;/enabled&gt; &lt;/snapshots&gt; &lt;/repository&gt;&lt;/repositories&gt; 上面的例子中声明了一个id为JBOSS的远程仓库，任何一个仓库声明的id都必须是唯一的。release的enable值为true，表示开启Jboss仓库发布版本的下载支持；snapshots的enable值为false，表示关闭Jboss仓库快照版本的下载支持。 可以声明多个远程仓库，maven会遍历这些仓库去查找所需的构件。 聚合与继承 聚合 一个项目中往往不止一个模块，比如有core、util等等模块的划分。每个模块是一个独立的工程，提供了对外的接口供调用，各个模块之间有相互依赖的关系。那么，如果我们想要一次性构建项目中的两个两个模块，而不是到两个模块各自的目录下面执行mvn命令，这时候就需要maven的聚合。 为了能够使用一条命令就构建core和util两个模块，我们需要额外创建一个名为aggregator的模块，然后通过该模块构建整个项目的所有模块。aggregator本身作为一个maven项目，必须有自己的pom： 123456789101112 &lt;project xmlns="http://maven.apache.org/POM/4.0.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd"&gt;&lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt;&lt;groupId&gt;com.test.app&lt;/groupId&gt;&lt;artifactId&gt;app-aggregator&lt;/artifactId&gt;&lt;version&gt;1.0-SNAPSHOT&lt;/version&gt;&lt;packaging&gt;pom&lt;/packaging&gt;&lt;modules&gt; &lt;module&gt;app-core&lt;/module&gt; &lt;module&gt;app-util&lt;/module&gt;&lt;/modules&gt; &lt;/project&gt; 对于聚合模块来说，packaging的值必须为pom，否则无法构建。用户可以通过在一个打包为pom的Maven项目中声明任意数量的module元素来实现模块的聚合。 这里每一个module的值都是一个当前pom的相对目录。比如app-aggregator的pom路径为~/app/app-aggregator/pom.xml，那么app-core就对应目录~/app/app-aggregator/app-core/,app-util就对应目录~/app/app-aggregator/app-util/，这两个目录各自包含pom.xml、src/main/java等内容，可以独立构建。 从聚合模块运行mvn命令，maven就会解析聚合模块的pom，分析要构建的模块，并计算出一个构建顺序，然后根据这个顺序依次构建各个模块。 继承 在面向对象的设计中，可以在父类中声明一些字段，由子类继承使用。类似的，pom也可以声明这样一种父子结构。 我们继续在~/app/app-aggregator/目录下创建一个名为app-parent的子目录，在该子目录中声明一个pom: 123456789 &lt;project xmlns="http://maven.apache.org/POM/4.0.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd"&gt;&lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt;&lt;groupId&gt;com.test.app&lt;/groupId&gt;&lt;artifactId&gt;app-parent&lt;/artifactId&gt;&lt;version&gt;1.0-SNAPSHOT&lt;/version&gt;&lt;packaging&gt;pom&lt;/packaging&gt;&lt;name&gt;App parent&lt;/name&gt; &lt;/project&gt; 修改app-core继承app-parent 12345678910111213 &lt;project xmlns="http://maven.apache.org/POM/4.0.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd"&gt;&lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt;&lt;parent&gt; &lt;groupId&gt;com.test.app&lt;/groupId&gt; &lt;artifactId&gt;app-parent&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;relativePath&gt;../app-parent/pom.xml&lt;/relativePath&gt;&lt;/parent&gt;&lt;artifactId&gt;app-core&lt;/artifactId&gt;&lt;packaging&gt;pom&lt;/packaging&gt;&lt;name&gt;App core&lt;/name&gt; &lt;/project&gt; 上述pom中parent元素声明父模块，groupId、artifactId、version指定了父模块的坐标。relativePath指定了父模块pom的相对路径。 app-core中没有声明version和groupId，他隐式的从父模块继承了这两个元素。 下面是可继承的pom元素： 12345678910111213141516171819groupId ：项目组 ID ，项目坐标的核心元素； version ：项目版本，项目坐标的核心元素； description ：项目的描述信息； organization ：项目的组织信息； inceptionYear ：项目的创始年份； url ：项目的 url 地址 develoers ：项目的开发者信息； contributors ：项目的贡献者信息； distributionManagerment ：项目的部署信息； issueManagement ：缺陷跟踪系统信息； ciManagement ：项目的持续继承信息； scm ：项目的版本控制信息； mailingListserv ：项目的邮件列表信息； properties ：自定义的 Maven 属性； dependencies ：项目的依赖配置； dependencyManagement ：醒目的依赖管理配置； repositories ：项目的仓库配置； build ：包括项目的源码目录配置、输出目录配置、插件配置、插件管理配置等； reporting ：包括项目的报告输出目录配置、报告插件配置等。 依赖管理与插件管理 上面的列表中包含了dependencies元素，表示依赖会被继承。因此，我们可以将模块的公有依赖配置到父模块pom中，子模块就可以移除这些依赖，但这样带来一个问题，如果我们新增了模块也继承父模块的话，新增的子模块也就有可能引入了他不需要的依赖。 为了解决这个问题，maven提供了dependencyManagement元素。在dependencyManagement元素下声明的依赖不会被实际引入：app-parent/pom.xml 12345678910111213141516171819 &lt;project xmlns="http://maven.apache.org/POM/4.0.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd"&gt;&lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt;&lt;groupId&gt;com.test.app&lt;/groupId&gt;&lt;artifactId&gt;app-parent&lt;/artifactId&gt;&lt;version&gt;1.0-SNAPSHOT&lt;/version&gt;&lt;packaging&gt;pom&lt;/packaging&gt;&lt;name&gt;App parent&lt;/name&gt;&lt;dependencyManagement&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;com.googlecode.java-diff-utils&lt;/groupId&gt; &lt;artifactId&gt;diffutils&lt;/artifactId&gt; &lt;version&gt;1.2.1&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/dependencyManagement&gt; &lt;/project&gt; 使用dependencyManagement声明的依赖既不会给app-parent引入依赖，也不会给他的子模块引入依赖，不过这段配置会被继承：app-core/pom.xml 1234567891011121314151617181920 &lt;project xmlns="http://maven.apache.org/POM/4.0.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd"&gt;&lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt;&lt;parent&gt; &lt;groupId&gt;com.test.app&lt;/groupId&gt; &lt;artifactId&gt;app-parent&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;relativePath&gt;../app-parent/pom.xml&lt;/relativePath&gt;&lt;/parent&gt;&lt;artifactId&gt;app-core&lt;/artifactId&gt;&lt;packaging&gt;pom&lt;/packaging&gt;&lt;name&gt;App core&lt;/name&gt;&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;com.googlecode.java-diff-utils&lt;/groupId&gt; &lt;artifactId&gt;diffutils&lt;/artifactId&gt; &lt;/dependency&gt;&lt;/dependencies&gt; &lt;/project&gt; 可以看到子模块只需要声明dependency的groupId、artifactId，不用声明version，虽然只省去了一行配置，但是统一了项目依赖的版本，降低依赖冲突的机会。 如果子模块没有声明diffutils，diffutils就不会被引入。 maven还提供了pluginManagement元素帮助管理插件。与dependencyManagement的原理相同。 超级pom 实际上，我们声明的pom都隐式的继承自超级pom，位于MAVEN_HOME/lib/maven-model-builder-x.jar中的org/apache/maven/model/pom-4.0.0.xml。 在超级pom中定义了仓库和插件仓库，都是中央仓库的地址，定义了项目的主代码目录，测试目录等等项目的结构。 我们可以模仿超级pom在我们自己的pom中声明这些元素，从而自定义项目结构。 属性与Profile属性属性有点类似于java中的变量。我们可以在pom中使用${属性名}的方式引用属性的值，从而消除重复，也能降低错误发生的概率。 maven属性有6类： 内置属性 主要有${basedir}表示项目根目录，即包含pom.xml的目录；${version}表示项目的版本 pom属性 ${project.build.directory}表示主源码路径; ${project.build.sourceEncoding}表示主源码的编码格式; ${project.build.sourceDirectory}表示主源码路径; ${project.build.finalName}表示输出文件名称; ${project.version}表示项目版本,与${version}相同; 自定义属性 123&lt;properties&gt;&lt;project.my&gt;hello&lt;/project.build.sourceEncoding&gt;&lt;/properties&gt; 在pom中的其他地方使用${project.my}就会被替换成hello settings属性 与pom属性同理，用户以settings开头的属性引用settings.xml文件中的xml元素值，如${settings.localRepository}指向本地仓库地址 java系统属性 所有java系统属性都可以使用maven属性引用。如${user.home}指向用户目录 环境变量属性 所有环境变量都可以用以env开头的属性引用。如${env.JAVA_HOME} 资源过滤一般情况下，我们习惯于在src/main/resources/目录下放置配置文件，在配置文件中，我们可能配置数据库的url，用户名密码等信息。但是在不同的环境中，这些数据库的配置常常会变动，比如在测试环境或者运行环境中。比较原始的做法手动更改这些配置，但是这样的方法比较低下也容易出错。maven可以在构建过程中针对不同的环境激活不同的配置。 首先需要使用maven属性将会发生变化的部分提取出来：在数据库配置文件中 12db.jdbc.driver=$&#123;db.driver&#125;db.jdbc.url=$&#123;db.url&#125; 这里定义了两个属性：db.driver、db.url 既然定义了maven属性，我们需要在某个地方为其赋值。与自定义属性不同的是，这里需要做的是使用profile将其包裹： 123456789&lt;profiles&gt; &lt;profile&gt; &lt;id&gt;pro_A&lt;/id&gt; &lt;properties&gt; &lt;db.driver&gt;com.mysql.jdbc.Driver&lt;/db.driver&gt; &lt;db.url&gt;jdbc:mysql://localhost:3306&lt;/db.url&gt; &lt;/properties&gt; &lt;/profile&gt;&lt;/profiles&gt; 那么这个profile是在哪里声明的呢？有三个地方： pom.xml: pom中的profile只对当前项目有效 用户settings.xml: 用户目录下.m2/settings.xml中的profile对该用户的所有maven项目有效 全局settings.xml: maven安装目录下conf/settings.xml中的profile对本机上所有maven项目有效 在配置文件中定义了maven属性，也在profile中为其赋值了，此时要做的是打开资源过滤： 资源文件的处理实际上是maven-resources-plugin插件所做的事情，他的默认行为只是将项目主资源文件复制到主代码编译输出目录中，将测试资源文件复制到测试代码编译输出目录中。我们需要一些配置，使得该插件能够解析资源文件中的maven属性，开启资源过滤。 maven默认的资源目录是在超级pom中定义的，要开启资源目录过滤，需要如下配置： 12345678&lt;build&gt; &lt;resources&gt; &lt;resource&gt; &lt;directory&gt;$&#123;project.basedir&#125;/src/main/resources&lt;/directory&gt; &lt;filtering&gt;true&lt;/filtering&gt; &lt;/resource&gt; &lt;/resources&gt;&lt;/build&gt; 上述代码为主资源目录开启了资源过滤，类似的我们可以为多个资源目录提供过滤配置：123456789101112&lt;build&gt; &lt;resources&gt; &lt;resource&gt; &lt;directory&gt;$&#123;project.basedir&#125;/src/main/resources&lt;/directory&gt; &lt;filtering&gt;true&lt;/filtering&gt; &lt;/resource&gt; &lt;resource&gt; &lt;directory&gt;$&#123;project.basedir&#125;/src/main/sql&lt;/directory&gt; &lt;filtering&gt;true&lt;/filtering&gt; &lt;/resource&gt; &lt;/resources&gt;&lt;/build&gt; 在配置文件中定义了maven属性，在profile中为属性赋值，并且为资源目录开启了资源过滤，接下来只需要在命令行激活profile：mvn clean test -Ppro_A. mvn命令中的-P参数激活了一个名为pro_A的profile。maven在构建项目的时候就会使用profile中的属性值替换在配置文件中的属性定义，然后将其复制到编译输出目录当中。 profile我们可以想到，针对不同的环境定义不同的profile，然后在不同的环境中通过命令行激活对应的profile，就能达到灵活切换配置的目的。除了命令行手动激活profile以外，还有下面几种方式能够激活profile： 默认激活 123456789101112 &lt;profiles&gt; &lt;profile&gt; &lt;id&gt;pro_A&lt;/id&gt; &lt;activation&gt; &lt;activeByDefault&gt;true&lt;/activeByDefault&gt; &lt;/activation&gt; &lt;properties&gt; &lt;db.driver&gt;com.mysql.jdbc.Driver&lt;/db.driver&gt; &lt;db.url&gt;jdbc:mysql://localhost:3306&lt;/db.url&gt; &lt;/properties&gt; &lt;/profile&gt;&lt;/profiles&gt; activeByDefault指定profile自动激活。但是如果pom中的任意一个profile通过其他方式被激活了，那么默认的激活配置失效。 属性激活 123456789101112131415 &lt;profiles&gt; &lt;profile&gt; &lt;id&gt;pro_A&lt;/id&gt; &lt;activation&gt; &lt;property&gt; &lt;name&gt;test&lt;/name&gt; &lt;value&gt;x&lt;/value&gt; &lt;/property&gt; &lt;/activation&gt; &lt;properties&gt; &lt;db.driver&gt;com.mysql.jdbc.Driver&lt;/db.driver&gt; &lt;db.url&gt;jdbc:mysql://localhost:3306&lt;/db.url&gt; &lt;/properties&gt; &lt;/profile&gt;&lt;/profiles&gt; 属性test存在且值为x时激活该profile。利用这个特性可以在命令行同时激活多个profile：mvn clean test -Dtest=x settings文件激活 12345&lt;settings&gt; &lt;activeProfiles&gt; &lt;activeProfile&gt;pro_x&lt;/activeProfile&gt; &lt;/activeProfiles&gt;&lt;/settings&gt; 在settings.xml文件中配置，表示其配置的profile对所有项目处于激活状态。 在profile中不仅可以添加或者修改maven属性，还可以对其他maven元素进行设置。 pom中的profile可以使用的元素： 123456789101112131415 &lt;repositories&gt;&lt;/repositories&gt;&lt;pluginRepositories&gt;&lt;/pluginRepositories&gt;&lt;distributionManagement&gt;&lt;/distributionManagement&gt;&lt;dependencies&gt;&lt;/dependencies&gt;&lt;dependencyManagement&gt;&lt;/dependencyManagement&gt;&lt;modules&gt;&lt;/modules&gt;&lt;properties&gt;&lt;/properties&gt;&lt;reporting&gt;&lt;/reporting&gt;&lt;build&gt; &lt;plugins&gt;&lt;/plugins&gt; &lt;defaultGoal&gt;&lt;/defaultGoal&gt; &lt;resources&gt;&lt;/resources&gt; &lt;testResources&gt;&lt;/testResources&gt; &lt;finalName&gt;&lt;/finalName&gt;&lt;/build&gt; 其他profile可以使用的元素 123&lt;repositories&gt;&lt;/repositories&gt;&lt;pluginRepositories&gt;&lt;/pluginRepositories&gt;&lt;properties&gt;&lt;/properties&gt;]]></content>
      <categories>
        <category>工具</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>maven</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[maven学习笔记(一)]]></title>
    <url>%2F2017%2F04%2F17%2Fmaven%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[上周末两天时间基本上将《Maven实战》这本书看完了。《Maven实战》是很棒的一本介绍maven相关知识的书籍。读完之后，对学到的maven相关的内容做一个梳理总结。 Maven基础有关Maven如何安装和设置，不在这里啰嗦了，可以到官网下载最新版本然后安装。 Maven是一个异常强大的构建工具，能够帮助我们自动化构建过程，从清理、编译、测试到生成报告，打包和部署。我们要做的只是使用Maven配置好项目，然后输入简单的命令，Maven会帮我们处理这些任务。 Maven项目的核心是pom.xml。Pom定义了项目的基本信息，用于描述项目如何构建，声明项目依赖等。下面是一个例子：123456789101112131415161718192021222324252627282930313233343536373839404142434445&lt;project xmlns="http://maven.apache.org/POM/4.0.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd"&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;space.yukai.mergetool&lt;/groupId&gt; &lt;artifactId&gt;mergetool-core&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;packaging&gt;jar&lt;/packaging&gt; &lt;name&gt;MergeTool&lt;/name&gt; &lt;name&gt;space.yukai&lt;/name&gt; &lt;url&gt;http://maven.apache.org&lt;/url&gt; &lt;properties&gt; &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt; &lt;/properties&gt; &lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-compiler-plugin&lt;/artifactId&gt; &lt;configuration&gt; &lt;source&gt;1.8&lt;/source&gt; &lt;target&gt;1.8&lt;/target&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;junit&lt;/groupId&gt; &lt;artifactId&gt;junit&lt;/artifactId&gt; &lt;version&gt;4.4&lt;/version&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;!-- https://mvnrepository.com/artifact/commons-io/commons-io --&gt; &lt;dependency&gt; &lt;groupId&gt;commons-io&lt;/groupId&gt; &lt;artifactId&gt;commons-io&lt;/artifactId&gt; &lt;version&gt;2.5&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/project&gt; Maven不仅是一个构建工具，还是一个依赖管理工具和项目信息管理工具。我们的java项目或多或少都会依赖一些第三方的类库，而maven提供了中央仓库，能够帮助我们自动下载构件。 Maven通过一个坐标系统准确的定位每一个构件(artifact)，也就是通过一组坐标Maven能够找到任何一个java类库(如jar包)。 在Maven的世界中，任何的jar、pom、或war都是通过这些坐标进行区分的。上面代码中开头的groupId、artifactId、version定义了这个项目的基本坐标。 groupId定义了项目属于哪个组，这个组往往和项目所在的组织有关联。比如Googlecode上面建立了一个项目app，那么groupId就应该为com.googlecode.app artifactId定义了当前项目在组中的唯一Id。比如为app中不同的子项目分配artifactId，如app-core、app-util、app-web version指定了项目当前的版本。SNAPSHOT表示项目还处于开发中，是不稳定的版本 packaging指定了项目的打包方式，默认为jar name定义了项目名称 上面dependency标签中的内容就是本项目声明的依赖。可以看到dependency标签中声明了groupId、artifactId、version这三个属性，比如commons-io，Maven解析到这个依赖时，就会根据这个坐标去本地仓库查找这个坐标下的依赖是否已经被下载，如果没有下载，那么到中央仓库去下载依赖的jar包到本地仓库，然后把下载好的jar包路径添加到classpath当中。这些工作都是自动进行的，我们要做的，只是在pom.xml中声明这个依赖即可。 Maven在项目构建过程和过程的各个阶段的工作都是由插件实现的，并且大部分的插件都是现成的。我们只需要声明项目的基本元素，Maven就会执行内置的构建过程。上面代码中plugin标签中的内容，是对maven-compiler-plugin这个插件进行的配置。 ArchetypeMaven提倡 “约定优于配置”。遵循Maven的一些约定，我们可以快速的创建项目并完成构建。对于遵循约定的Maven项目，我们可以快速的了解其结构，减轻了我们的学习成本。 比如：在项目的根目录放置pom.xml，在src/main/java目录放置项目主代码，在src/test/java放置项目测试代码。我们称这些基本的目录结构为项目骨架。通过Archetype插件可以帮助我们快速的创建出项目骨架。 运行mvn archetype:generate命令，选择我们的项目骨架。 1234567891011121314151617181920212223242526272829303132C:\Users\kyu\Desktop\test&gt;mvn archetype:generate[INFO] Scanning for projects...[INFO][INFO] ------------------------------------------------------------------------[INFO] Building Maven Stub Project (No POM) 1[INFO] ------------------------------------------------------------------------[INFO][INFO] &gt;&gt;&gt; maven-archetype-plugin:3.0.1:generate (default-cli) @ standalone-pom &gt;&gt;&gt;[INFO][INFO] &lt;&lt;&lt; maven-archetype-plugin:3.0.1:generate (default-cli) @ standalone-pom &lt;&lt;&lt;[INFO][INFO] --- maven-archetype-plugin:3.0.1:generate (default-cli) @ standalone-pom ---[INFO] Generating project in Interactive mode[INFO] No archetype defined. Using maven-archetype-quickstart (org.apache.maven.archetypes:maven-archetype-quickstart:1.0)Choose archetype:1: remote -&gt; am.ik.archetype:maven-reactjs-blank-archetype (Blank Project for React.js)2: remote -&gt; am.ik.archetype:msgpack-rpc-jersey-blank-archetype (Blank Project for Spring Boot + Jersey)3: remote -&gt; am.ik.archetype:mvc-1.0-blank-archetype (MVC 1.0 Blank Project)4: remote -&gt; am.ik.archetype:spring-boot-blank-archetype (Blank Project for Spring Boot)5: remote -&gt; am.ik.archetype:spring-boot-docker-blank-archetype (Docker Blank Project for Spring Boot)6: remote -&gt; am.ik.archetype:spring-boot-gae-blank-archetype (GAE Blank Project for Spring Boot)7: remote -&gt; am.ik.archetype:spring-boot-jersey-blank-archetype (Blank Project for Spring Boot + Jersey)8: remote -&gt; at.chrl.archetypes:chrl-spring-sample (Archetype for Spring Vaadin Webapps)9: remote -&gt; br.com.address.archetypes:struts2-archetype (an archetype web 3.0 + struts2 (bootstrap + jquery) + JPA 2.1 with struts2 login system)10: remote -&gt; br.com.address.archetypes:struts2-base-archetype (An Archetype with JPA 2.1; Struts2 core 2.3.28.1; Jquery struts plugin; Struts BootStrap plugin; json Struts plugin;...1813: remote -&gt; us.fatehi:schemacrawler-archetype-plugin-command (-)1814: remote -&gt; us.fatehi:schemacrawler-archetype-plugin-dbconnector (-)1815: remote -&gt; us.fatehi:schemacrawler-archetype-plugin-lint (-)Choose a number or apply filter (format: [groupId:]artifactId, case sensitive contains): 955: 默认为maven-archetype-quickstart(955)。选择该Archetype，Maven会提示输入创建项目的groupId、artifactId、version及包名package。 在当前目录下，Archetype插件会创建以artifactId命名的子目录： 可以看出，使用约定俗成的Archetype，不仅使用Maven插件代替了原本需要手工处理的劳动，同时节省了时间，降低了错误发生的概率。 也可以定义自己的项目骨架，在创建项目的时候，就可以直接使用该Archetype。 生命周期Maven的生命周期对所有的构建过程进行了抽象和统一。这个生命周期包括项目的清理、初始化、编译、测试、打包、集成测试、验证、部署和站点生成等所有的构建步骤。所有的项目构建，都可以映射到这样一个生命周期上。 Maven只是抽象出了生命周期，生命周期中实际的任务都是交给插件完成的，类似于设计模式中的模板方法模式。 Maven拥有三套独立的生命周期：clean、default、site。每个生命周期包含一些阶段： clean pre-clean 执行一些清理前需要完成的工作 clean 清理上一次构建生成的文件 post-clean 执行一些清理后需要完成的工作 default validate 检查工程配置是否正确，完成构建过程的所有必要信息是否能够获取到。 initialize 初始化构建状态，例如设置属性。 generate-sources 生成编译阶段需要包含的任何源码文件。 process-sources 处理源代码，例如，过滤任何值（filter any value）。 generate-resources 生成工程包中需要包含的资源文件。 process-resources 拷贝和处理资源文件到目的目录中，为打包阶段做准备。 compile 编译工程源码。 process-classes 处理编译生成的文件，例如 Java Class 字节码的加强和优化。 generate-test-sources 生成编译阶段需要包含的任何测试源代码。 process-test-sources 处理测试源代码，例如，过滤任何值（filter any values)。 test-compile 编译测试源代码到测试目的目录。 process-test-classes 处理测试代码文件编译后生成的文件。 test 使用适当的单元测试框架（例如JUnit）运行测试。 prepare-package 在真正打包之前，为准备打包执行任何必要的操作。 package 获取编译后的代码，并按照可发布的格式进行打包，例如 JAR、WAR 或者 EAR 文件。 pre-integration-test 在集成测试执行之前，执行所需的操作。例如，设置所需的环境变量。 integration-test 处理和部署必须的工程包到集成测试能够运行的环境中。 post-integration-test 在集成测试被执行后执行必要的操作。例如，清理环境。 verify 运行检查操作来验证工程包是有效的，并满足质量要求。 install 安装工程包到本地仓库中，该仓库可以作为本地其他工程的依赖。 deploy 拷贝最终的工程包到远程仓库中，以共享给其他开发人员和工程。 site pre-site 执行一些生成项目站点前需要完成的工作 site 生成项目站点文档 post-site 执行一些生成项目站点前需要完成的工作 site-deploy 将生成的站点发布到服务器 每个生命周期的阶段是有顺序的，后面的阶段依赖前面的阶段。使用maven最直接的交互方式就是调用这些生命周期的阶段。比如，当用户调用pre-clean时，只有pre-clean阶段得以执行，当调用clean时，pre-clean和clean依次执行，当调用post-clean时，pre-clean、clean和post-clean依次执行。 虽然每个生命周期内的阶段是有顺序和前后依赖的，但是三套生命周期之间是互相独立的。比如，当用户调用clean生命周期的clean阶段时，不会触发default生命周期的任何阶段，反之，当用户调用default生命周期的compile阶段时，也不会触发clean生命周期的任何阶段。 mvn clean install，该命令调用了clean生命周期clean阶段与default生命周期install 阶段。实际执行的阶段为clean生命周期的pre-clean、clean阶段，以及default生命周期从validate到install所有阶段。 插件目标Maven的核心仅仅定义了抽象的生命周期，具体的任务是由插件来完成的。 每个插件可以完成多个功能，每个功能就是插件的一个目标。比如maven-dependency-plugin可以列出项目依赖树，列出所有已解析的依赖等等。这两个目标对应的命令为： mvn dependency:tree，mvn dependency:list。冒号前面是插件前缀，冒号后面是插件目标。 所以，我们知道了mvn命令有两种调用方式，一种调用其生命周期，一种直接调用插件目标。 插件的生命周期与插件相互绑定，完成实际的构建任务。调用生命周期实际上也是执行了多个插件目标。 内置绑定 Maven核心已经对一些主要的生命周期阶段绑定了很多插件目标，当用户通过命令行调用生命周期的时候，对应的插件目标就会执行相应的任务。 比如，clean生命周期有pre-clean、clean、post-clean三个阶段，clean生命周期阶段与插件目标的绑定关系如下： 生命周期阶段 | 插件目标————|———–pre-clean |clean |maven-clean-plugin:cleanpost-clean | 执行命令mvn post-clean，输出如下： 123456789101112[INFO] ------------------------------------------------------------------------[INFO] Building space.yukai 0.0.1-SNAPSHOT[INFO] ------------------------------------------------------------------------[INFO] [INFO] --- maven-clean-plugin:2.5:clean (default-clean) @ space.yukai ---[INFO] ------------------------------------------------------------------------[INFO] BUILD SUCCESS[INFO] ------------------------------------------------------------------------[INFO] Total time: 0.409 s[INFO] Finished at: 2017-04-17T16:37:08+08:00[INFO] Final Memory: 7M/106M[INFO] ------------------------------------------------------------------------ 从输出中可以看到，执行的插件目标仅为maven-clean-plugin:clean 自定义绑定 除了内置绑定之外，用户可以自己选择将某个插件目标绑定到生命周期的某个阶段。 比如，我们可以自行配置创建项目的源码jar包。maven-source-plugin的jar-no-fork目标可以将项目的主代码打包成jar文件。我们将其绑定到clean生命周期的post-clean阶段测试一下： 12345678910111213&lt;plugin&gt;&lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt;&lt;artifactId&gt;maven-source-plugin&lt;/artifactId&gt;&lt;executions&gt; &lt;execution&gt; &lt;id&gt;attach-source&lt;/id&gt; &lt;phase&gt;post-clean&lt;/phase&gt; goals&gt; &lt;goal&gt;jar-no-fork&lt;/goal&gt; &lt;/goals&gt; &lt;/execution&gt;&lt;/executions&gt;&lt;/plugin&gt; 运行mvn post-clean，输出： 12345678910111213141516[INFO] ------------------------------------------------------------------------[INFO] Building space.yukai 0.0.1-SNAPSHOT[INFO] ------------------------------------------------------------------------[INFO] [INFO] --- maven-clean-plugin:2.5:clean (default-clean) @ space.yukai ---[INFO] Deleting Y:\code\versionmergetool\VersionMergeTool\target[INFO] [INFO] --- maven-source-plugin:3.0.1:jar-no-fork (attach-source) @ space.yukai ---[INFO] Building jar: Y:\code\versionmergetool\VersionMergeTool\target\space.yukai-0.0.1-SNAPSHOT-sources.jar[INFO] ------------------------------------------------------------------------[INFO] BUILD SUCCESS[INFO] ------------------------------------------------------------------------[INFO] Total time: 1.082 s[INFO] Finished at: 2017-04-17T16:55:32+08:00[INFO] Final Memory: 7M/111M[INFO] ------------------------------------------------------------------------ 可以看到，当执行post-clean阶段的时候，maven-source-plugin:jar-no-fork 创建了一个以-sources.jar结尾的源码包。 为了了解插件有哪些配置，我们可以使用maven-help-plugin来获取插件信息。 运行命令mvn help:describe -Dplugin=compiler 123456789101112131415161718192021222324252627282930313233343536373839[INFO] Scanning for projects...[INFO][INFO] ------------------------------------------------------------------------[INFO] Building mvntest-test 1.0-SNAPSHOT[INFO] ------------------------------------------------------------------------[INFO][INFO] --- maven-help-plugin:2.2:describe (default-cli) @ mvntest-test ---[INFO] org.apache.maven.plugins:maven-compiler-plugin:3.6.1Name: Apache Maven Compiler PluginDescription: The Compiler Plugin is used to compile the sources of your project.Group Id: org.apache.maven.pluginsArtifact Id: maven-compiler-pluginVersion: 3.6.1Goal Prefix: compilerThis plugin has 3 goals:compiler:compile Description: Compiles application sourcescompiler:help Description: Display help information on maven-compiler-plugin. Call mvn compiler:help -Ddetail=true -Dgoal=&lt;goal-name&gt; to display parameter details.compiler:testCompile Description: Compiles application test sources.For more information, run &apos;mvn help:describe [...] -Ddetail&apos;[INFO] ------------------------------------------------------------------------[INFO] BUILD SUCCESS[INFO] ------------------------------------------------------------------------[INFO] Total time: 5.944s[INFO] Finished at: Mon Apr 17 17:02:52 CST 2017[INFO] Final Memory: 11M/110M[INFO] ------------------------------------------------------------------------ 可以得到插件maven-compiler-plugin的信息及相关目标。还可以加上detail参数输出更详细的信息mvn help:describe -Dplugin=compiler -Ddetail 前缀 笔记开头说了，在maven的世界中，所有的构件都是由坐标来确定的，构件包括依赖的jar或者插件。那么我们上面的mvn help:describe -Dplugin=compiler中并没有指定插件的坐标，为什么能够正常的运行呢？ 其实mvn help:describe -Dplugin=compiler就等效于mvn org.apache.maven.plugins:maven-help-plugin:2.2:describe -Dplugin=compiler。help就是maven-help-plugin的前缀，maven能够根据这个前缀找到对应的artifactId，从而解析得到groupId和version，所有能够精确的定位某个插件。compiler也是前缀。]]></content>
      <categories>
        <category>工具</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>maven</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[木耳炒山药]]></title>
    <url>%2F2017%2F04%2F16%2F%E6%9C%A8%E8%80%B3%E7%82%92%E5%B1%B1%E8%8D%AF%2F</url>
    <content type="text"><![CDATA[天气越来越热了，今天炒了一个比较清淡的菜–木耳炒山药。 原料长山药、黑木耳、青椒、食用油、鸡精、盐、淀粉、葱、蒜、胡椒面 做法 山药切片，入锅钞水后捞出备用 黑木耳温水浸泡 少量淀粉和水勾兑 青椒切片(我还把剩下的胡萝卜丝搁一块了)，切好葱蒜备用 锅内倒入少量油，油热后放入葱蒜胡椒面炸香 倒入钞好的山药翻炒，随后加入青椒和木耳一起翻炒 加入适量的盐和鸡精，随后将备勾兑好的水淀粉倒入 翻炒片刻，淋少许油出锅 成品]]></content>
      <categories>
        <category>生活</category>
      </categories>
      <tags>
        <tag>食物</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[hexo博客备份方案]]></title>
    <url>%2F2017%2F04%2F11%2Fhexo%E5%8D%9A%E5%AE%A2%E5%A4%87%E4%BB%BD%E6%96%B9%E6%A1%88%2F</url>
    <content type="text"><![CDATA[周末的时候给博客换了一个主题，现在的博客看起来比之前的要清爽多了。 hexo是把生成的一套html发布到服务器上面的，我使用了github来托管自己的博客，每次发布时只把生成的html等文件发布到github，源代码并不会一同发到上面。 如果是换电脑的话就很不方便了，再加上之前使用hexo generate -d发布博客的时候出了点问题，所以抽空写了一个专门用来发布博客和保存源代码的脚本，在此记录。 脚本12345678910111213141516171819202122232425262728# hexo generate -d 命令失效，将hexo分支推送到了master分支。使用此脚本进行部署# 将此脚步置于与blog同级目录下。# 部署root=&quot;/home/yukai/project/blog&quot;folder=&quot;$root/blogdeploy&quot;blog=&quot;$root/Hikyu.github.io&quot;if [ ! -d &quot;$folder&quot; ]; then echo &quot;初始化...&quot; mkdir &quot;$folder&quot; cp -R &quot;$blog/.git/&quot; &quot;$folder/.git/&quot; cd &quot;$folder&quot; git checkout masterfiecho &quot;博客生成...&quot;cd &quot;$blog&quot;git checkout hexohexo generatecp -R &quot;$blog&quot;/public/* &quot;$folder&quot;echo &quot;博客发布...&quot;cd &quot;$folder&quot;git add --all .git commit -m &apos;update&apos;git push origin masterecho &quot;备份博客源码到hexo分支...&quot;cd &quot;$blog&quot;git add --all .git commit -m &apos;update&apos;git push origin hexo 将上述脚本保存为deploy.sh。 使用时需要将变量root设为博客目录的父目录。 如果博客目录还不存在(换电脑)，需要使用git clone命令把博客源代码下载下来。 修改博客源码后，执行 sudo ./deploy.sh进行博客发布与备份。 原理 发布博客 hexo generate -d 可以将博客编译后发布到服务器。其原理就是将源代码中public目录下的内容推送到远程分支上面。 我们使用master分支保存发布的博客(github也规定了要发布的博客必须为master分支)。 首先建立推送博客的目录$folder，并且将博客目录$blog下.git文件夹拷贝到$folder； 切换到博客目录$blog，然后生成博客，将生成的public目录的内容拷贝到$folder； 将$folder中的内容推送到远程分支master，完成发布。 源码备份 使用新的分支hexo来保存我们的博客源代码。 切换到博客目录$blog，并切换分支到hexo； 将博客目录$blog中的源代码内容推动到远程分支hexo，完成备份。]]></content>
      <categories>
        <category>工具</category>
      </categories>
      <tags>
        <tag>hexo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[糖醋里脊]]></title>
    <url>%2F2017%2F04%2F09%2F%E7%B3%96%E9%86%8B%E9%87%8C%E8%84%8A%2F</url>
    <content type="text"><![CDATA[今天给女朋友做了一道菜：糖醋里脊。如图，还算是比较成功的～ 原料猪里脊肉、白糖、醋、料酒、盐、番茄酱、葱蒜、胡椒粉、面粉、淀粉 制作方法 将醋、糖、料酒、盐，少许水和淀粉混合成调味汁儿备用，比例糖4醋3料酒1，水、盐适量。 将里脊切成粗条状，放入碗中。加入盐、胡椒粉、料酒抓匀后腌制20分钟。 将腌制好的里脊肉沥水后倒入碗中，打入一个鸡蛋，抓匀。 将面粉(可以加点淀粉)倒入碗中，依次将里脊肉放入面粉中，保证里脊粘上一层面粉。 锅中加入油，烧至六成热，转中小火，逐个将粘上面粉的肉条放入，炸约一分钟捞出沥油。 将锅里的油继续加热，油温八九成热时，倒入肉条复炸片刻至金黄色酥脆后，捞出沥油。 锅中留少许底油加热，爆香葱蒜末。加入番茄酱炒香。加入调好的糖醋汁煮至浓稠。 下入炸好的里脊条快速翻匀，出锅装盘。 成品]]></content>
      <categories>
        <category>生活</category>
      </categories>
      <tags>
        <tag>食物</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[java类加载]]></title>
    <url>%2F2017%2F04%2F06%2Fjava%E7%B1%BB%E5%8A%A0%E8%BD%BD%2F</url>
    <content type="text"><![CDATA[本篇笔记的目标是理解类加载器的架构，学会实现类加载器并理解热替换的底层原理。 什么是类加载 类从被加载到虚拟机内存中开始，到卸载出内存为止，包括了以下几个生命周期： 什么时候会触发类加载的第一个阶段(加载)？虚拟机规范没有强制规定，这一点依据不同的虚拟机实现来定。但对于初始化阶段，虚拟机规范规定了有且只有5种&gt;情况必须立即对类进行初始化(加载阶段自然要在此之前开始)： 1.使用new关键字实例化对象、读取或设置一个类的静态字段(被final修饰的常量字段除外)、调用一个类的静态方法。 2.使用反射方法对类进行调用 3.初始化一个类的时候，发现其父类未初始化，则触发父类的初始化 4.虚拟机启动时，用户需指定一个要执行的主类(包含main的那个类)，虚拟机先初始化该类 5.当使用jdk1.7的动态语言支持时，如果一个java.lang.invoke。MethodHandle实例最后的解析结果REF_getStatic、REF_putStatic、REF_invokeStatic的方法句柄所对应的类没有进行过初始化，则先触发其初始化(不懂…) –《深入理解jvm虚拟机》 这篇笔记所要学习的内容，仅仅是类加载的第一个阶段：加载。在加载阶段，虚拟机会完成下面三件事： 1.通过一个类的全限定名获取定义此类的二进制字节流 2.将这个字节流所代表的静态存储结构转化为方法区的运行时数据结构 3.在内存中生成一个代表这个类的java.lang.Class对象，作为方法区中这个类的各种数据的访问入口 在上面的三个阶段中，通过一个类的全限定名获取定义此类的二进制字节流 是开发人员可以控制的部分，也是我们这篇笔记所要探讨的内容。 虚拟机设计团队将通过一个类的全限定名获取定义此类的二进制字节流这个动作放到java虚拟机外部去实现，以便让应用程序自己决定去如何获取所需要的类。实现这个动作的代码模块被称为”类加载器”。定义此类的二进制字节流可以来自class文件、网络、zip包、或者运行时生成等。 类加载器实现类的加载动作，比较两个类是否相等，只有在这两个类是由同一个类加载器加载的前提下才有意义，否则，即使两个类源自于同一份class文件，被同一个虚拟机加载，只要加载他们的类加载器不同，那么这两个类必定不相等。 12345678910111213141516171819202122232425262728293031323334353637public class ClassLocaderTest &#123; public static void main(String[] args) &#123; Object testClassLoader1 = getMyClassLoader1(); System.out.println(testClassLoader1.getClass()); System.out.println(testClassLoader1 instanceof space.kyu.TestClass); &#125; static Object getMyClassLoader1() &#123; Object obj = null; try &#123; MyClassLoader1 loader = new MyClassLoader1(); obj = loader.loadClass("space.kyu.TestClass").newInstance(); &#125; catch (Exception e) &#123; System.out.println(e); &#125; return obj; &#125;&#125;class MyClassLoader1 extends ClassLoader&#123; @Override public Class&lt;?&gt; loadClass(String name) throws ClassNotFoundException &#123; try &#123; String fileName = name.substring(name.lastIndexOf(".") + 1) + ".class"; InputStream stream = getClass().getResourceAsStream(fileName); if (stream == null) &#123;// System.out.println("ClassLoader load class" + name); return super.loadClass(name); &#125; byte[] bs = new byte[stream.available()]; stream.read(bs);// System.out.println("MyClassLoader1 load class: " + name); return defineClass(name, bs, 0, bs.length); &#125; catch (IOException e) &#123; throw new ClassNotFoundException(name); &#125; &#125; &#125; 输出： 12class space.kyu.TestClassfalse 在上面的例子中，虚拟机中存在两个space.kyu.TestClass类，一个是由系统应用程序类加载器加载的，一个是由我们自己实现的类加载器加载的。虽然来自同一个class文件，但依然是两个独立的类，故不相等。 类加载器应用于类层次划分、OSGI、热部署、代码加密等方面。 类加载器层次结构从java虚拟机的角度来看，类加载器分为两类： 1.启动类加载器 使用c++实现，是虚拟机自身的一部分 2.其他类加载器 由java语言实现，独立于虚拟机外部，全都继承自抽象类java.lang.ClassLoader 从类加载器的实现来看，类加载器又可分为系统提供的类加载器与我们自己实现的类加载器。系统提供的类加载器主要有三个： 引导类加载器，用来加载java核心类库。主要是放在JAVA_HOME\lib目录中或被-Xbootclasspath所指定的目录。 扩展类加载器，由sun.misc.Launcher$ExtClassLoader实现。负责加载JAVA_HOME\lib\ext目录中，或java.ext.dirs所指定的路径中的类库。 应用程序类加载器，由sun.misc.Launcher$AppClassLoader实现。这个类也是ClassLoader中getSystemClassLoader()方法的返回值。负责加载classpath上指定的类库。 除了系统提供的类加载器以外，我们可以通过继承 java.lang.ClassLoader类的方式实现自己的类加载器，以满足一些特殊的需求。 除了引导类加载器之外，所有的类加载器都有一个父类加载器。这种父子关系构成了类加载器的层次结构。 对于系统提供的类加载器来说，应用程序类加载器的父类加载器是扩展类加载器，而扩展类加载器的父类加载器是引导类加载器。 因为类加载器 Java 类如同其它的 Java 类一样，也是要由类加载器来加载的。对于开发人员编写的类加载器来说，其父类加载器是加载此类加载器 Java 类的类加载器。 这种类加载器之间的层次关系，称为类加载器的双亲委派模型： 注意，上图中的树状结构并不意味着继承关系，而是使用委托实现的。 双亲委派模型的工作过程是：如果一个类加载器收到了类加载的请求，他会首先把这个请求委托给自己的父类加载器去完成，每一层次的加载器都是如此，最后所有的类加载请求最终都会传递到顶层的引导类加载器中去，只有当父类加载器无法完成这个加载请求(所请求加载的类不在 他加载的范围内)时，子类加载器会尝试自己加载。 双亲委派机制保证了java核心类库的安全，如果尝试加载与rt.jar类库中已有的类重名的java类，该类永远无法被加载运行，因为请求被传递到引导类加载器之后，引导类加载器会返回加载到的rt.jar中的类。 我们观察一下双亲委派机制的实现： 首先看一下ClassLoader中的方法： 1234567891011findLoadedClass：每个类加载器都维护有自己的一份已加载类名字空间，其中不能出现两个同名的类。凡是通过该类加载器加载的类，无论是直接的还是间接的，都保存在自己的名字空间中，该方法就是在该名字空间中寻找指定的类是否已存在，如果存在就返回给类的引用，否则就返回 null。这里的直接是指，存在于该类加载器的加载路径上并由该加载器完成加载，间接是指，由该类加载器把类的加载工作委托给其他类加载器完成类的实际加载。getSystemClassLoader：Java2 中新增的方法。该方法返回系统使用的 ClassLoader。可以在自己定制的类加载器中通过该方法把一部分工作转交给系统类加载器去处理。defineClass：该方法是 ClassLoader 中非常重要的一个方法，它接收以字节数组表示的类字节码，并把它转换成 Class 实例，该方法转换一个类的同时，会先要求装载该类的父类以及实现的接口类。loadClass：加载类的入口方法，调用该方法完成类的显式加载。通过对该方法的重新实现，我们可以完全控制和管理类的加载过程。findClass(String name): 查找名称为 name的类，返回的结果是 java.lang.Class类的实例。resolveClass(Class&lt;?&gt; c): 链接指定的 Java 类。 实现双亲委派机制的代码集中在ClassLoader的loadClass方法中。 12345678910111213141516171819202122232425262728293031323334353637protected Class&lt;?&gt; loadClass(String name, boolean resolve) throws ClassNotFoundException &#123; synchronized (getClassLoadingLock(name)) &#123; // First, check if the class has already been loaded Class c = findLoadedClass(name); if (c == null) &#123; long t0 = System.nanoTime(); try &#123; if (parent != null) &#123; c = parent.loadClass(name, false); &#125; else &#123; c = findBootstrapClassOrNull(name); &#125; &#125; catch (ClassNotFoundException e) &#123; // ClassNotFoundException thrown if class not found // from the non-null parent class loader &#125; if (c == null) &#123; // If still not found, then invoke findClass in order // to find the class. long t1 = System.nanoTime(); c = findClass(name); // this is the defining class loader; record the stats sun.misc.PerfCounter.getParentDelegationTime().addTime(t1 - t0); sun.misc.PerfCounter.getFindClassTime().addElapsedTimeFrom(t1); sun.misc.PerfCounter.getFindClasses().increment(); &#125; &#125; if (resolve) &#123; resolveClass(c); &#125; return c; &#125; &#125; 先检查是否已经加载过，若没有则调用父类加载器的loadClass方法，若父类加载器为空则默认使用启动类加载器作为父加载器。如果父类加载器加载失败，抛出ClassNotFoundException异常后，则调用自己的findClass方法进行加载。 双亲委托机制的不足双亲委派机制很好的解决了各个类加载器的基础类统一的问题，基础类总是作为被用户代码调用的API（比如rt.jar中的类）。但是如果基础类要调用用户的代码时会发生什么？ 首先要搞明白一点：当我们使用 new 关键字或者 Class.forName 来加载类时，所要加载的类都是由调用 new 或者 Class.forName 的类的类加载器进行加载的。比如我们使用JDBC标准接口时，JDBC标准接口存在于rt.jar中，在这个接口中又需要调用各个数据库厂商提供的jdbc驱动程序来达到管理驱动的目的，这些驱动程序的jar包一般置于claspath路径下。问题出现了：JDBC标准接口是由引导类加载器加载的，故在这些接口中调用classpath路径下的jdbc驱动代码时，也会尝试使用引导类加载器进行加载。但是引导类加载器根本不可能认识这些代码(只负责rt.jar)。 为了解决这个问题，引入了线程上下文类加载器。 这个类加载器可以通过java.lang.Thread类的setContextClassLoader()方法进行设置，如果创建线程时没有设置，将会从父线程中继承一个，如果在应用程序的全局范围内都没有设置，那么这个类加载器默认就是应用程序类加载器。 使用java.lang.Thread.getContextClassLoader()可以获得线程上下文类加载器，故可以使用这个加载器加载classpath路径下的代码，也就是父类加载器请求子类加载器完成类加载动作，破坏了双亲委托模型。 实现自己的类加载器上面提到的系统提供的类加载器在大多数情况下可以满足我们的需求，但是在某些情况下，我们需要开发自己的类加载器，比如，加载网络传输得到的类字节码、对字节码进行加密解码、加载运行时生成的字节码、实现类的热替换等。这些情况下类的字节码仅仅依靠上述的三种系统类加载器是无法加载的。 我自己实现了一些测试代码，现在将他们贴到这里，顺便对前面的总结做一个印证。下面的几个类都位于包space.kyu下面： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139class MyClassLoader1 extends ClassLoader&#123; @Override public Class&lt;?&gt; loadClass(String name) throws ClassNotFoundException &#123; try &#123; String fileName = name.substring(name.lastIndexOf(".") + 1) + ".class"; InputStream stream = getClass().getResourceAsStream(fileName); if (stream == null) &#123;// System.out.println("ClassLoader load class" + name); return super.loadClass(name); &#125; byte[] bs = new byte[stream.available()]; stream.read(bs);// System.out.println("MyClassLoader1 load class: " + name); return defineClass(name, bs, 0, bs.length); &#125; catch (IOException e) &#123; throw new ClassNotFoundException(name); &#125; &#125;&#125;public class MyClassLoader2 extends ClassLoader &#123; public Class&lt;?&gt; loadDirectly(String name) throws ClassNotFoundException &#123; try &#123; String fileName = name.substring(name.lastIndexOf(".") + 1) + ".class"; InputStream stream = getClass().getResourceAsStream(fileName); if (stream == null) &#123;// System.out.println("ClassLoader load class" + name); return super.loadClass(name); &#125; byte[] bs = new byte[stream.available()]; stream.read(bs);// System.out.println("MyClassLoader2 load class: " + name); return defineClass(name, bs, 0, bs.length); &#125; catch (IOException e) &#123; throw new ClassNotFoundException(name); &#125; &#125;&#125;public interface Operation &#123; void doSomething();&#125;public class Test &#123; public String str; public Test(String str) &#123; this.str = str; &#125; public void test() &#123; System.out.println(str); &#125;&#125;public class TestClass implements Operation&#123; public Test test; @Override public void doSomething() &#123; System.out.println("hello"); &#125; public Test test()&#123; test = new Test("haha"); System.out.println(test.str); return test; &#125;&#125;public class ClassLocaderTest &#123; public static void main(String[] args) &#123; Object testClassLoader1 = getMyClassLoader1(); Object testClassLoader2 = getMyClassLoader2(); System.out.println("*****************testClassLoader1*******************"); printClassLoader(testClassLoader1); reflectInvoke(testClassLoader1); interfaceInvoke(testClassLoader1); System.out.println("*****************testClassLoader2*******************"); printClassLoader(testClassLoader2); reflectInvoke(testClassLoader2); interfaceInvoke(testClassLoader2); &#125; static void printClassLoader(Object object) &#123; System.out.println("*********printClassLoader:"); ClassLoader classLoader = object.getClass().getClassLoader(); while (classLoader != null) &#123; System.out.println(classLoader); classLoader = classLoader.getParent(); &#125; &#125; static void reflectInvoke(Object obj) &#123; System.out.println("*********reflectInvoke:"); try &#123; Method test = obj.getClass().getMethod("test", new Class[] &#123;&#125;); test.invoke(obj, new Object[] &#123;&#125;); Method doSomething = obj.getClass().getMethod("doSomething", new Class[] &#123;&#125;); doSomething.invoke(obj, new Object[] &#123;&#125;); &#125; catch (InvocationTargetException e) &#123; Throwable t = e.getTargetException();// 获取目标异常 System.out.println(t); &#125; catch (Exception e) &#123; System.out.println(e); &#125; &#125; static void interfaceInvoke(Object obj) &#123; System.out.println("*********interfaceInvoke:"); try &#123; Operation operation = (Operation) obj; operation.doSomething(); &#125; catch (Exception e) &#123; System.out.println(e); &#125; &#125; static Object getMyClassLoader1() &#123; Object obj = null; try &#123; MyClassLoader1 loader = new MyClassLoader1(); obj = loader.loadClass("space.kyu.TestClass").newInstance(); &#125; catch (Exception e) &#123; System.out.println(e); &#125; return obj; &#125; static Object getMyClassLoader2() &#123; Object obj = null; try &#123; MyClassLoader2 loader = new MyClassLoader2(); obj = loader.loadDirectly("space.kyu.TestClass").newInstance(); &#125; catch (Exception e) &#123; System.out.println(e); &#125; return obj; &#125;&#125; 上述六个类位于space.kyu下不同的类文件当中。ClassLocaderTest运行结果： 1234567891011121314151617181920*****************testClassLoader1****************************printClassLoader:space.kyu.MyClassLoader1@76e2d0absun.misc.Launcher$AppClassLoader@52a53948sun.misc.Launcher$ExtClassLoader@5d53d05b*********reflectInvoke:hahahello*********interfaceInvoke:java.lang.ClassCastException: space.kyu.TestClass cannot be cast to space.kyu.Operation*****************testClassLoader2****************************printClassLoader:space.kyu.MyClassLoader2@6c618821sun.misc.Launcher$AppClassLoader@52a53948sun.misc.Launcher$ExtClassLoader@5d53d05b*********reflectInvoke:hahahello*********interfaceInvoke:hello 一般来说，我们自己开发的类加载器只要继承ClassLoader并覆盖findClass方法即可。这样的话就会自动使用双亲委派机制，我们可以在findClass方法中填写我们自己的加载逻辑：从网络上或者是硬盘上加载一个类的字节码。 上面的例子中并没有使用这个套路，MyClassLoader1直接复写loadClass方法，MyClassLoader2添加了方法loadDirectly，如果不这样做的话，我们在加载space.kyu.TestClass这个类的时候，因为这个类在classpath上，由于双亲委派机制，这个类会被应用程序类加载器先进行加载，达不到测试的效果。 观察上面printClassLoader部分，通过getParent方法打印了类加载器的层次结构。可见虽然我们并未显示指定这两个自定义加载器的父类加载器，但是他们的父类加载器已经被默认设置为sun.misc.Launcher$AppClassLoader，也就是加载这两个个自定义类加载器所使用的加载器。印证上面的结论：对于开发人员编写的类加载器来说，其父类加载器是加载此类加载器 Java 类的类加载器。 reflectInvoke方法是使用反射机制调用了加载出来类的方法，如果去掉上面自定义类加载器中注掉的System.out方法，就会看到，在反射调用TestClass的test方法的时候，类加载器加载了space.kyu.Test这个类，并且加载他的类加载器正是我们自定义的类加载器，印证了我们上面的结论：当我们使用 new 关键字或者 Class.forName 来加载类时，所要加载的类都是由调用 new 或者 Class.forName 的类的类加载器进行加载的 思考上面的反射用法，为什么不直接将getMyClassLoader1()方法返回的Object对象强转为space.kyu.TestClass呢？比如这样： space.kyu.TestClass testClass = (TestClass)getMyClassLoader1(); 编译并没有问题，但是在运行时就会报错：java.lang.ClassCastException 为什么会出现这样的结果呢？其实从这篇文章的一开始就已经演示过了。space.kyu.TestClass testClass这个类是通过应用程序类加载器加载的，而getMyClassLoader1()方法得到的是我们自定义类加载器加载的类，这两个类是不相等的(虽然名字相同)，所以强转失败。 接下来看interfaceInvoke这部分。将自定义类加载器加载得到的对象强转为了接口类型。注意到，MyClassLoader1加载的类对象在强转时抛出异常，而MyClassLoader2可以正常强转并调用接口方法。 MyClassLoader1加载的类为什么强转失败？原因在于，MyClassLoader1在加载TestClass类时，触发其父类接口Operation的加载，此时默认使用MyClassLoader1加载Operation类。在MyClassLoader1中我们覆盖了loadClass方法，故加载Operation时也会调用我们自己实现的loadClass方法进行加载。 同样的，MyClassLoader2在加载TestClass类时，也触发其父类接口Operation的加载，此时默认使用MyClassLoader2加载Operation类。不同之处在于我们并未覆盖loadClass方法，加载Operation时调用了ClassLoader中的loadClass方法，在这个方法的实现中，由应用程序类加载器加载了Operation类。 所以，出现上面结果的原因也就一目了然了。 类加载器与热替换普通的java应用中不能实现类的热替换的原因在于同名类的不同版本的实例不能共存，因为使用了默认的类加载机制后，一个类只会被加载一次，再次请求加载时直接返回之前加载的缓存(findLoadedClass)。故我们重新编译生成的class文件并不会被重新读取并加载。 为了绕过这个加载机制，我们可以通过不同的类加载器来加载该类的不同版本。 在space.kyu包下面新增一个类HotSwapTest：12345678910111213141516171819202122public class HotSwapTest &#123; public static void main(String[] args) &#123; Timer timer = new Timer(false); TimerTask task = new TimerTask() &#123; public void run() &#123; update(); &#125; &#125;; timer.schedule(task, 1000, 2000); &#125; public static void update() &#123; try &#123; MyClassLoader2 loader = new MyClassLoader2(); Object obj = loader.loadDirectly("space.kyu.TestClass").newInstance(); Method doSomething = obj.getClass().getMethod("doSomething", new Class[] &#123;&#125;); doSomething.invoke(obj, new Object[] &#123;&#125;); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125;&#125; 在HotSwapTest类中，我们模拟了一个定时升级的任务：每隔两秒执行一次升级，实例化一个MyClassLoader2对象并使用该类加载器加载space.kyu.TestClass，反射调用其doSomething方法打印字符串。 编译并运行HotSwapTest，运行过程中，每隔两秒doSomething便打印字符串”hello”，此时修改space.kyu.TestClass源码，将打印字符串替换为”world”，CTRL+S，我们的程序并未停止，但是下一次打印出的字符串已然不同了： 12345678hellohellohellohellohelloworldworldworld 上面就是一个简单的热替换的例子。实际的应用中当然不是通过一个定时任务进行升级的。把新版本类的字节码通过网络传输到服务器上去，然后发送一个升级指令，使用上面类似的方法便可对类进行升级。 参考Java 类的热替换 —— 概念、设计与实现 深入探讨 Java 类加载器]]></content>
      <categories>
        <category>编程</category>
      </categories>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[java注解]]></title>
    <url>%2F2017%2F03%2F31%2Fjava%E6%B3%A8%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[在写java代码的过程中，经常会遇到注解，但是没有去理解注解背后的原理，也没有实现过注解。网上关于java注解的文章已经有很多了，参考了一些资料，整理一下注解这方面的知识~ 什么是注解注解其实很常见。比如@override、Deprecated等。在使用Junit或Spring boot等一些框架的时候，注解更是无处不在了。那么，到底什么是注解呢？ 123Annotations, a form of metadata, provide data about a program that is not part of the program itself. Annotations have no direct effect on the operation of the code they annotate. &gt;&gt;[https://docs.oracle.com/javase/tutorial/java/annotations/] 注解是元数据的一种，提供了关于程序的一些描述信息，但这些信息并不属于这个程序本身的一部分。注解并不会直接影响到代码的执行。 翻译起来有点拗口。实际上，注解是那些插入到源代码中用于某种工具进行处理的标签。注解不会改变对编写的程序的编译方式，对于包含和不包含注解的代码，java编译器都会生成相同的虚拟机指令。 一句话来说，注解只是描述代码的标签。注解本身不会做什么事情，为了使注解起到作用来实现一些黑科技，我们还需要用于处理注解的工具(编写代码处理这些注解)。 我们使用注解可以： 生成文档 在编译时进行检查。比如@override 替代配置文件，实现自动配置。比如 Springboot 注解Annotation是在jdk1.5之后引进的，jdk1.8之后又增加了一些新的特性。接下来的讨论基于jdk1.7。 注解的使用在java中，注解是当做一个修饰符(比如public或static之类的关键词)来使用的。注解可以存在于： 包 | 类(包括enum) | 接口(包括注解接口) | 方法 | 构造器 | 成员变量 | 本地变量 | 方法参数 注意： 1.对于包的注解，需要在package-info.java中声明。 2.对于本地变量的注解，只能在源码级别上进行处理。所有的本地变量注解在类编译完之后会被遗弃掉。 假如有这样一个注解：(注解的定义见下文) 12345@interface Result &#123; String name() default &quot;&quot;; int value() default -1; String res() default &quot;&quot;;&#125; 我们可以这样使用它： @Result(name=&quot;res1&quot;,value=1) 括号中元素的顺序无关紧要 @Result(value=1,name=&quot;res1&quot;)等价于@Result(name=&quot;res1&quot;,value=1) 如果元素值没有指定，则使用默认值：(没有声明默认值时必须指定元素值) @Result等价于@Result(name=&quot;&quot;,value=-1,&quot;&quot;) 如果元素的名字为特殊值value，那么可以忽略这个元素名和等号： @Result(1)等价于@Result(name=&quot;&quot;,value=1,&quot;&quot;) 如果元素是数组，那么他的值要用括号括起来： @Result(res={&quot;a&quot;,&quot;b&quot;}) 如果数组是单值，可以忽略这些括号： @Result(res=&quot;a&quot;) 注解分类根据注解的用途和使用方式，注解可以分为以下几类： 元注解：注解注解的注解。也就是用来描述注解定义的注解 预定义注解：jdk内置的一些注解 自定义注解：我们自己定义的注解 元注解 元注解包含下面几个： @Target: 指定这个注解可以应用于哪些项 12345678910111213141516171819202122232425public enum ElementType &#123; /** Class, interface (including annotation type), or enum declaration */ TYPE, /** Field declaration (includes enum constants) */ FIELD, /** Method declaration */ METHOD, /** Parameter declaration */ PARAMETER, /** Constructor declaration */ CONSTRUCTOR, /** Local variable declaration */ LOCAL_VARIABLE, /** Annotation type declaration */ ANNOTATION_TYPE, /** Package declaration */ PACKAGE&#125; 比如，我们定义了一个注解Bug，该注解只能应用于方法或成员变量： 1234@Target(&#123;ElementType.METHOD,ElementType.FIELD&#125;)@interface Bug&#123; int value() default -1;&#125; 注解Bug则只能用于类方法或成员变量，如果注解了其他项比如类或者包，编译则不会通过。 对于一个没有声明@Target的注解，可以应用到任何项上。 @Retention: 指定这个注解可以保留多久 123456789101112131415161718192021public enum RetentionPolicy &#123; /** * Annotations are to be discarded by the compiler. */ SOURCE, /** * Annotations are to be recorded in the class file by the compiler * but need not be retained by the VM at run time. This is the default * behavior. */ CLASS, /** * Annotations are to be recorded in the class file by the compiler and * retained by the VM at run time, so they may be read reflectively. * * @see java.lang.reflect.AnnotatedElement */ RUNTIME&#125; SOURCE：只存在于源代码，编译成.class之后就没了 CLASS: 保留到类文件中，但是虚拟机不会载入 RUNTIME：保留到类文件中，并且虚拟机会载入。这意味着通过反射可以获取到这些注解和注解元素值 默认情况下(没有声明@Retention)，注解保留级别为CLASS @Document：指定这个注解应该包含在文档中 文档化的注解意味着像javadoc这样的工具生成的文档中会包含这些注解。比如： 12345@Documented@Retention(RetentionPolicy.RUNTIME)@Target(value=&#123;CONSTRUCTOR, FIELD, LOCAL_VARIABLE, METHOD, PACKAGE, PARAMETER, TYPE&#125;)public @interface Deprecated &#123;&#125; @Deprecated是文档化的注解，URLDecoder.decode(String s)方法应用了这个注解： 可以在文档中看到Deprecated的出现。 @Inherited: 指定一个注解，当他应用于一个类的时候，能够自动被其子类继承 @Inherited只能应用于对类的注解。如果一个类具有继承注解，那么他的所有子类都自动具有同样的注解。 比如，定义了一个继承注解@Secret表示一个类是隐私的不可被序列化传输的，那么该类的子类会被自动注解为不可序列化传输的。 1234567@Inherited@interface Secret&#123;&#125;@Secret class A&#123;&#125;class B extends A&#123;&#125; //同样是@Secret的 当注解工具去获取声明了@Secret的对象时，他能够获取到A的对象和B的对象。 预定义注解 常用的有三个：@override、@Deprecated、@SuppressWarnings，具体的作用可以查文档或者源码，不再赘述。 注解的定义上面的讨论中已经涉及到了注解的定义。一个注解是由一个注解接口来定义的： 1234@interface Result &#123; String name(); int value() default -1;&#125; 每个元素的声明有两种形式，有默认值和没有默认值的，就像上面那样。注解的元素可以是下面之一： 基本类型|String|Class类型|enum|注解类型|由前面所述类型构成的数组 123456789@interface BugReport&#123; enum Status&#123;FIXED,OPEN,NEW,CLOSE&#125;; boolean isIgnore() default false; String id(); Class&lt;?&gt; testCase() default Void.class; Status status() default Status.NEW; Author author() default @Author; String[] reportMsg() default &quot;&quot;;&#125; 注意，虽然注解元素可以是另一个注解，但是不能在注解中引入循环依赖，比如@BugReport依赖@Author，而@Author又依赖@BugReport。同时，注解元素也不可以为null，元素的值必须是编译期常量。 我们可以通过在注解的定义前声明之前提到的元注解来定制我们的注解，比如： 123456789@Target(&#123; ElementType.METHOD, ElementType.FIELD &#125;)@Inherited@Documented@Retention(RetentionPolicy.RUNTIME)@interface Result &#123; String name() default &quot;&quot;; int value() default -1; String[] reportMsg() default &quot;&quot;;&#125; 所有的注解接口隐式的继承自java.lang.annotation.Annotation接口。这是一个正常的接口，而不是注解接口。123456public interface Annotation &#123; boolean equals(Object obj); int hashCode(); String toString(); Class&lt;? extends Annotation&gt; annotationType();&#125; 也就是说，注解接口也是普通接口的一种。注解接口中的元素实际上也是方法的声明，这些方法类似于bean的get、set，我们使用@Result(name=”A”)的形式实际上是调用了set方法给某个变量赋值。 既然是接口，那么就应该有实现(不然怎么用呢？)。我们不需要主动提供实现了注解接口的类，虚拟机会在需要的时候产生一些代理类和对象。下文会提到。 既然可以为注解元素赋值，那么必定有方法去获得这些值。也就是注解的解析。 注解的解析我们定义了注解并且应用了注解，但是仅仅这样的话注解并不会起到什么作用。需要我们提供一种工具去解析声明的注解，然后实现一些自动配置或者生成报告的功能。这就是注解的解析。 源代码中的注解 注解的用处之一就是自动生成一些包含程序额外信息的文件。比如，根据注解生成代码进度报告，或者bug修复报告等。生成的文件可以是属性文件、xml文件、html文档或者shell脚本。也可以生成java源文件。 注解处理器通常通过集成AbstractProcessor类实现了Processor接口，通过process方法实现处理源码中注解的逻辑。通过声明具体的注解类型来指定该处理器处理哪些注解。 12345678910@SupportedAnnotationTypes(&quot;space.yukai.annotations.BUG&quot;)class AnnotationProcessor extends AbstractProcessor &#123; @Override public boolean process(Set&lt;? extends TypeElement&gt; annotations, RoundEnvironment roundEnv) &#123; // TODO Auto-generated method stub return false; &#125; &#125; process的两个参数：annotations代表了要处理的注解集，roundEnv是包含有关当前处理循环信息的RoundEnv引用。 Java注解处理器这篇文章以通过注解自动生成工厂类文件为例，详细介绍了如何处理源码级别的注解。（英文原文在这：http://hannesdorfmann.com/annotation-processing/annotationprocessing101） 注意，我们虽然可以通过源码级别的注解处理器生成新的文件，却很难编辑源文件，比如，通过处理注解自动生成get、set方法。字节码级别的处理器是可以的。 字节码中的注解 字节码级别的注解，即存在于class文件中的注解。我们还可以通过BCEL这样的字节码工程类库修改或插入字节码来改变类文件。比如在声明了@LogEntity的方法开始部分插入打印日志信息的字节码。 涉及的不多，不再赘述。 运行时的注解 在运行时处理注解是比较常见的注解处理手段。一般是通过反射API获取到我们的注解信息，从而实现一些功能。 下面是自己写的一个例子，通过解析BugReport注解得到一些测试信息，然后通过动态代理的方式生成代理测试类，最后运行测试自动生成测试报告。（不要在意代码有什么缺陷或者其他问题，仅仅是一个例子而已～） 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111package space.kyu.proxy;import java.lang.annotation.ElementType;import java.lang.annotation.Retention;import java.lang.annotation.RetentionPolicy;import java.lang.annotation.Target;import java.lang.reflect.InvocationHandler;import java.lang.reflect.Method;import java.lang.reflect.Proxy;import java.util.ArrayList;import java.util.List;public class AnnotationsTest &#123; public static void main(String[] args) &#123; TestBug testBug = new TestBug(true); TestBug testBug1 = new TestBug(false); TestExecutor executor = new TestExecutor(); executor.addTest(testBug); executor.addTest(testBug1); executor.executeTest(); &#125;&#125;class TestExecutor &#123; private List&lt;Test&gt; testCases; public TestExecutor() &#123; testCases = new ArrayList&lt;Test&gt;(); &#125; public &lt;T extends Test&gt; void addTest(T testCase) &#123; Class&lt;? extends Object&gt; cl = testCase.getClass(); Method[] declaredMethods = cl.getDeclaredMethods(); try &#123; for (Method method : declaredMethods) &#123; if (method.isAnnotationPresent(BugReport.class)) &#123; BugReport annotation = method.getAnnotation(BugReport.class); if (annotation != null) &#123; System.out.println(annotation.toString()); System.out.println(annotation.annotationType().getName()); System.out.println(annotation.getClass().getName()); String bugId = annotation.id(); String bugMsg = annotation.msg(); Test obj = (Test) createBugReportHandler(testCase,bugId,bugMsg); testCases.add(obj); &#125; &#125; &#125; &#125; catch (Exception e) &#123; e.printStackTrace(); throw new IllegalStateException(e); &#125; &#125; public void executeTest() &#123; for (Test test : testCases) &#123; test.test(); &#125; &#125; private Object createBugReportHandler(Test testCase, final String bugId, final String bugMsg) &#123; return Proxy.newProxyInstance(testCase.getClass().getClassLoader(), testCase.getClass().getInterfaces(), new InvocationHandler() &#123; @Override public Object invoke(Object proxy, Method method, Object[] args) throws Throwable &#123; boolean res = (boolean) method.invoke(testCase, args); //也可以输出到文件中形成测试报告 System.out.println(&quot;******************************&quot;); System.out.println(&quot;bug: &quot; + bugId + &quot;测试结果：&quot;); if (res) &#123;//测试通过 System.out.println(&quot;已通过&quot;); &#125; else &#123;//测试不通过 System.out.println(&quot;未通过&quot;); &#125; System.out.println(&quot;备注信息：&quot; + bugMsg); return res; &#125; &#125;); &#125;&#125;interface Test &#123; /** * 测试方法 2017年4月1日 * @return * true 通过测试 * false 未通过测试 */ boolean test();&#125;class TestBug implements Test &#123; boolean fixed; public TestBug(boolean fixed) &#123; //控制测试成功或失败 this.fixed = fixed; &#125; @BugReport(id = &quot;bug001&quot;, msg = &quot;bug注释：这是一条测试bug&quot;) @Override public boolean test() &#123; System.out.println(&quot;执行测试...&quot;); //假装测试成功或者失败了 return fixed; &#125;&#125;@Target(ElementType.METHOD)@Retention(RetentionPolicy.RUNTIME)@interface BugReport &#123; String id(); String msg();&#125; 运行结果： 12345678910111213141516@space.kyu.proxy.BugReport(id=bug001, msg=bug注释：这是一条测试bug)space.kyu.proxy.BugReportspace.kyu.proxy.$Proxy1@space.kyu.proxy.BugReport(id=bug001, msg=bug注释：这是一条测试bug)space.kyu.proxy.BugReportspace.kyu.proxy.$Proxy1执行测试...******************************bug: bug001测试结果：已通过备注信息：bug注释：这是一条测试bug执行测试...******************************bug: bug001测试结果：未通过备注信息：bug注释：这是一条测试bug 上面的代码很简单，我们要注意的有几点： 1.method.isAnnotationPresent(BugReport.class)和 method.getAnnotation(BugReport.class) 这两个方法来自于接口AnnotatedElement，Method、Field、Package、Constructor、Class这些类都实现了这个接口，使得这些类拥有了提供所声明的注解的功能。 通过method.getAnnotation(BugReport.class)得到了声明在方法上的BugReport注解，获得这个注解的实例之后，我们就可以调用以该注解声明的元素为名称的方法来获取对应的元素值了。 2.annotation.annotationType().getName()和annotation.getClass().getName() annotation.annotationType()方法上面已经提到过了，是Annotation的一个方法，用于描述该注解对象的注解接口。这个方法返回的内容为：space.kyu.proxy.BugReport annotation.getClass()获得了实现了Annotation接口的代理类，通过调用getName()方法可以打印这个代理类的名称：space.kyu.proxy.$Proxy1。从而印证了我们上面所说，确实自动生成了代理类。 上面的例子很简单，说白了，注解就是给代码加了一些额外的信息，这些信息对代码里面的逻辑是没有任何影响的。但是我们可以通过其他手段获得我们在代码中的注解，从而实现一些重复性的工作。这就是注解的作用。]]></content>
      <categories>
        <category>编程</category>
      </categories>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[java代理机制]]></title>
    <url>%2F2017%2F03%2F28%2Fjava%E4%BB%A3%E7%90%86%E6%9C%BA%E5%88%B6%2F</url>
    <content type="text"><![CDATA[代理模式代理模式，顾名思义，即一个客户不想或者不能直接访问一个对象，需要通过一个称为代理的第三方对象来实现间接引用。代理对象的作用就是客户端和目标对象之间的一个中介，通过代理对象可以隐藏不让用户看到的内容或实现额外的服务。 代理机制应用的场景有很多：比如在代理对象中实现缓存，验证，权限控制等功能，真正的业务逻辑封装在真实对象中。RMI远程方法调用也用到了代理。当你调用一个远程方法的时候，相当于调用这个方法的代理对象，在代理对象中封装了网络请求等部分，真实对象存在于另一个进程上。重构老旧代码的时候也常常会用到代理模式。 代理分两种：静态代理和动态代理 静态代理静态代理即在代码中手动实现代理模式。代理模式涉及到三个角色： 真实对象RealSubject、抽象主题Subject、代理对象Proxy 12345678910111213141516171819202122232425262728293031323334public class ProxyTest &#123; public static void main(String[] args) &#123; new Proxy(&quot;hello&quot;).request(); &#125;&#125;interface Subject &#123; void request();&#125;class Proxy implements Subject&#123; String str; RealSubject subject; public Proxy(String string) &#123; str = string; subject = new RealSubject(str); &#125; @Override public void request() &#123; System.out.println(&quot;代理对象验证机制....&quot;); subject.request(); &#125; &#125;class RealSubject implements Subject&#123; String str; public RealSubject(String string) &#123; str = string; &#125; @Override public void request() &#123; System.out.println(&quot;真实对象打印str: &quot; + str); &#125; &#125; 输出：12代理对象验证机制....真实对象打印str: hello 上面的代码模拟了一个代理对象实现验证机制的过程。可以看到，代码很简单，代理模式也很好理解。（我们在真实生活中不也有代理么,,比如黄牛，帮你买到你买不到的火车票） JDK动态代理实现动态代理时较为高级的一种代理模式。典型的应用有Spring AOP，RMI。 在上面的静态代理模式中，真实对象是事先存在的，并且作为代理对象的内部成员属性。一个真实的对象必须对应一个代理对象，如果真实对象很多的话会导致类膨胀。 另外，如何在事先不知道真实对象的情况下使用代理代理对象，这都是动态代理需要解决的问题。 比如有n个类需要在执行前打印几行日志，而这n个类是无法通过源代码修改的(从jar包中引入的)。通过静态代理实现的话将会有n个新的代理类产生，而使用动态代理的话，只需一个类即可。 动态代理的实现方式有很多，我们只讨论JDK中的动态代理实现。 12345678910111213141516171819202122232425262728293031323334353637383940import java.lang.reflect.InvocationHandler;import java.lang.reflect.Method;import java.lang.reflect.Proxy;public class DynamicProxyTest &#123; public static void main(String[] args) &#123; Subject subject = (Subject) new DynamicProxy().bind(new RealSubject(&quot;hello&quot;)); subject.request(); &#125;&#125;interface Subject &#123; void request();&#125;class RealSubject implements Subject&#123; String str; public RealSubject(String string) &#123; str = string; &#125; @Override public void request() &#123; System.out.println(&quot;真实对象打印str: &quot; + str); &#125;&#125;class DynamicProxy implements InvocationHandler &#123; Object object; public Object bind(Object object) &#123; this.object = object; return Proxy.newProxyInstance(object.getClass().getClassLoader(), object.getClass().getInterfaces(), this); &#125; @Override public Object invoke(Object proxy, Method method, Object[] args) throws Throwable &#123; System.out.println(&quot;代理对象验证...&quot;); return method.invoke(object, args); &#125;&#125; 输出：12代理对象验证...真实对象打印str: hello 可以看到，动态代理实现了与静态代理一样的功能，但他的优点在于代理的真实对象不是确定的，可以在运行时指定，增大了灵活性。如果我们有很多的真实对象需要代理访问，并且他们代理对象中的内容都实现了相同的功能，那么我们只需要一个动态代理类即可。 动态代理原理我们通过观察java.lang.reflect.Proxy的源码来了解动态代理的原理。下面的代码截取自openjdk7-b147 (安利一个不错的搜索java源码的网站:http://grepcode.com) 上面的方法截取自Proxy.newProxyInstance，可以看到，调用getProxyClass方法获取到一个代理类class对象，然后使用该class对象通过反射方法实例化一个对象返回。 接下来观察getProxyClass方法。 这部分代码截取自getProxyClass，先从缓存中查询是否已经生成过对应的class，若有，则直接返回该对象，没有，则继续下一步生成class 这部分代码是代理类class对象的生成过程。其中： byte[] proxyClassFile = ProxyGenerator.generateProxyClass(proxyName, interfaces);这行代码调用ProxyGenerator.generateProxyClass返回了代理类class对象的字节码byte序列，proxyClass = defineClass0(loader, proxyName,proxyClassFile, 0, proxyClassFile.length);这一行则进行了类加载的工作，最终生成了代理类class对象。 generateProxyClass，其中的gen.generateClassFile()方法实现了字节码的生成。 generateClassFile方法的实现。开头调用的三个addProxyMethod方法将object类中的hashcode、equals、toString方法重写，故对这三个方法的调用会传递到InvocationHandler.invoke方法当中。注意，除了上述三个方法之外，调用代理类中Object定义的其他方法不会传递到invoke方法当中，也就是说，调用这些方法会执行Object中的默认实现。 如果想要查看ProxyGenerator.generateProxyClass这个方法在运行时产生的代理类中写了些什么，可以在main方法中加入： 1System.getProperties().put(&quot;sun.misc.ProxyGenerator.saveGeneratedFiles&quot;, &quot;true&quot;); 运行时会将生成的class文件保存到硬盘当中：$Proxy0.class 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104import java.lang.reflect.InvocationHandler;import java.lang.reflect.Method;import java.lang.reflect.Proxy;import java.lang.reflect.UndeclaredThrowableException;public final class $Proxy0 extends Proxy implements Subject&#123; private static Method m1; private static Method m3; private static Method m0; private static Method m2; public $Proxy0(InvocationHandler paramInvocationHandler) &#123; super(paramInvocationHandler); &#125; public final boolean equals(Object paramObject) &#123; try &#123; return ((Boolean)this.h.invoke(this, m1, new Object[] &#123; paramObject &#125;)).booleanValue(); &#125; catch (Error|RuntimeException localError) &#123; throw localError; &#125; catch (Throwable localThrowable) &#123; throw new UndeclaredThrowableException(localThrowable); &#125; &#125; public final void request() &#123; try &#123; this.h.invoke(this, m3, null); return; &#125; catch (Error|RuntimeException localError) &#123; throw localError; &#125; catch (Throwable localThrowable) &#123; throw new UndeclaredThrowableException(localThrowable); &#125; &#125; public final int hashCode() &#123; try &#123; return ((Integer)this.h.invoke(this, m0, null)).intValue(); &#125; catch (Error|RuntimeException localError) &#123; throw localError; &#125; catch (Throwable localThrowable) &#123; throw new UndeclaredThrowableException(localThrowable); &#125; &#125; public final String toString() &#123; try &#123; return (String)this.h.invoke(this, m2, null); &#125; catch (Error|RuntimeException localError) &#123; throw localError; &#125; catch (Throwable localThrowable) &#123; throw new UndeclaredThrowableException(localThrowable); &#125; &#125; static &#123; try &#123; m1 = Class.forName(&quot;java.lang.Object&quot;).getMethod(&quot;equals&quot;, new Class[] &#123; Class.forName(&quot;java.lang.Object&quot;) &#125;); m3 = Class.forName(&quot;Subject&quot;).getMethod(&quot;request&quot;, new Class[0]); m0 = Class.forName(&quot;java.lang.Object&quot;).getMethod(&quot;hashCode&quot;, new Class[0]); m2 = Class.forName(&quot;java.lang.Object&quot;).getMethod(&quot;toString&quot;, new Class[0]); return; &#125; catch (NoSuchMethodException localNoSuchMethodException) &#123; throw new NoSuchMethodError(localNoSuchMethodException.getMessage()); &#125; catch (ClassNotFoundException localClassNotFoundException) &#123; throw new NoClassDefFoundError(localClassNotFoundException.getMessage()); &#125; &#125;&#125; 上面的代码很好理解。可以看到equals、hashCode、toString以及我们Subject接口request方法的实现中都是调用了InvocationHandler.invoke方法，而这个InvocationHandler实例就是我们在Proxy.newProxyInstance中传入的对象。 综上，可以看到实现动态代理的几个步骤： 1.实现InvocationHandler 2.获得动态代理类，这一步又涉及到运行时代理类字节码的生成和类加载 3.通过反射机制（getConstructor(InvocationHandler.class)）获取代理类的实例并返回该对象 4.调用代理对象的目标方法（也就是request方法，代理类也实现了Subject这个接口），调用转发到InvocationHandler.invoke方法当中，执行invoke的逻辑（我们自己的InvocationHandler实现） 至此，我们就了解了动态代理的运行原理。动态代理的机制也有一些缺陷，比如他代理的必须是接口方法。看一下我们上面生成的$Proxy0.class，可知这个代理类已经默认继承了类Proxy，所以，他只能通过实现我们提供的接口来代理我们的方法。在invoke方法中，我们可以通过对传入的代理类、方法和参数来进行判断，对不同的方法实现不同的业务逻辑。]]></content>
      <categories>
        <category>编程</category>
      </categories>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[java序列化与反序列化]]></title>
    <url>%2F2017%2F03%2F22%2Fjava%E5%BA%8F%E5%88%97%E5%8C%96%E4%B8%8E%E5%8F%8D%E5%BA%8F%E5%88%97%E5%8C%96%2F</url>
    <content type="text"><![CDATA[什么是序列化所谓的序列化，即把java对象以二进制形式保存到内存、文件或者进行网络传输。从二进制的形式恢复成为java对象，即反序列化。 通过序列化可以将对象持久化，或者从一个地方传输到另一个地方。这方面的应用有RMI，远程方法调用。 java中实现序列化有两种方式，实现Serializable接口或者Externalizable接口。这篇总结只讨论Serializable的情况。 123456789101112131415161718public class SerializeTest implements Serializable&#123; private static final long serialVersionUID = 1L; public String str; public SerializeTest(String str) &#123; this.str = str; &#125; public static void main(String[] args) throws IOException, ClassNotFoundException &#123; SerializeTest test = new SerializeTest(&quot;hello&quot;); ByteArrayOutputStream oStream = new ByteArrayOutputStream(); ObjectOutputStream objectOutputStream = new ObjectOutputStream(oStream); objectOutputStream.writeObject(test);//序列化 ObjectInputStream inputStream = new ObjectInputStream(new ByteArrayInputStream(oStream.toByteArray())); SerializeTest obj = (SerializeTest) inputStream.readObject();//反序列化 System.out.println(obj.str); &#125;&#125; 上面的代码演示了类SerializeTest实现序列化和反序列化的过程。 所有的序列化和反序列化过程都是java默认实现的，你只需要实现接口Serializable，就能得到一个实现了序列化的类。通过ObjectOutputStream和ObjectInputStream分别将序列化对象输出或者写入到某个流当中。流的目的地可以是内存字节数组(上例)、文件、或者网络。 下面研究一下序列化过程中的几个问题： 静态变量如何序列化12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849public class SeriaUtil &#123; ByteArrayInputStream bInputStream; ByteArrayOutputStream byOutputStream; ObjectOutputStream outputStream ; ObjectInputStream inputStream; public void seria(Object test) throws IOException &#123; if (byOutputStream == null) &#123; byOutputStream = new ByteArrayOutputStream(); &#125; if (outputStream == null) &#123; outputStream = new ObjectOutputStream(byOutputStream); &#125; outputStream.writeObject(test);// System.out.println(byOutputStream.toByteArray().length); &#125; public Object reSeria() throws IOException, ClassNotFoundException &#123; if (bInputStream == null) &#123; bInputStream = new ByteArrayInputStream(byOutputStream.toByteArray()); &#125; if (inputStream == null) &#123; inputStream = new ObjectInputStream(bInputStream); &#125; Object obj = inputStream.readObject(); return obj; &#125;&#125;public class StaticTest implements Serializable&#123; private static final long serialVersionUID = 1L; public static int A = 0; public static String B = &quot;hello&quot;; public static void main(String[] args) throws IOException, ClassNotFoundException &#123; //先序列化类，此时 A=0 B = hello SeriaUtil seriaUtil = new SeriaUtil(); StaticTest test = new StaticTest(); seriaUtil.seria(test); //修改 静态变量的值 StaticTest.A = 1; StaticTest.B = &quot;world&quot;; StaticTest obj = (StaticTest) seriaUtil.reSeria(); //输出 A = 1 B = world System.out.println(obj.A); System.out.println(obj.B); &#125;&#125; 上面的代码说明了，静态变量不会被序列化。 序列化StaticTest实例test时，静态变量 A=0 B=”hello”，序列化之后，修改StaticTest类的静态变量值，A=1 B=”world”，此时反序列化得到之前序列化的实例对象赋给obj，发现obj的静态变量变为A=1 B=”world”，说明静态变量并未序列化成功。 事实上，在序列化对象时，会忽略对象中的静态变量。很好理解，静态变量是属于类的，而不是某个对象的状态。我们序列化面向的是对象，是想要将对象的状态保存下来，所以静态变量不会被序列化。反序列化得到的对象中的静态变量的值是当前jvm中静态变量的值。静态变量对于同一个jvm中同一个类加载器加载的类来说，是一样的。对于同一个静态变量，不会存在同一个类的不同实例拥有不同的值。 同一对象序列化两次，反序列化后得到的两个对象是否相等这个问题提到的相等，是指是否为同一对象，即==关系 在某些情况下，确保这种关系是很重要的。比如王经理和李经理拥有同一个办公室，即存在引用关系： 12345678910111213141516public class Manager&#123; Room room; public Manager(Room r)&#123; room = r; &#125;&#125;public class Room&#123;&#125;public class APP&#123; public void main(String args[])&#123; Room room = new Room(); Manager wang = new Manager(room); Manager li = new Manager(room); &#125;&#125; 反序列化之后，wang，li，room的这种引用关系不应该发生变化。通过代码验证一下： 12345678910111213141516171819public class ReferenceTest implements Serializable&#123; public String a; public ReferenceTest() &#123; a = &quot;hah&quot;; &#125; public static void main(String[] args) throws Exception &#123; System.out.println(&quot;构造对象********************&quot;); ReferenceTest test = new ReferenceTest(); System.out.println(&quot;序列化**********************&quot;); SeriaUtil util = new SeriaUtil(); util.seria(test); util.seria(test);//第二次序列化该对象 System.out.println(&quot;反序列化**********************&quot;); ReferenceTest obj = (ReferenceTest) util.reSeria(); ReferenceTest obj1 = (ReferenceTest) util.reSeria(); System.out.println(obj == obj1);//true System.out.println(obj == test);//false &#125;&#125; 上面的例子证明（System.out.println(obj == obj1);//true），同一对象序列化多次之后，反序列化得到的多个对象相等，即内存地址一致。 使用同一个ObjectOutputStream对象序列化某个实例时，如果该实例还没有被序列化过，则序列化，若之前已经序列化过，则不再进行序列化，只是做一个标记而已。所以在反序列化时，可以保持原有的引用关系。 System.out.println(obj == test);//false 也可以理解，反序列化之后重建了该对象，内存地址必然是新分配的，故obj != test 父类没有实现Serializable，父类中的变量如何序列化12345678910111213141516171819202122232425262728293031323334353637public class SuperTest&#123; public String superB; public SuperTest() &#123; superB = &quot;hehe&quot;; System.out.println(&quot;super 无参构造函数&quot;); &#125; public SuperTest(String b)&#123; System.out.println(&quot;super 有参构造函数&quot;); superB = b; &#125; public static void main(String[] args) throws IOException, ClassNotFoundException &#123; System.out.println(&quot;构造对象*******************&quot;); SonTest sonTest = new SonTest(&quot;son&quot;, &quot;super&quot;); System.out.println(&quot;序列化*********************&quot;); SeriaUtil seriaUtil = new SeriaUtil(); seriaUtil.seria(sonTest); System.out.println(&quot;反序列化******************&quot;); SonTest obj = (SonTest) seriaUtil.reSeria(); System.out.println(obj.sonA); System.out.println(obj.superB); &#125;&#125;class SonTest extends SuperTest implements Serializable&#123; private static final long serialVersionUID = 1L; public String sonA; public SonTest() &#123; System.out.println(&quot;son 无参构造函数&quot;); &#125; public SonTest(String a, String b) &#123; super(b); System.out.println(&quot;son 有参构造函数&quot;); sonA = a; &#125;&#125; 输出： 构造对象*super 有参构造函数son 有参构造函数序列化*反序列化**super 无参构造函数sonhehe 通过上面的代码可以看出，父类如果没有实现serializable，反序列化时会调用父类的无参构造函数初始化父类当中的变量。 所以，我们可以通过显示声明父类的无参构造函数，并在其中初始化变量值来控制反序列化后父类变量的值。 transient使用实现了serializable接口的类在序列化时默认会将所有的非静态变量进行序列化。我们可以控制某些字段不被默认的序列化机制序列化。 比如，有些字段是跟当前系统环境相关的或者涉及到隐私的，需要保密的。这些字段是不可以被序列化到文件中或者通过网络传输的。我们可以通过为这些字段声明transient关键字，保证其不被序列化。 被关键字transient声明的变量不会被序列化，反序列化时该变量会被自动填充为null（int 为0）。我们也可以为这些字段实现自己的序列化机制。 123456789101112131415161718192021222324252627public class TransientTest implements Serializable&#123; private static final long serialVersionUID = 1L; public transient String str; public TransientTest() &#123; str = &quot;hello&quot;; &#125; private void writeObject(ObjectOutputStream out) throws IOException &#123; out.defaultWriteObject(); String encryption = &quot;key&quot; + str; out.writeObject(encryption); &#125; private void readObject(ObjectInputStream in) throws IOException, ClassNotFoundException &#123; in.defaultReadObject(); String encryption = (String) in.readObject(); str = encryption.substring(&quot;key&quot;.length(), encryption.length()); &#125; public static void main(String[] args) throws IOException, ClassNotFoundException &#123; TransientTest test = new TransientTest(); SeriaUtil util = new SeriaUtil(); util.seria(test); TransientTest reSeria = (TransientTest) util.reSeria(); System.out.println(reSeria.str);//hello &#125;&#125; 通过实现writeObject和readObject实现自己的序列化机制。上面的代码模拟了一个加密的序列化过程。 成员变量没有实现序列化序列化某个实例时，如果这个实例含有对象类型的成员变量，那么同时会触发该变量的序列化机制。这时就要求这个成员变量也实现Serializable接口，如果没有实现该接口，抛出异常。 1234567891011121314151617181920212223public class VariableTest implements Serializable&#123; Variable variable ; public VariableTest() &#123; variable = new Variable(); &#125; public static void main(String[] args) throws IOException, ClassNotFoundException &#123; System.out.println(&quot;构造对象*************&quot;); VariableTest variableTest = new VariableTest(); System.out.println(&quot;序列化**************&quot;); SeriaUtil util = new SeriaUtil(); //抛出异常：java.io.NotSerializableException util.seria(variableTest); System.out.println(&quot;反序列化****************&quot;); VariableTest obj = (VariableTest) util.reSeria(); System.out.println(obj.variable.a);//抛出异常：Exception in thread &quot;main&quot; java.io.NotSerializableException: space.kyu.Variable &#125;&#125;class Variable &#123; public String a; public Variable()&#123; a = &quot;hehe&quot;; &#125;&#125; 单例模式下的序列化1234567891011public class SingleTest implements Serializable&#123; public static SingleTest instance = new SingleTest(); private SingleTest()&#123;&#125; public static void main(String[] args) throws IOException, ClassNotFoundException &#123; SingleTest test = SingleTest.instance; SeriaUtil util = new SeriaUtil(); util.seria(test); SingleTest reSeria = (SingleTest) util.reSeria(); System.out.println(reSeria == SingleTest.instance);//false &#125;&#125; 由上面的代码可以看出，有两个SingleTest实例同时存在，通过反序列化破坏了单例模式。反序列化时会开辟新的内存空间重新实例化对象，所以单例模式被破坏。 为了解决这种问题，可以实现readResolve()方法。 1234567891011121314public class SingleTest implements Serializable&#123; public static SingleTest instance = new SingleTest(); private SingleTest()&#123;&#125; private Object readResolve() &#123; return SingleTest.instance; &#125; public static void main(String[] args) throws IOException, ClassNotFoundException &#123; SingleTest test = SingleTest.instance; SeriaUtil util = new SeriaUtil(); util.seria(test); SingleTest reSeria = (SingleTest) util.reSeria(); System.out.println(reSeria == SingleTest.instance);//true &#125;&#125; 序列化版本代码是在不断的演化的。1.1版本的类可以读取1.0版本的序列化文件吗？这就涉及到序列化的版本管理。 每个序列化版本都有其唯一的ID，他是数据域类型和方法签名的指纹。当类的定义产生变化时，他的指纹也会跟着产生变化，对象流将拒绝读入具有不同指纹的对象。如果想保持早期版本的兼容，首先要获取这个类早期版本的指纹。 我们可以使用 jdk自带的工具 serialver 获得这个指纹：serialver Test1staic final long serialVersionUID = -1423859403827594712L 然后将1.1版本中Test类的serialVersionUID常量定义为上面的值，即可序列化老版本的代码。 如果一个类具有名为serialVersionUID的常量，那么java就不会再主动计算这个值，而是直接将其作为这个版本类的指纹。没有特殊要求的话，一般都显示的声明serialVersionUID：private static final long serialVersionUID = 1L;来保证兼容性 如果对象流中的对象具有在当前版本中没有的数据域，那么对象流会忽略这些数据；如果当前版本具有对象流中所没有的数据域，那么这些新加的域将被设为默认值。 序列化与克隆反序列化重新构建对象的机制提供了一种克隆对象的简便途径，只要对应的类可序列化即可。 做法很简单：直接将对象序列化到输出流当中，然后将其读回。这样产生的对象是对现有对象的一个深拷贝。 12345678910111213141516171819202122232425public class CloneTest implements Serializable, Cloneable &#123; public String str; public CloneTest(String str) &#123; this.str =str; &#125; @Override protected Object clone() throws CloneNotSupportedException &#123; SeriaUtil util = new SeriaUtil(); try &#123; util.seria(this); CloneTest reSeria = (CloneTest) util.reSeria(); return reSeria; &#125; catch (Exception e) &#123; e.printStackTrace(); return null; &#125; &#125; public static void main(String[] args) throws CloneNotSupportedException &#123; CloneTest test = new CloneTest(&quot;hi&quot;); CloneTest clone = (CloneTest) test.clone(); System.out.println(clone.str);//hi System.out.println(clone == test);//false &#125;&#125; 这样克隆对象的优点是简单，缺点是比普通的克隆实现要慢的多。]]></content>
      <categories>
        <category>编程</category>
      </categories>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[java I/O总结]]></title>
    <url>%2F2017%2F03%2F19%2FI-O%E6%80%BB%E7%BB%93%2F</url>
    <content type="text"><![CDATA[在平时维护JDBC驱动的过程中，经常会接触到IO相关的代码。总结梳理一下java中的IO~ IOIO，即Input和Output。流可以理解为字节序列的流动，可以从其中读入字节序列的对象称为输入流，可以向其中写入字节序列的对象称为输出流。这些字节序列的来源和目的地可以是文件，网络，或者内存等。 java中的IO基本可以分为两大类： 1.基于字节操作的 I/O 接口：InputStream 和 OutputStream 2.基于字符操作的 I/O 接口：Writer 和 Reader 不管是磁盘还是网络传输，最小的存储单元都是字节，而不是字符，所以 I/O 操作的都是字节而不是字符。但是我们的程序通常操作的数据都是以字符的形式存在，比如处理网页中的内容或者磁盘文件中的文本。为了操作方便，提供了直接操作字符的接口。操作字符的接口底层还是基于字节的，只不过封装了一些例如编码和解码等操作。 下面是java.io包中的内容：Package java.io java.io 类图: 字节接口 上图给出了InputStream和OutputStream的继承关系(不仅仅是java.io包) 理解InputStream家族，首先要理解装饰者模式： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263Component：定义一个对象接口，可以给这些对象动态地添加职责。public interface Component&#123; void operation();&#125; Concrete Component：定义一个对象，可以给这个对象添加一些职责。动作的具体实施者。public class ConcreteComponent implements Component&#123; public void operation() &#123; // Write your code here &#125;&#125; Decorator：维持一个指向Component对象的引用，并定义一个与 Component接口一致的接口。public class Decorator implements Component&#123; public Decorator(Component component) &#123; this.component = component; &#125; public void operation() &#123; component.operation(); &#125; private Component component;&#125; Concrete Decorator：在Concrete Component的行为之前或之后，加上自己的行为，以“贴上”附加的职责。public class ConcreteDecorator extends Decorator&#123; public void operation() &#123; //addBehavior也可以在前面 super.operation(); addBehavior(); &#125; private void addBehavior() &#123; //your code &#125;&#125; 使用装饰模式来实现扩展比继承更加灵活，它以对客户透明的方式动态地给一个对象附加更多的责任。装饰模式可以在不需要创造更多子类的情况下，将对象的功能加以扩展。 InputStream族与装饰者模式的对应关系： Component: InputStream ConcreteComponent: InputStream除FilterINputStream以外的直接子类，如FileInputStream，他们提供了最终的读取字节功能 Decorator: FilterInputStream ConcreteDecorator: FilterINputStream的直接子类，如BufferedInputStream，他们为读取字节附加了一些功能 首先看一下InputStream为我们提供了哪些操作： 123456789101112131415161718int available()返回不阻塞情况下可用的字节数void close()关闭这个输入流void mark(int readlimit)在流的当前位置打一个标记boolean markSupported()如果这个流支持打标记，则返回trueabstract int read()从数据中读取一个字节，并返回该字节int read(byte[] b)读入一个字节数组，并返回读入的字节数int read(byte[] b, int off, int len)读入一个字节数组，并返回读入的字节数。b:数据读入的数组 off:第一个读入的字节在b中的偏移量 len:读入字节的最大数量void reset()返回最后的标记，随后对read的调用将重新读入这些字节long skip(long n)在输入流中跳过n个字节，返回实际跳过数 其中：abstract int read()int read(byte[] b)int read(byte[] b, int off, int len) 这三个方法提供了基本的读入功能。read方法在执行时将被阻塞，直到字节确实被读入。InputStream的子类实现或重写了这些方法的具体的操作，来完成对具体对象的读入功能。 通过一个简单的例子来理解InputStream的组合过滤器功能。 我们要从文件中读入数字，则首先必须有一个具体实现读取文件的FileInputStream实例： FileInputStream fin = new FileInputStream(“test.dat”); 流在默认情况下是不被缓冲区缓存的，也就是说，对于每一次的read的调用都会请求操作系统再分发一个字节。相比之下，一次请求一个数据块将其置于缓冲区显得更加高效。因此，我们为流添加缓冲功能，形成缓冲流： BufferedInputStream bin = new BufferedInputStream(fin); test.dat文件中存储的是十进制数字的二进制序列。此时我们的流仅仅提供了读取字节序列的功能，为了实现将二进制序列转为十进制数字的功能，我们做进一步转换：DataInputStream din = new DataInputStream(bin); 此时我们可以调用 din.readInt()方法依次读取文件中以二进制形式存储的十进制数字了。 注意，我们将DataInputStream置于构造链的最后，这是因为我们最终希望使用DataInputStream的方法来读取十进制数字。 观察一下上面提到的几个类的实现，就会对这种装饰者模式的工作机制有更加深刻的理解。理解了装饰者模式之后，再结合上面的类图，使用IO流就会更加得心应手。 对于OutputStream，实现原理与InputStream是一样的，不再赘述。 记录几个常用的stream： DataOutputStream: 将基本类型的数据以二进制流的形式写出 DataInputStream: 将二进制流读入为基本类型数据 ObjectInputStream: 将Java对象以二进制流的形式写出 （序列化使用） ObjectOutputStream: 将二进制流读入为java对象 （序列化时使用） PipedOutputStream和PipedInputStream分别是管道输出流和管道输入流，让多线程可以通过管道进行线程间的通讯 ZipOutputStream和ZipInputStream: 文件压缩与解压缩 PushBackInputStream：回退流 字符接口 在保存数据时，可以选择二进制格式保存或者文本格式保存。比如，整数12234可以存储成二进制，是由00 00 04 D2构成的字节序列。而存储成文本格式，则存储成为字符串“1234”。二进制格式的存储高效且节省空间，但是文本格式的存储方式更适宜人类阅读，应用也很广泛。 与字节接口类似，字符接口族也是采用了装饰者模式的架构。 在存储或读取文本字符串时，可以选择编码。比如： InputStreamReader reader = new InputStreamReader(new FileInputStream(“test.dat”),”UTF-8”); reader将使用GBK编码读取文本test.dat的内容。如果构造器没有显示指定编码，将使用主机系统所使用的默认文字编码方式。 与DataOutputStream对应，PrintWriter用来以文本的格式打印字符串和数字。 与DataInputStream对应，可以使用Scanner类来读取文本格式的数据。 字符集字符集规定了某个字符对应的二进制数字存放方式（编码）和某串二进制数值代表了哪个字符（解码）的映射关系。 JavaSE-1.4的java.nio包中引入了类Charset统一了对字符集的转换。 通过观察InputStreamReader的源码（1.7），InputStreamReader 将字符的读取与解码委托给了类StreamDecoder实现。而在StreamDecoder中，又是通过传入的InputStream与指定的Charset配合完成了字节序列的读取和解码工作。 可以通过调用静态的forName方法获取一个Charset：1Charset charset = Charset.forName(&quot;UTF-8&quot;); 其中，传入的参数是某个字符集的官方名或者别名。 Set alias = charset.aliases(); //获取某个Charset的所有可用别名Map charsets = Charset.availableCharsets(); //获取所用可用字符集的名字 有了字符集Charset，就可以通过他将字节序列解码为字符序列或者将字符序列编码为字节序列： 12345678910//编码String str = &quot;hello&quot;;ByteBuffer bb = charset.encode(str);byte[] bytes = bb.array();//解码byte[] bytes = ....ByteBuffer bb = ByteBuffer.wrap(bytes, 0, bytes.length);CharBuffer cb = Charset.decode(bb);String str = cb.toString(); 实际上，通过观察源码，得知InputStreamReader也是这么做的（还有String）。 文件操作Stream关心的是文件的内容，File类关心的是文件的存储。 关于File的使用，网上有很多介绍，可以参考官网Class File，不再赘述。 要注意一个类RandomAccessFile，可以在文件的任何位置查找或者写入数据，RandomAccessFile同时实现了DataInput和DataOutput接口。 我们可以使用RandomAccessFile随机读写的特性来完成大文件的上传或者下载。把文件分为n份，开启n个线程同时对这n个部分进行读写操作，提高了读写的效率。（让我想起了ConcurrentHashMap，分段锁的原理）同时，还具有了断点续传的功能。]]></content>
      <categories>
        <category>编程</category>
      </categories>
      <tags>
        <tag>java io</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[webservice相关]]></title>
    <url>%2F2017%2F03%2F15%2Fwebservice%E7%9B%B8%E5%85%B3%2F</url>
    <content type="text"><![CDATA[上周最后三天去北京培训了Hadoop，了解了一些目前流行的分布式组件。在谈到这些组件的交互过程中，经常会提到RPC，webservice等关键词，所以简单了解了一下这些关键词的含义~ WebServicewebservice，拆开来看就是 web（网络）和service（服务），先了解一下什么是服务： 计算机的后台进程提供了某种功能，我们把提供了这种功能的进程称为守护进程（Daemon），提供的功能称为服务。比如，我们启动了数据库，数据库进程就会一直运行在后台监听连接数据库的动作，这种监听连接的功能就是一种服务。 服务分为本地服务和网络服务。使用同一台机器上提供的服务就是本地服务，通过网络连接到另一台计算机使用它提供的服务就是网络服务。 所以，webservice 就是通过网络使用了其他服务器提供的某种功能或获取了某些资源。 这样一来，webservice就很常见了。比如我们做了一个显示天气情况的app，使用了百度地图提供的定位功能，使用了其他服务商提供的天气数据，这些都属于webservice。 webservice可以包含以下几个实现： RPC：面向过程 RMI：面向对象 REST：面向资源 Web Service tutorial RPC概念 远程过程调用（英语：Remote Procedure Call，缩写为 RPC）是一个计算机通信协议。该协议允许运行于一台计算机的程序调用另一台计算机的子程序，而程序员无需额外地为这个交互作用编程。如果涉及的软件采用面向对象编程，那么远程过程调用亦可称作远程调用或远程方法调用。 上面的解释摘自维基百科 RPC属于webservice的一种，就是在一个进程中调用另一个进程中的服务。就像调用本地方法一样调用远程服务器的方法。 RPC有很多实现，包括XML-RPC、JSON-RPC、JAX-RPC等等。 一次RPC调用过程就是向服务器发送一个过程调用的方法和参数，得到服务器返回的方法执行结果。RPC的本质就是一次远程调用，但更强调透明调用。RPC是跨语言的。 使用以Json-Rpc 为例，看一下RPC是如何工作的： 使用java中的json-rpc实现jsonrpc4j：（也有其他语言的实现） Create your service interface:1234567package com.mycompany;public interface UserService &#123; User createUser(String userName, String firstName, String password); User createUser(String userName, String password); User findUserByUserName(String userName); int getUserCount();&#125; Implement it:1234567891011121314151617181920212223242526package com.mycompany;public class UserServiceImpl implements UserService &#123; public User createUser(String userName, String firstName, String password) &#123; User user = new User(); user.setUserName(userName); user.setFirstName(firstName); user.setPassword(password); database.saveUser(user) return user; &#125; public User createUser(String userName, String password) &#123; return this.createUser(userName, null, password); &#125; public User findUserByUserName(String userName) &#123; return database.findUserByUserName(userName); &#125; public int getUserCount() &#123; return database.getUserCount(); &#125;&#125; Server12345678910111213141516class UserServiceServlet extends HttpServlet &#123; private UserService userService; private JsonRpcServer jsonRpcServer; protected void doPost(HttpServletRequest req, HttpServletResponse resp) &#123; jsonRpcServer.handle(req, resp); &#125; public void init(ServletConfig config) &#123; //this.userService = ... this.jsonRpcServer = new JsonRpcServer(this.userService, UserService.class); &#125;&#125; Client123456789JsonRpcHttpClient client = new JsonRpcHttpClient( new URL(&quot;http://example.com/UserService.json&quot;));UserService userService = ProxyUtil.createClientProxy( getClass().getClassLoader(), UserService.class, client);User user = userService.createUser(&quot;bob&quot;, &quot;the builder&quot;); 上面的例子只是最简单的访问方式，在分布式环境中，RPC还涉及到服务寻址，负载均衡等等问题。 更加详细的RPC介绍，可以参考RPC 是什么 为什么是RPC在网上查看RPC资料的时候，就想到一个问题，既然RPC这么复杂，为什么不使用HTTP接口调用的方式来进行网络通信呢？以前做一些小demo的时候使用HttpClient就完全OK了。 看到一个很有意思的讨论：为什么需要RPC，而不是简单的HTTP接口 RPC调用简单，适用于业务逻辑比较复杂的情况，比如分布式环境当中。RPC强调透明调用,也利于解耦。 原理QiuRPC：一个通用的网络RPC框架 你应该知道的 RPC 原理 SOAPXML-RPC只能使用有限的数据类型种类和一些简单的数据结构。于是就出现了SOAP(Simple Object Access Protocol)。 SOAP (Simple Object Access Protocol) 顾名思义，是一个严格定义的信息交换协议，用于在Web Service中把远程调用和返回封装成机器可读的格式化数据。 事实上SOAP数据使用XML数据格式，定义了一整套复杂的标签，以描述调用的远程过程、参数、返回值和出错信息等等。而且随着需要的增长，又不得增加协议以支持安全性，这使SOAP变得异常庞大，背离了简单的初衷。另一方面，各个服务器都可以基于这个协议推出自己的API，即使它们提供的服务及其相似，定义的API也不尽相同，这又导致了WSDL的诞生。 WSDL (Web Service Description Language) 也遵循XML格式，用来描述哪个服务器提供什么服务，怎样找到它，以及该服务使用怎样的接口规范，简言之，服务发现。 现在，使用Web Service的过程变成，获得该服务的WSDL描述，根据WSDL构造一条格式化的SOAP请求发送给服务器，然后接收一条同样SOAP格式的应答，最后根据先前的WSDL解码数据。绝大多数情况下，请求和应答使用HTTP协议传输，那么发送请求就使用HTTP的POST方法。 Working Soap client example SOAP Messaging Models and Examples 通过soap demo体会soap与rpc的区别 RMIRMI其实也属于RPC的一种，是面向对象的。RMI只能在java里玩，不支持跨语言。与RPC不同的是，RMI可以返回java对象以及基本的数据类型，RPC不允许返回对象，RPC服务的信息由外部数据表示。RMI的优势在于依靠Java序列化机制，对开发人员屏蔽了数据编排和解排的细节，要做的事情非常少。 用代码说话： RMI采用的是典型的客户端-服务器端架构。首先需要定义的是服务器端的远程接口，这一步是设计好服务器端需要提供什么样的服务。对远程接口的要求很简单，只需要继承自RMI中的Remote接口即可。Remote和Serializable一样，也是标记接口。远程接口中的方法需要抛出RemoteException。定义好远程接口之后，实现该接口即可。如下面的Calculator是一个简单的远程接口。123public interface Calculator extends Remote &#123; String calculate(String expr) throws RemoteException;&#125; 实现了远程接口的类的实例称为远程对象。创建出远程对象之后，需要把它注册到一个注册表之中。这是为了客户端能够找到该远程对象并调用。12345678910public class CalculatorServer implements Calculator &#123; public String calculate(String expr) throws RemoteException &#123; return expr; &#125; public void start() throws RemoteException, AlreadyBoundException &#123; Calculator stub = (Calculator) UnicastRemoteObject.exportObject(this, 0); Registry registry = LocateRegistry.getRegistry(); registry.rebind(&quot;Calculator&quot;, stub); &#125;&#125; CalculatorServer是远程对象的Java类。在它的start方法中通过UnicastRemoteObject的exportObject把当前对象暴露出来，使得它可以接收来自客户端的调用请求。再通过Registry的rebind方法进行注册，使得客户端可以查找到。 客户端的实现就是首先从注册表中查找到远程接口的实现对象，再调用相应的方法即可。实际的调用虽然是在服务器端完成的，但是在客户端看来，这个接口中的方法就好像是在当前JVM中一样。这就是RMI的强大之处。123456789101112public class CalculatorClient &#123; public void calculate(String expr) &#123; try &#123; Registry registry = LocateRegistry.getRegistry(&quot;localhost&quot;); Calculator calculator = (Calculator) registry.lookup(&quot;Calculator&quot;); String result = calculator.calculate(expr); System.out.println(result); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125;&#125; 在运行的时候，需要首先通过rmiregistry命令来启动RMI中用到的注册表服务器。 为了通过Java的序列化机制来进行传输，远程接口中的方法的参数和返回值，要么是Java的基本类型，要么是远程对象，要么是实现了 Serializable接口的Java类。当客户端通过RMI注册表找到一个远程接口的时候，所得到的其实是远程接口的一个动态代理对象。当客户端调用其中的方法的时候，方法的参数对象会在序列化之后，传输到服务器端。服务器端接收到之后，进行反序列化得到参数对象。并使用这些参数对象，在服务器端调用实际的方法。调用的返回值Java对象经过序列化之后，再发送回客户端。客户端再经过反序列化之后得到Java对象，返回给调用者。这中间的序列化过程对于使用者来说是透明的，由动态代理对象自动完成。除了序列化之外，RMI还使用了动态类加载技术。当需要进行反序列化的时候，如果该对象的类定义在当前JVM中没有找到，RMI会尝试从远端下载所需的类文件定义。可以在RMI程序启动的时候，通过JVM参数java.rmi.server.codebase来指定动态下载Java类文件的URL。 RESTREST只是一种软件架构的风格，而不是一种协议或者其他。 REST基于HTTP协议，一般使用JSON传输数据。REST是面向资源的，资源由URI来表示。 以下解释参考自理解RESTful架构 要理解RESTful架构，最好的方法就是去理解Representational State Transfer这个词组到底是什么意思，它的每一个词代表了什么涵义。如果你把这个名称搞懂了，也就不难体会REST是一种什么样的设计。 资源（Resources） REST的名称”表现层状态转化”中，省略了主语。”表现层”其实指的是”资源”（Resources）的”表现层”。 所谓”资源”，就是网络上的一个实体，或者说是网络上的一个具体信息。它可以是一段文本、一张图片、一首歌曲、一种服务，总之就是一个具体的实在。你可以用一个URI（统一资源定位符）指向它，每种资源对应一个特定的URI。要获取这个资源，访问它的URI就可以，因此URI就成了每一个资源的地址或独一无二的识别符。 所谓”上网”，就是与互联网上一系列的”资源”互动，调用它的URI。 表现层（Representation） “资源”是一种信息实体，它可以有多种外在表现形式。我们把”资源”具体呈现出来的形式，叫做它的”表现层”（Representation）。 比如，文本可以用txt格式表现，也可以用HTML格式、XML格式、JSON格式表现，甚至可以采用二进制格式；图片可以用JPG格式表现，也可以用PNG格式表现。 URI只代表资源的实体，不代表它的形式。严格地说，有些网址最后的”.html”后缀名是不必要的，因为这个后缀名表示格式，属于”表现层”范畴，而URI应该只代表”资源”的位置。它的具体表现形式，应该在HTTP请求的头信息中用Accept和Content-Type字段指定，这两个字段才是对”表现层”的描述。 状态转化（State Transfer） 访问一个网站，就代表了客户端和服务器的一个互动过程。在这个过程中，势必涉及到数据和状态的变化。 互联网通信协议HTTP协议，是一个无状态协议。这意味着，所有的状态都保存在服务器端。因此，如果客户端想要操作服务器，必须通过某种手段，让服务器端发生”状态转化”（State Transfer）。而这种转化是建立在表现层之上的，所以就是”表现层状态转化”。 客户端用到的手段，只能是HTTP协议。具体来说，就是HTTP协议里面，四个表示操作方式的动词：GET、POST、PUT、DELETE。它们分别对应四种基本操作：GET用来获取资源，POST用来新建资源（也可以用于更新资源），PUT用来更新资源，DELETE用来删除资源。 综述 综合上面的解释，我们总结一下什么是RESTful架构：（1）每一个URI代表一种资源；（2）客户端和服务器之间，传递这种资源的某种表现层；（3）客户端通过四个HTTP动词，对服务器端资源进行操作，实现”表现层状态转化”。 参考RESTful API 设计指南设计Rest API github的API设计就是REST风格的。 网上关于REST和PRC的争论有很多,总的来说有以下几个： 安全性上：SOAP安全性高于REST 成熟度上：SOAP在成熟度上优于REST 效率和易用性上：REST更胜一筹 参考你应该知道的 RPC 原理 RPC 是什么 Web service是什么？ Java深度历险（十）——Java对象序列化与RMI]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>web</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[linux分区]]></title>
    <url>%2F2017%2F03%2F04%2Flinux%E5%88%86%E5%8C%BA%2F</url>
    <content type="text"><![CDATA[每次安装linux的时候，都会选择分区和挂载点。但是基本上没怎么研究过linux分区的细节，今天回顾了一下《鸟哥的linux私房菜》，总结一下分区的相关知识。 磁盘的组成 磁道（Track）：当磁盘旋转时，磁头若保持在一个位置上，则每个磁头都会在磁盘表面划出一个圆形轨迹，这些圆形轨迹就叫做磁道（Track）。 柱面（Cylinder）：在有多个盘片构成的盘组中，由不同盘片的面，但处于同一半径圆的多个磁道组成的一个圆柱面（Cylinder）。 扇区（Sector）：磁盘上的每个磁道被等分为若干个弧段，这些弧段便是硬盘的扇区（Sector）。 磁头（Heads） 盘片（Platters） 每个碟片都有两面，因此也会相对应每碟片有2个磁头。 硬盘的物理结构一般由磁头与碟片、电动机、主控芯片与排线等部件组成；当主电动机带动碟片旋转时，副电动机带动一组（磁头）到相对应的碟片上并确定读取正面还是反面的碟面，磁头悬浮在碟面上画出一个与碟片同心的圆形轨道（磁轨或称柱面），这时由磁头的磁感线圈感应碟面上的磁性与使用硬盘厂商指定的读取时间或数据间隔定位扇区，从而得到该扇区的数据内容； 磁盘的第一个扇区记录了整块磁盘的重要信息，主要有两个： 1.主引导分区：可以安装引导加载程序的地方，有446bytes 2.分区表：记录整块音盘的分区状况，有64bytes 开机流程简单梳理一下开机流程： 计算机开机后，会主动执行BIOS程序，BIOS是写入到主板上面的一个软件程序。接下来BIOS会去分析计算机中有哪些存储设备，然后依据用户的设置获取可以开机的硬盘（比如我们设置从usb启动），然后到读取该硬盘中的第一个扇区MBR位置。MBR中放置着基本的引导加载程序，接下来就是MBR内的引导加载程序加载内核文件。这个引导加载程序是操作系统在安装时提供的。 磁盘分区表分区不难理解，在windows中，就意味着C，D，E等不同的盘，其实这些c盘，d盘往往都是属于同一块磁盘，将同一块磁盘划分开来，这就是分区。那为什么要分区呢？ 1.数据安全 很好理解。比如我们在重装win操作系统的时候，往往只需要重装c盘即可，d盘等其他分区里的数据并不受重装系统的影响。 2.性能 将磁盘分区后，提高了数据读取的速度。我们在寻找某个分区的数据时，只需要扫描该分区对应磁盘的位置即可，并不需要全盘扫描。 那么，到底是如何分区呢？ 上图中，不同颜色的柱面范围就代表了不同的分区。分区利用了柱面号码的方式来处理。在分区表所在的64bytes中，总共分为四组记录，每组记录该分区的起始与结束柱面号码。 我们将上图中从圆心到周长中间切出一条长方形来看： 上图假设硬盘有400个柱面，分成四个分区。所谓的分区其实就是针对分区表进行设置而已。分区表最多可以容纳四个分区(只能记录四条数据)，这四个分区被称为主分区或者扩展分区。系统要写磁盘时，首先会参考磁盘分区表，然后才对某个分区的数据进行处理。 假设这个磁盘在linux中的设备文件名为/dev/hda，那么这四个分区的文件名分别为： p1:/dev/hda1 p2:/dev/hda2 p3:/dev/hda3 p4:/dev/hda4 那么如何可以分得更多的分区呢？装过操作系统的人都知道分区不仅仅可以分四个，我们可以有c,d,e,f,g等等多个磁盘的划分。这都是通过扩展分区来做到的。 扩展分区的原理就是利用额外的扇区来记录更多的分区信息，从而继续分出更多的分区来。由扩展分区分出来的分区叫做逻辑分区。 上图中，我们将磁盘/dev/sdb 分为了六个分区，分别是 三个主分区：/dev/sdb1，/dev/sdb2/，/dev/sdb3 三个逻辑分区：/dev/sdb5，/dev/sdb6/，/dev/sdb7 为什么没有sdb4呢？那是因为1-4是保留给主分区或者扩展分区使用的。 注意以下几点： 主分区和扩展分区最多只能有四个； 扩展分区只能有一个； 逻辑分区是有扩展分区再切割而来的； 扩展分区不能够格式化，所以无法直接使用，必须分为逻辑分区后才可以访问； 所以说，如果我们想要分出四个以上的分区时，务必要设置一个扩展分区，而不能将四个分区全部划为主分区。 多重引导前面的开机流程中提到，计算机通过读取MBR中的引导加载程序，使用该程序读取内核文件，启动操作系统。如果我们安装了双系统的话，又是如何指定启动哪一个操作系统呢？ 引导加载程序主要有下面几个功能： 提供不同的开机选项； 载入内核文件； 将引导加载功能转交给其他引导加载程序； 其中第三点，转交给其他引导加载程序，表明我们可以安装不同的引导加载程序到硬盘上面，但是MBR只有一个，也只能安装一个引导加载程序。其他的引导加载程序，可以安装在不同分区的引导扇区上面。 上图中，我们假设分别在两块分区上安装了windows和linux。当MBR中的引导加载程序开始工作时，会提供两个开机选项供我们选择： 如果我们选择windows，引导加载程序直接加载windows的内核文件开机； 如果我们选择linux，引导加载程序会把工作交给第二个分区的启动扇区中的引导加载程序。第二个引导加载程序启动后，加载该分区内的内核文件开机。 那么，为什么安装双系统时，常常要求先安装windows，后安装linux呢？ 那是因为windows在安装的时候，会主动覆盖掉MBR及自己所在分区的启动扇区，并且也没有提供不同的开机选项菜单；而安装linux，可以选择将引导程序安装在MBR或者其他分区的启动扇区，并且也提供了手动设置开机菜单的功能。 如果我们先安装了linux，再安装windows的时候就会把linux在MBR内的引导加载程序覆盖掉，并且也不会提供linux选项，而是直接进入windows系统。 挂载点安装linux的时候，都会让我们选择挂载点。这个挂载点又与分区有什么关系呢？ 我们知道linux中所有的数据都以文件的形式存在，而文件数据是放在磁盘的分区当中的。所有的文件都是又根目录/衍生而来，我们想要取得/home/yukai/data.txt这个文件时，系统又根目录开始找，找到home，然后找到yukai，最后找到data.txt这个文件。如何由目录树找到磁盘分区中的数据，就是挂载点的意义。 所谓的挂载就是利用一个目录当作进入点，去访问挂载在这个目录上的分区内的文件，即进入该目录就可以读取该分区，该目录是该分区的入口。我们想要访问一个分区时，必须将该分区挂载到某个目录上面，这个目录就是挂载点。 所以说在安装linux的时候，要选择分区和挂载点，意思就是把不同的数据放置到不同的分区上的意思，比如我们把 /dev/sda1的挂载点设置为/home，就意味着/home下所有的数据都存放在/dev/sda1这个分区上面。]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux的五个查找命令]]></title>
    <url>%2F2017%2F02%2F26%2FLinux%E7%9A%84%E4%BA%94%E4%B8%AA%E6%9F%A5%E6%89%BE%E5%91%BD%E4%BB%A4%2F</url>
    <content type="text"><![CDATA[最近一直在读阮一峰老师的博客,今天读到一篇介绍Linux查找命令的文章。恰好最近在学习linux，所以转载过来，当作一篇备忘录。 原文链接：Linux的五个查找命令 使用电脑的时候，经常需要查找文件。 在Linux中，有很多方法可以做到这一点。国外网站LinuxHaxor总结了五条命令，你可以看看自己知道几条。大多数程序员，可能经常使用其中的2到3条，对这5条命令都很熟悉的人应该是不多的。 findfind是最常见和最强大的查找命令，你可以用它找到任何你想找的文件。 find的使用格式如下：1234 $ find &lt;指定目录&gt; &lt;指定条件&gt; &lt;指定动作&gt; - &lt;指定目录&gt;： 所要搜索的目录及其所有子目录。默认为当前目录。 - &lt;指定条件&gt;： 所要搜索的文件的特征。 - &lt;指定动作&gt;： 对搜索结果进行特定的处理。 如果什么参数也不加，find默认搜索当前目录及其子目录，并且不过滤任何结果（也就是返回所有文件），将它们全都显示在屏幕上。 find的使用实例：123456 $ find . -name &apos;my*&apos;搜索当前目录（含子目录，以下同）中，所有文件名以my开头的文件。 $ find . -name &apos;my*&apos; -ls搜索当前目录中，所有文件名以my开头的文件，并显示它们的详细信息。 $ find . -type f -mmin -10搜索当前目录中，所有过去10分钟中更新过的普通文件。如果不加-type f参数，则搜索普通文件+特殊文件+目录。 locatelocate命令其实是”find -name”的另一种写法，但是要比后者快得多，原因在于它不搜索具体目录，而是搜索一个数据库（/var/lib/locatedb），这个数据库中含有本地所有文件信息。Linux系统自动创建这个数据库，并且每天自动更新一次，所以使用locate命令查不到最新变动过的文件。为了避免这种情况，可以在使用locate之前，先使用updatedb命令，手动更新数据库。 locate命令的使用实例：123456 $ locate /etc/sh搜索etc目录下所有以sh开头的文件。 $ locate ~/m搜索用户主目录下，所有以m开头的文件。 $ locate -i ~/m搜索用户主目录下，所有以m开头的文件，并且忽略大小写。 whereiswhereis命令只能用于程序名的搜索，而且只搜索二进制文件（参数-b）、man说明文件（参数-m）和源代码文件（参数-s）。如果省略参数，则返回所有信息。 whereis命令的使用实例：1 $ whereis grep whichwhich命令的作用是，在PATH变量指定的路径中，搜索某个系统命令的位置，并且返回第一个搜索结果。也就是说，使用which命令，就可以看到某个系统命令是否存在，以及执行的到底是哪一个位置的命令。 which命令的使用实例：1 $ which grep typetype命令其实不能算查找命令，它是用来区分某个命令到底是由shell自带的，还是由shell外部的独立二进制文件提供的。如果一个命令是外部命令，那么使用-p参数，会显示该命令的路径，相当于which命令。 type命令的使用实例：123456 $ type cd系统会提示，cd是shell的自带命令（build-in）。 $ type grep系统会提示，grep是一个外部命令，并显示该命令的路径。 $ type -p grep加上-p参数后，就相当于which命令。]]></content>
      <categories>
        <category>工具</category>
      </categories>
      <tags>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[centos7BCM驱动安装]]></title>
    <url>%2F2017%2F02%2F25%2Fcentos7BCM%E9%A9%B1%E5%8A%A8%E5%AE%89%E8%A3%85%2F</url>
    <content type="text"><![CDATA[前段时间安装了centos后，一直使用网线上网。今天是周末，安装了一下无线驱动，可以愉快的使用无线wifi上网啦～ 查看无线驱动1iwconfig 如果没有iwconfig命令，则先安装： 1sudo yum install wireless-tools 如上图显示有类似wlp7s0这样的信息，则表示无线驱动已经安装好了。若没有，则全部为no wireless extensions. 没有安装无线驱动，进行下面的操作。 查看网卡型号1lspci |grep -i network 显示： 107:00.0 Network controller: Broadcom Limited BCM43142 802.11b/g/n (rev 01) 表示是BCM的网卡 查看内核信息1uname -r 显示内核信息：13.10.0-514.6.1.el7.x86_64 注意上面的发行版版本为el6,后面64为64位操作系统 编译安装驱动程序下面只针对el7 64的情况，其他配置的系统参考：wl-kmod 1.安装工具12345yum group install &apos;Development Tools&apos;yum install redhat-lsb kernel-abi-whitelistsyum install kernel-devel-$(uname -r) 2.切换到普通用户，配置构建树123mkdir -p ~/rpmbuild/&#123;BUILD,RPMS,SPECS,SOURCES,SRPMS&#125;echo -e &quot;%_topdir $(echo $HOME)/rpmbuild\n%dist .el$(lsb_release -s -r|cut -d&quot;.&quot; -f1).local&quot; &gt;&gt; ~/.rpmmacros 3.下载 wl-kmod*nosrc.rpm 到任意目录，比如 ～/packagehttp://elrepo.org/linux/elrepo/el7/SRPMS/wl-kmod-6_30_223_271-3.el7.elrepo.nosrc.rpm 4.下载合适的驱动http://www.broadcom.com/support/802.11 选择64位的驱动，下载到~/rpmbuild/SOURCES/目录 5.构建kmod-wl1rpmbuild --rebuild --target=`uname -m` --define &apos;packager yukai&apos; ~/package/wl-kmod*nosrc.rpm 其中，yukai是当前登陆用户，~/package/是第三步下载的rpm文件位置 6.安装kmod-wl 1rpm -Uvh /home/yukai/rpmbuild/RPMS/x86_64/kmod-wl*rpm 第五步构建完成之后,在～/rpmbuild/RPMS/x86_64目录会有kmod-wl*rpm文件生成，安装它即可 7.删除不用的文件 保存/home/yukai/rpmbuild/RPMS/x86_64/kmod-wl*rpm文件，然后删除～/rpmbuild/ 1rm -rf ～/rpmbuild/ 8.重启即可]]></content>
      <categories>
        <category>工具</category>
      </categories>
      <tags>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ssh的两种用法]]></title>
    <url>%2F2017%2F02%2F23%2Fssh%E7%9A%84%E4%B8%A4%E7%A7%8D%E7%94%A8%E6%B3%95%2F</url>
    <content type="text"><![CDATA[工作中在远程主机上进行一些操作时，经常使用ssh进行远程登录。后来使用github时，也会用到ssh。其中涉及到了ssh的两种用法，记录一下~ 本文主要参考自阮一峰老师的博客：SSH原理与运用（一）：远程登录 ssh是每台linux机器的标准配置。ssh是一种协议，SSH在计算机之间构建网络连接，确保连接双方身份的真实性，同时，它还保证在此连接上传送的数据到达时不会被人更改，不会被他人窃听。 ssh有多种实现，我们一般使用的是openssh，这是一款免费开源的ssh工具。一般在我们使用的linux发行版中，已经预设了这个软件了，所以可以直接使用它。如果是在windows中使用ssh客户端连接远程linux ssh服务，我使用一款名为MobaXterm的工具。 密码登录这是我们使用远程linux机器时最一般的登录方式。使用user这个用户登录到主机host: ssh user@host ssh默认端口是22，如果远程主机ssh服务端口不是22的话，可以通过-p参数修改连接端口： ssh -p 8899 user@host 整个的登录过程： 1.远程主机收到客户端的登录请求，把自己的公钥发给用户。 2.客户端使用这个公钥，将登录密码加密后，发送回来。 3.远程主机用自己的私钥，解密登录密码，如果密码正确，就同意客户端登录。 这样的登录方式有一个问题，那就是如果有人截获了客户端的登录请求（比如使用公共WiFi），然后将自己的公钥发给了客户端，就可以冒充远程主机获取客户端的密码了。Https协议是有CA证书中心作公证的，ssh协议并不存在这样的机构，所以就有中间人攻击的风险。 为了应对这种风险，当客户端第一次登陆远程主机时，会有类似的提示： 123The authenticity of host &apos;test.linux.org (192.168.1.100)&apos; can&apos;t be established. RSA key fingerprint is 46:cf:06:6a:ad:ba:e2:85:cc:d9:c4:8d:15:bb:f3:ec. Are you sure you want to continue connecting (yes/no)? 意思就是要你核对远程主机的公钥指纹，从而证明他的身份。那么我们如何判断这个公钥指纹是不是远程主机的公钥产生的指纹呢？答案是没有好办法，只能由用户自己想办法核对，比如远程主机在网站上贴出了自己的公钥指纹。 当我们输入yes之后，会出现： 1Warning: Permanently added &apos;test.linux.org,192.168.1.100&apos; (RSA) to the list of known 表示我们已经认可了该主机。 此时要求我们输入登录用户的密码，密码正确则登录。 当远程主机的公钥被接受以后，它就会被保存在文件$HOME/.ssh/known_hosts之中。下次再连接这台主机，系统就会认出它的公钥已经保存在本地了，从而跳过警告部分，直接提示输入密码。 每个SSH用户都有自己的known_hosts文件，此外系统也有一个这样的文件，通常是/etc/ssh/ssh_known_hosts，保存一些对所有用户都可信赖的远程主机的公钥。 公钥登录步骤ssh还提供了另一种登录方式，就是公钥登录，避免了输入密码的麻烦。 所谓”公钥登录”，原理很简单，就是用户将自己的公钥储存在远程主机上。登录的时候，远程主机会向用户发送一段随机字符串，用户用自己的私钥加密后，再发回来。远程主机用事先储存的公钥进行解密，如果成功，就证明用户是可信的，直接允许登录shell，不再要求密码。 这种方法要求用户必须提供自己的公钥。如果没有现成的，可以直接用ssh-keygen生成一个： ssh-keygen 运行结束以后，在$HOME/.ssh/目录下，会新生成两个文件：id_rsa.pub和id_rsa。前者是你的公钥，后者是你的私钥。 这时再输入下面的命令，将公钥传送到远程主机host上面： ssh-copy-id user@host 然后，打开远程主机/etc/ssh/sshd_config这个文件，检查以下几项： RSAAuthentication yesPubkeyAuthentication yesAuthorizedKeysFile .ssh/authorized_keys 然后重启ssh服务就可以了： service sshd restart authorized_keys远程主机将用户的公钥，保存在登录后的用户主目录的$HOME/.ssh/authorized_keys文件中。公钥就是一段字符串，只要把它追加在authorized_keys文件的末尾就行了。 这里不使用上面的ssh-copy-id命令，改用下面的命令，解释公钥的保存过程： ssh user@host ‘mkdir -p .ssh &amp;&amp; cat &gt;&gt; .ssh/authorized_keys’ &lt; ~/.ssh/id_rsa.pub 这条命令由多个语句组成，依次分解开来看： “ssh user@host”，表示登录远程主机； 单引号中的mkdir .ssh &amp;&amp; cat &gt;&gt; .ssh/authorized_keys，表示登录后在远程shell上执行的命令： “mkdir -p .ssh”的作用是，如果用户主目录中的.ssh目录不存在，就创建一个； ‘cat &gt;&gt; .ssh/authorized_keys’ &lt; ~/.ssh/id_rsa.pub的作用是，将本地的公钥文件~/.ssh/id_rsa.pub，重定向追加到远程文件authorized_keys的末尾。 写入authorized_keys文件后，公钥登录的设置就完成了。 参考簡易 Telnet 與 SSH 主機設定 SSH原理与运用（一）：远程登录]]></content>
      <categories>
        <category>编程</category>
      </categories>
      <tags>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[java日志框架的使用]]></title>
    <url>%2F2017%2F02%2F21%2Fjava%E6%97%A5%E5%BF%97%E4%BD%BF%E7%94%A8%2F</url>
    <content type="text"><![CDATA[之前在web项目中用到了日志，日志在web应用中很重要，特别是对于程序员追查bug而言。但是由于对混乱的日志框架体系不是十分清楚，导致各种jar包冲突和日志不正常输出。今天来总结一下日志框架的使用主要介绍日志门面slf4j结合日志实现log4j。关于其他的日志框架介绍和使用，参考链接里列出了前辈总结的很好的资料，相信读完之后一定会有收获。 日志门面和实际日志框架日志框架有：jdk自带的logging(jul)，log4j1、log4j2、logback日志门面有：apache commons-logging、slf4j 日志框架很好理解，就是提供日志api，使我们可以很轻易的，有组织有规范的输出日志。日志门面的作用是在日志记录实现的基础上提供一个封装的 API 层次，对日志记录 API 的使用者提供一个统一的接口，使得可以自由切换不同的日志记录实现。日志门面就好比java中的jdbc规范接口，各个数据库厂家实现的jdbc驱动程序就是实际的日志框架，他们遵循了这个规范，使得我们在编写java程序时不用考虑底层驱动的不同，只需调用jdbc规范接口即可。这是典型的面向对象思想。 slf4j的使用简介 上图来自slf4j官网 slf4j-api.jar包含了slf4j的抽象层API，我们在代码中调用这个jar包中的接口。API层 slf4j-log412.jar、slf4j-jdk14.jar等是slf4j通向具体日志实现框架的桥梁。中间层 log4j.jar等则是具体的日志实现框架。实现层 SLF4J does not rely on any special class loader machinery. In fact, each SLF4J binding is hardwired at compile time to use one and only one specific logging framework. For example, the slf4j-log4j12-1.7.23.jar binding is bound at compile time to use log4j. In your code, in addition to slf4j-api-1.7.23.jar, you simply drop one and only one binding of your choice onto the appropriate class path location. Do not place more than one binding on your class path. Here is a graphical illustration of the general idea. 上面这段话的意思大概是，我们不应该在classpath中绑定多于一个的中间层，否则会导致jar包冲突或者输出混乱。 To switch logging frameworks, just replace slf4j bindings on your class path. For example, to switch from java.util.logging to log4j, just replace slf4j-jdk14-1.7.23.jar with slf4j-log4j12-1.7.23.jar. 当我们需要将日志实现由jul切换到log4j时，仅仅把中间层替换，同时切换实现层即可，并不需要修改代码。这就是日志门面的好处。不过实际应用中，需要切换日志实现的场景貌似不是很多。 slf4j结合log4j依赖需要的jar包：slf4j-api.jar、slf4j-log4j12.jar、log4j.jar 对应的maven依赖： 123456789101112131415&lt;dependency&gt; &lt;groupId&gt;org.slf4j&lt;/groupId&gt; &lt;artifactId&gt;slf4j-api&lt;/artifactId&gt; &lt;version&gt;1.7.23&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.slf4j&lt;/groupId&gt; &lt;artifactId&gt;slf4j-log4j12&lt;/artifactId&gt; &lt;version&gt;1.7.23&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;log4j&lt;/groupId&gt; &lt;artifactId&gt;log4j&lt;/artifactId&gt; &lt;version&gt;1.2.17&lt;/version&gt;&lt;/dependency&gt; 使用编写log4j.properties配置文件，放到类路径下 123456log4j.rootLogger=INFO,stdoutlog4j.appender.stdout=org.apache.log4j.ConsoleAppenderlog4j.appender.stdout.Target=System.outlog4j.appender.stdout.layout=org.apache.log4j.PatternLayoutlog4j.appender.stdout.layout.ConversionPattern=[%-5p] %d&#123;yyyy-MM-dd HH:mm:ss,SSS&#125; method:%l%n%m%n java代码 123456789101112131415161718package space.kyu.LogTest.log4j;import org.slf4j.Logger;import org.slf4j.LoggerFactory;public class Test &#123; public static Logger logger = LoggerFactory.getLogger(Test.class); public void test() &#123; logger.info(&quot;info&quot;); logger.debug(&quot;debug&quot;); logger.warn(&quot;warn&quot;); logger.error(&quot;error&quot;); &#125; public static void main(String[] args) &#123; new Test().test(); &#125;&#125; 输出 123456[INFO ] 2017-02-21 14:52:28,083 method:space.kyu.LogTest.log4j.Test.test(Test.java:10)info[WARN ] 2017-02-21 14:52:28,085 method:space.kyu.LogTest.log4j.Test.test(Test.java:12)warn[ERROR] 2017-02-21 14:52:28,085 method:space.kyu.LogTest.log4j.Test.test(Test.java:13)error 原理slf4j-api.jar: org.slf4j.LoggerFactory1234public static Logger getLogger(String name) &#123; ILoggerFactory iLoggerFactory = getILoggerFactory(); return iLoggerFactory.getLogger(name);&#125; 可以看到，主要分为两部分，获取ILoggerFactory，使用ILoggerFactory获取logger. slf4j-api.jar: org.slf4j.LoggerFactory1234567891011121314151617181920212223public static ILoggerFactory getILoggerFactory() &#123; if (INITIALIZATION_STATE == UNINITIALIZED) &#123; synchronized (LoggerFactory.class) &#123; if (INITIALIZATION_STATE == UNINITIALIZED) &#123; INITIALIZATION_STATE = ONGOING_INITIALIZATION; performInitialization(); &#125; &#125; &#125; switch (INITIALIZATION_STATE) &#123; case SUCCESSFUL_INITIALIZATION: return StaticLoggerBinder.getSingleton().getLoggerFactory(); case NOP_FALLBACK_INITIALIZATION: return NOP_FALLBACK_FACTORY; case FAILED_INITIALIZATION: throw new IllegalStateException(UNSUCCESSFUL_INIT_MSG); case ONGOING_INITIALIZATION: // support re-entrant behavior. // See also http://jira.qos.ch/browse/SLF4J-97 return SUBST_FACTORY; &#125; throw new IllegalStateException(&quot;Unreachable code&quot;);&#125; 注意return StaticLoggerBinder.getSingleton().getLoggerFactory();这行，StaticLoggerBinder是slf4j-log4j12.jar中的类 slf4j-log4j12.jar: org.slf4j.impl.StaticLoggerBinder123456789private StaticLoggerBinder() &#123; loggerFactory = new Log4jLoggerFactory(); try &#123; @SuppressWarnings(&quot;unused&quot;) Level level = Level.TRACE; &#125; catch (NoSuchFieldError nsfe) &#123; Util.report(&quot;This version of SLF4J requires log4j version 1.2.12 or later. See also http://www.slf4j.org/codes.html#log4j_version&quot;); &#125;&#125; slf4j-log4j12.jar: org.slf4j.impl.Log4jLoggerFactory12345public Log4jLoggerFactory() &#123; loggerMap = new ConcurrentHashMap&lt;String, Logger&gt;(); // force log4j to initialize org.apache.log4j.LogManager.getRootLogger();&#125; 注意org.apache.log4j.LogManager.getRootLogger();初始化了log4j为具体的日志实现 追踪源代码还可以发现，我们在代码中调用的LoggerFactory.getLogger(Test.class);最终返回的是org.apache.log4j.Logger实例，也就是说，日志实现最终托付给了log4j log4j的使用日志组件Loggers：Logger负责捕捉事件并将其发送给合适的Appender。 Appenders：也被称为Handlers，负责将日志事件记录到目标位置。在将日志事件输出之前，Appenders使用Layouts来对事件进行格式化处理。 Layouts：也被称为Formatters，它负责对日志事件中的数据进行转换和格式化。Layouts决定了数据在一条日志记录中的最终形式。 当Logger记录一个事件时，它将事件转发给适当的Appender。然后Appender使用Layout来对日志记录进行格式化，并将其发送给控制台、文件或者其它目标位置。 日志级别每个Logger都被了一个日志级别（log level），用来控制日志信息的输出。日志级别从高到低分为： org.apache.log4j.Level12345678public final static int OFF_INT = Integer.MAX_VALUE;public final static int FATAL_INT = 50000;public final static int ERROR_INT = 40000;public final static int WARN_INT = 30000;public final static int INFO_INT = 20000;public final static int DEBUG_INT = 10000; //public final static int FINE_INT = DEBUG_INT;public final static int ALL_INT = Integer.MIN_VALUE; A：off 最高等级，用于关闭所有日志记录。 B：fatal 指出每个严重的错误事件将会导致应用程序的退出。 C：error 指出虽然发生错误事件，但仍然不影响系统的继续运行。 D：warm 表明会出现潜在的错误情形。 E：info 一般和在粗粒度级别上，强调应用程序的运行全程。 F：debug 一般用于细粒度级别上，对调试应用程序非常有帮助。 G：all 最低等级，用于打开所有日志记录。 我们一般只是用error,warn,info和debug就够了。 配置文件编写了解了组件和日志级别，我们可以编写自己的配置文件，log4j.properties放到类路径下，如果缺少了配置文件，log4j会报错。我们也可以使用PropertyConfigurator.configure ( String configFilename)来指定配置文件 配置logger配置根logger：log4j.rootLogger = [ level ] , appenderName, appenderName, … 比如：log4j.rootLogger=INFO,stdout level为日志级别，表示这个logger只打印级别大于等于level的日志。 appenderName定义了如何处理日志，即把日志输出到哪个地方，如何输出。 可以看出，一个logger可以根据appender同时输出到多个地方，logger与appender是一对多的关系。 我们也可以定义自己的logger：log4j.logger.yukai=DEBUG,stdout 配置appenderappender定义了日志输出的目的地：log4j.appender.appenderName = fully.qualified.name.of.appender.class 其中，Log4j提供的常用的appender： org.apache.log4j.ConsoleAppender（控制台）， org.apache.log4j.FileAppender（文件）， org.apache.log4j.DailyRollingFileAppender（每天产生一个日志文件）， org.apache.log4j.RollingFileAppender（文件大小到达指定尺寸的时候产生一个新的文件）， org.apache.log4j.WriterAppender（将日志信息以流格式发送到任意指定的地方） 我们还可以设置appender的属性，比如针对ConsoleAppender 123456属性 描述layout Appender 使用 Layout 对象和与之关联的模式来格式化日志信息。target 目的地可以是控制台、文件，或依赖于 appender 的对象。level 级别用来控制过滤日志信息。threshold Appender 可脱离于日志级别定义一个阀值级别，Appender 对象会忽略所有级别低于阀值级别的日志。filter Filter 对象可在级别基础之上分析日志信息，来决定 Appender 对象是否处理或忽略一条日志记录。 配置layout一个appender可以关联某一个layout，用来格式化日志的输出。可用的layout有以下几种： org.apache.log4j.HTMLLayout（以HTML表格形式布局）， org.apache.log4j.PatternLayout（可以灵活地指定布局模式）， org.apache.log4j.SimpleLayout（包含日志信息的级别和信息字符串）， org.apache.log4j.TTCCLayout（包含日志产生的时间、线程、类别等等信息） 可用的格式： %m 输出代码中指定的消息 %p 输出优先级，即DEBUG，INFO，WARN，ERROR，FATAL %r 输出自应用启动到输出该log信息耗费的毫秒数 %c 输出所属的类目，通常就是所在类的全名 %t 输出产生该日志事件的线程名 %n 输出一个回车换行符，Windows平台为”rn”，Unix平台为”n” %d 输出日志时间点的日期或时间，默认格式为ISO8601，也可以在其后指定格式，比如：%d{yyy MMM dd HH:mm:ss,SSS}，输出类似：2002年10月18日 22：10：28，921 %l 输出日志事件的发生位置，包括类目名、发生的线程，以及在代码中的行数。举例：Testlog4.main(Test Log4.java:10) 比如： 12log4j.appender.stdout.layout=org.apache.log4j.PatternLayoutlog4j.appender.stdout.layout.ConversionPattern=[%-5p] %d&#123;yyyy-MM-dd HH:mm:ss,SSS&#125; method:%l%n%m%n 打印的信息： 12[ERROR] 2017-02-21 16:41:25,563 method:space.kyu.LogTest.log4j.Test.test(Test.java:13)info logger的继承关系我们可以定义自己的logger：log4j.logger.yukai=DEBUG,stdout 其中，yukai指定了这个logger的名字，可以在代码中使用它： 1public static Logger logger = LoggerFactory.getLogger(&quot;yukai&quot;); 假如我们同时定义这样一个logger：log4j.logger.yukai.child=DEBUG,stdout 就表示yukai.child这个logger继承了yukai这个logger，更java中的包有些类似 在代码中使用： 1public static Logger logger = LoggerFactory.getLogger(&quot;yukai.child&quot;); 使用了该logger会默认实现自身的设定和父Logger的设定。比如使用该logger打印了一条debug信息，同样的打印动作会执行两次，因为父logger的打印动作也会实现。 上面提到的rootlogger就是所有looger的根logger。 我们经常在代码中使用 public static Logger logger = LoggerFactory.getLogger(Test.calss);这样的方式，因此我们可以通过指定包名的logger来控制某个包下面所有的logger输出。比如： 我们指定：log4j.logger.space.kyu=DEBUG,stdout,就表示space.kyu包下面的所有logger(以LoggerFactory.getLogger(Test.calss);这种方式获取的)都继承该logger的设定。这在分层的应用或功能性应用中有可以用到。 可以通过配置log4j.additivity.XXX=ture/false来打开或关闭继承功能；若为 false,表示Logger 的 appender 不继承它的父Logger； 若为true，则继承，这样就兼有自身的设定和父Logger的设定。 MDC的使用 在一个高访问量的 Web 应用中，经常要在同一时刻处理大量的用户请求。Web 服务器会为每一个请求分配一个线程，每一个线程都会向日志系统输入一些信息，通常日志系统都是按照时间顺序而不是用户顺序排列这些信息的，这些线程的交替运行会让所有用户的处理信息交错在一起，让人很难分辨出那些记录是同一个用户产生的。另外，高可用性的网站经常会使用负载均衡系统平衡网络流量，这样一个用户的操作记录很可能会分布在多个 Web 服务器上，如果我们没有一种方法来标示一条记录是哪个用户产生的，从这众多的日志信息中筛选出对我们有用的东西将是一项艰巨的工作。 NDC或MDC就是用来解决这个问题的。 MDC 可以看成是一个与当前线程绑定的哈希表，可以往其中添加键值对。MDC 中包含的内容可以被同一线程中执行的代码所访问。当前线程的子线程会继承其父线程中的 MDC 的内容。当需要记录日志时，只需要从 MDC 中获取所需的信息即可。MDC 的内容则由程序在适当的时候保存进去。对于一个 Web 应用来说，通常是在请求被处理的最开始保存这些数据。 1234567891011121314151617public class App &#123; private static final Logger logger = LoggerFactory.getLogger(App.class); public static void main(String[] args) &#123; new App().log(&quot;main thread&quot;); new Thread()&#123; public void run() &#123; new App().log(&quot;sub thread&quot;); &#125;; &#125;.start(); &#125; public void log(String arg) &#123; MDC.put(&quot;username&quot;, &quot;Yukai&quot;); logger.info(&quot;This message from : &#123;&#125;&quot;, arg); &#125;&#125; 设置appender: log4j.appender.stdout.layout.ConversionPattern=%X{username} %d{yyyy-MM-dd HH:mm:ss} [%p] %c - %m%n 输出 Yukai 2017-02-21 22:10:54 [INFO] space.kyu.log_test.App - This message from : main threadYukai 2017-02-21 22:10:54 [INFO] space.kyu.log_test.App - This message from : sub thread 参考SLF4J user manual JDK Logging深入分析 jdk-logging、log4j、logback日志介绍及原理 commons-logging与jdk-logging、log4j1、log4j2、logback的集成原理 slf4j与jdk-logging、log4j1、log4j2、logback的集成原理 slf4j、jcl、jul、log4j1、log4j2、logback大总结 Java 日志管理最佳实践]]></content>
      <categories>
        <category>工具</category>
      </categories>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[java国际化]]></title>
    <url>%2F2017%2F02%2F19%2Fjava%E5%9B%BD%E9%99%85%E5%8C%96%2F</url>
    <content type="text"><![CDATA[使用java编写一个带GUI程序或者其他需要给用户传递文字信息的程序的时候，就很有可能需要用到国际化的知识，来总结一下。 所谓的国际化，就是使编写的程序可以适应不同的语言环境，比如，在中文环境下，可以与用户使用中文交互，在英文环境下则切换为英文。而这个切换过程不需要修改代码或者仅仅修改少量的代码。java给我们提供了这样的实现。 java文件国际化我们通过将与界面显示有关系的资源提取出来到资源文件中，然后读取不同的资源文件来达到国际化的目的。在java中，这些是通过ResourceBundle这个类来实现的。 ResourceBundle分为两种，一种是ListResourceBundle,另一种是PropertyResourceBundle。下面介绍这两种ResourceBundle的使用方法： 首先列出demo工程的代码结构： 1234567891011121314151617181920212223242526272829TestResourceBundle||--src | |--kyu | |--bundle | | | |--ListResourceTranslator.java | | | |--PropertyResourceTranslator.java | | | |--ResourceTranslator.java | |--test | | | |--App.java | |--Errors_en_Us.java | |--Errors_zh_CN.java | |--Errors.java | |--Errors_en_Us.properties | |--Errors_zh_CN.properties | |--Errors.properties PropertyResourceBundle 首先需要建立若干语言的properties文件： 自定义名语言代码国别代码.properties 比如：errors_en_US.properties, errors_zh_CN.properties 其中的语言代码和国别代码，分别是你要国际化的语言。需要几种语言，就添加几个properties文件。 国别代码 语言代码 通过打印java所支持的语言和国家查看： 1234567private static void printLocal() &#123; Locale[] localeList = Locale.getAvailableLocales(); for (int i = 0; i &lt; localeList.length; i++) &#123; System.out.println(localeList[i].getDisplayCountry() + &quot;: &quot; + localeList[i].getCountry()); System.out.println(localeList[i].getDisplayLanguage() + &quot;: &quot; + localeList[i].getLanguage()); &#125;&#125; 建立默认语言的properties文件：自定义名.properties 比如：errors.properties 当所需语言的properties文件不存在的时候就会默认读取这个文件中的内容 注意，资源文件都必须是ISO-8859-1编码，对于中文等非西方语系，可通过JDK自带的工具native2ascii进行处理，在Eclipse中也可以安装插件SimplePropertiesEditor来处理这类文件。 使用 ResourceTranslator.java 1234567891011121314package kyu.bundle;import java.util.Locale;import java.util.ResourceBundle;public abstract class ResourceTranslator &#123; protected ResourceBundle bundle; protected Locale lc; protected static final String PROP_FILE = &quot;kyu.errors&quot;; public String translate(String id) &#123; return bundle.getString(id); &#125;&#125; PropertyResourceTranslator.java 123456789101112131415161718package kyu.bundle;import java.util.Locale;import java.util.PropertyResourceBundle;import java.util.ResourceBundle;public class PropertyResourceTranslator extends ResourceTranslator&#123; public PropertyResourceTranslator() &#123; lc = Locale.getDefault(); bundle = PropertyResourceBundle.getBundle(PROP_FILE, lc); &#125; public PropertyResourceTranslator(String language, String country) &#123; lc = new Locale(language, country); bundle = PropertyResourceBundle.getBundle(PROP_FILE, lc); &#125;&#125; App.java 12345678910111213141516171819202122232425package kyu.test;import kyu.bundle.ListResourceTranslator;import kyu.bundle.PropertyResourceTranslator;public class App &#123; public static void main(String[] args) &#123; testPropertyResource(); &#125; private static void testPropertyResource() &#123; PropertyResourceTranslator translatorDefault = new PropertyResourceTranslator(); PropertyResourceTranslator translatorZH = new PropertyResourceTranslator(&quot;zh&quot;, &quot;CN&quot;); PropertyResourceTranslator translatorEN = new PropertyResourceTranslator(&quot;en&quot;, &quot;US&quot;); String def = translatorDefault.translate(&quot;ERROR-001&quot;); String zh = translatorZH.translate(&quot;ERROR-001&quot;); String en = translatorEN.translate(&quot;ERROR-001&quot;); System.out.println(&quot;test PropertyResourceBundle&gt;&gt;&gt;&gt;&gt;&gt;&quot;); System.out.println(&quot;default: &quot; + def); System.out.println(&quot;zh: &quot; + zh); System.out.println(&quot;en: &quot; + en); &#125; &#125; .properties文件内容： 12345678Errors_en_Us.properties:ERROR-001=error passwordErrors.propertiesERROR-001=error passwordErrors_zh_CN.propertiesERROR-001=密码错误 执行App.java的测试结果： 1234test PropertyResourceBundle&gt;&gt;&gt;&gt;&gt;&gt;default: 密码错误zh: 密码错误en: error password 可以看到，通过指定Local构造函数的语言和国别代码，就能自动找到对应的.properties，并匹配其中的内容。 当使用Locale.getDefault()时，自动检测当前的系统环境，从而选择对应的语言。 还有一点要注意的是： PropertyResourceBundle.getBundle(PROP_FILE, lc); 其中PROP_FILE，为properties文件的路径，此路径为properties文件的完整路径，即 所在完整包名.自定义名称 ListResourceBundleListResourceBundle的使用与PropertyResourceBundle的使用大同小异，不过是将properties文件换成了.java文件 ListResourceTranslator.java 12345678910111213141516package kyu.bundle;import java.util.ListResourceBundle;import java.util.Locale;public class ListResourceTranslator extends ResourceTranslator&#123; public ListResourceTranslator() &#123; lc = Locale.getDefault(); bundle = ListResourceBundle.getBundle(PROP_FILE, lc); &#125; public ListResourceTranslator(String language, String country) &#123; lc = new Locale(language, country); bundle = ListResourceBundle.getBundle(PROP_FILE, lc); &#125;&#125; ERRORS_en_US.java 12345678910111213package kyu;import java.util.ListResourceBundle;public class ERRORS_en_US extends ListResourceBundle&#123; static final Object[][] contents = new String[][] &#123; &#123; &quot;ERROR-001&quot;, &quot;error password&quot; &#125; &#125;; public Object[][] getContents() &#123; return contents; &#125;&#125; ERRORS_zh_CN.java 12345678910111213package kyu;import java.util.ListResourceBundle;public class ERRORS_zh_CN extends ListResourceBundle &#123; static final Object[][] contents = new String[][] &#123; &#123; &quot;ERROR-001&quot;, &quot;密码错误&quot; &#125; &#125;; public Object[][] getContents() &#123; return contents; &#125;&#125; 继承了ListResourceBundle的类就相当于前面的properties文件，需要提供一个getContents()方法，返回对应的键值对。 同样的，要注意ListResourceBundle子类的命名规则，与properties文件相同，路径也与properties文件相同。 通过App.java的测试(将对应的bundle替换)，可以得到相同的测试结果。 使用Eclipse对java文件进行国际化在需要国际化的类文件上点击右键-&gt;Source-&gt;Externalize Strings… 出现窗口，Eclipse会自动检测类文件中的字符串，在窗口中可以选择相应的字符串，最后自动生成类似于上面的PropertyResourceTranslator.java和properties文件，完成国际化。 其原理与以上所讲的相同，故不再详细说明。 Eclipse RCP国际化 最近在使用Eclipse RCP这项技术开发程序，其中也有国际化相关的东西，总结下来。 Eclipse RCP and Plugin Internationalization - Tutorial 上面这篇文章详细的说明了Eclipse RCP工程中的国际化问题，可以作为一个备忘录。下面介绍一下eclipse rcp中比较常用到的国际化方式： plugin.xml文件国际化plugin.xml文件中保存了扩展点等相关的信息，当扩展点与界面UI相关时，就需要用到国际化 在工程的根目录下面建立一个plugin.properties资源文件，此文件类似于我们上面提到的errors.properties。当然，也可以建立plugin_zh.properties等文件，这些文件名中的plugin是可以自由定义的。 在 MANIFEST.MF文件中增加代码行：Bundle-Localization: plugin 注意，这个plugin与上面的properties文件名保持一致。 plugin.xml配置文件对资源文件进行引用时, 在引用的key前面加一个%，比如： 12345678&lt;view id=&quot;org.jkiss.dbeaver.core.databaseNavigator&quot; category=&quot;org.jkiss.dbeaver.core.category&quot; class=&quot;org.jkiss.dbeaver.ui.navigator.database.DatabaseNavigatorView&quot; allowMultiple=&quot;false&quot; icon=&quot;icons/databases.png&quot; name=&quot;%view.database.navigator.title&quot;/&gt;&lt;view 类文件国际化与前面所介绍的java类文件国际化相同，也可以通过选择类文件点击右键-&gt;Source-&gt;Externalize Strings… Eclipse IDE会自动帮你完成国际化的一些工作，同样也生成了相关的类和properties文件，但不同的是，生成的类文件内容类似于： 1234567891011121314151617package test;import org.eclipse.osgi.util.NLS;public class Messages extends NLS &#123; private static final String BUNDLE_NAME = &quot;test.messages&quot;; //$NON-NLS-1$ public static String View_0; public static String View_1; static &#123; // initialize resource bundle NLS.initializeMessages(BUNDLE_NAME, Messages.class); &#125; private Messages() &#123; &#125;&#125; 当然，我们也可以手动建立这些文件进行国际化操作~~不再详细说明，可以通过观察IDE的行为进行我们手动的国际化操作~]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[win7与centos7双系统安装]]></title>
    <url>%2F2017%2F02%2F18%2Fwin7%E4%B8%8Ecentos7%E5%8F%8C%E7%B3%BB%E7%BB%9F%E5%AE%89%E8%A3%85%2F</url>
    <content type="text"><![CDATA[之前会有同学让帮忙重装操作系统，正好计划重新装一下自己电脑的系统，折腾了win7与linux双系统，在此记录。以后就可以给他们看这篇笔记自己去装啦~ ps: 由于是双系统的安装操作，而不是虚拟机，所以并未截图，是纯文字说明。如果不清楚，可以参考最下面的参考链接 安装win7下载win7镜像文件：系统之家win7下载 选择一款进行下载，我选择了雨林木风 GHOST WIN7 SP1 X64 装机旗舰版 V2017.02（64位） 制作U盘启动工具下载启动盘制作工具： 老毛桃u盘启动盘制作工具 下载装机版，进行安装 启动盘制作工具安装完成，且镜像下载完毕之后，启动老毛桃，选择U盘启动-&gt;默认模式 插入一个可用的U盘，在选择设备这项中，选择插入的U盘设备，注意不要选错 其他选项默认，点击 开始制作 进行启动盘的制作。 启动盘制作完毕之后，将下载好的iso文件拷入U盘 安装win7插入制作好的启动盘，重启电脑 开机画面出现时，按下F12，boot options(我的电脑是DELL的，其他品牌电脑自行查找) 选择USB启动 老毛桃启动盘正常启动，此时选择第二项，win8pe,点击进入win8pe 首先进行分区，选择分区工具，可以自由设置分区数目和分区大小(我分了3个区，一个用来装win7(C)，一个用来做Windows的资料盘(D)，另外一个用来安装Linux(E)) 双击win8pe桌面上的“diskgenius分区工具”图标，在弹出的窗口中点击“快速分区”，即可启动分区工具，具体的分区方法参考官网介绍：老毛桃分区工具的使用 设置好分区后，鼠标左键双击打开桌面上的“老毛桃PE装机工具”，选择“还原分区”，映像文件路径选择上一步拷入U盘的镜像，然后选择要装入的分区(C盘)，点击确认开始自动装机。 系统自动重启几次之后，就安装好了，可以卸载一些不必要的系统自带软件，此时的操作系统已经是激活的版本了（我下载的镜像是），各种需要的驱动也都安装完毕，简单省事。 安装centos7查看磁盘分区情况右键计算机-&gt;管理，打开计算机管理程序。选择磁盘管理，查看分区情况。 选择之前分好的E盘，右键“删除卷”，使之状态变为“可用空间”，以便centos安装程序识别。 制作U盘启动工具下载centos7镜像文件（DVD版本即可） CentOS-7-x86_64-DVD-1611.iso 下载烧录U盘工具 ImageUsb 插入一个可用的U盘 启动 imageusb.exe， step1 选择要写入的U盘; step2 选择 write image to USB driver; step3 选择下载好的centos7镜像文件 step4 点击 write ，开始烧录启动盘 启动盘烧录完毕后，可以开始安装centos 安装centos7插入制作好的启动盘，重启电脑 开机画面出现时，按下F12 (我的电脑是DELL的，其他品牌电脑自行查找) 选择USB启动 选择第一项，Install CentOs 7 ，回车，开始安装CentOS 7 之后就进入了简单的可视化安装界面，有几点需要注意： 1.分区选择 如果是像上面一样分了3个区，两个被Windows使用，还剩一个分区未被使用，那么可以选择自动选择分区，centos安装程序会自动选择好这块未被使用的分区（将“/”目录挂载到这个分区上面） 也可以自定义分区，建议分四个区：/ /boot /home swap（如果有这么些分区的话） 2.在之后的安装信息摘要中，注意“软件”-“软件选择”，默认是最小安装，即不安装桌面环境，若选择此项，则只有命令行界面，应该选择带有UI界面的选项。 之后就是很简单的安装了 配置引导程序再次启动电脑之后，会发现自动进入Linux，没有win7系统的选项，此时需要配置引导程序 首先添加ntfs支持 123wget -O /etc/yum.repos.d/epel.repo http://mirrors.aliyun.com/repo/epel-7.repoyum update;yum install ntfs-3g 安装完毕后打开终端，运行grub2-mkconfig -o /boot/grub2/grub.cfg 就会重新生成引导项，重启电脑即可 参考老毛桃u盘安装原版win7系统详细教程 老毛桃分区工具的使用 CentOS 7.0系统安装配置图解教程]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Vps使用笔记]]></title>
    <url>%2F2017%2F02%2F07%2FVps%E4%BD%BF%E7%94%A8%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[今天折腾了一天，总算是把翻墙的梯子搭起来了，租了国外的vps，然后在上面搭建了shadowsocks服务，手机和电脑就可以使用shadowsocks客户端的方式科学上网了。Shadowsocks 是一个由很多人参与的开源项目，感谢shadowsocks作者@clowwindy.关于shadowssocks和vpn等等翻墙方式的区别,不再一一赘述，本文只是记录梯子搭建的过程 购买VPSVPS的概念我也不是特别清楚，就把他当成主机好了，类似于阿里云等等。 购买之后，会分配给你root账户密码，你就拥有了一台国外机房的主机。 VPS 可以参考 有哪些便宜稳定，速度也不错的Linux VPS 推荐？,我买了Vultr 日本机房的vps,充了5美刀先试试。具体的购买方法自行谷歌 搭建shadowsocks服务升级内核我选择了Centos7的Linux发型版本作为操作系统。 使用MobaXterm(或者是其他ssh工具)连接到分配给你的主机(root密码购买成功时会给出), 首先升级一下内核：wget -O- https://zhujiwiki.com/usr/uploads/2016/12/install_bbr_centos.sh | bash 完成之后，重启： reboot 重新登录，查看内核版本： uname -r 不出意外已经更新到了最新版本。接着执行： sysctl -a|grep congestion_control 如果输出选项包含：net.ipv4.tcp_congestion_control = bbr 表示安装成功，否则需要手动开启bbr模式： 12345echo &quot;net.core.default_qdisc=fq&quot; &gt;&gt; /etc/sysctl.confecho &quot;net.ipv4.tcp_congestion_control=bbr&quot; &gt;&gt; /etc/sysctl.confsysctl -psysctlnet.ipv4.tcp_available_congestion_control 再次查看： sysctl -a|grep congestion_control 搭建服务搭建服务可以选择使用别人写好的现成的脚本，也可以自己搭建，下面介绍这两种方法： 使用现成脚本执行以下命令： --no-check-certificatelink12chmod +x shadowsocks.sh./shadowsocks.sh 2&gt;&amp;1 | tee shadowsocks.log 首先会提示你输入密码和端口，然后开始安装。安装完成后代表shadowsocks服务已经开启了。此时可以使用shadowsocks客户端去连接这个服务器了。 脚本可用的命令： 启动：/etc/init.d/shadowsocks start 停止：/etc/init.d/shadowsocks stop 重启：/etc/init.d/shadowsocks restart 状态：/etc/init.d/shadowsocks status 卸载：./shadowsocks.sh uninstall 支持多用户的方法：修改配置文件:/etc/shadowsocks.json 123456789101112131415&#123; &quot;server&quot;:&quot;0.0.0.0&quot;, &quot;local_address&quot;:&quot;127.0.0.1&quot;, &quot;local_port&quot;:1080, &quot;port_password&quot;:&#123; &quot;8989&quot;:&quot;password0&quot;, &quot;9001&quot;:&quot;password1&quot;, &quot;9002&quot;:&quot;password2&quot;, &quot;9003&quot;:&quot;password3&quot;, &quot;9004&quot;:&quot;password4&quot; &#125;, &quot;timeout&quot;:300, &quot;method&quot;:&quot;aes-256-cfb&quot;, &quot;fast_open&quot;: false&#125; 自行搭建首先安装shadowsocks服务： 12yum install python-setuptools &amp;&amp; easy_install pippip install shadowsocks 显示 “Successfully installed shadowsocks-2.6.10″。意味着Shadowsocks已经成功安装。 接着，创建一个Shadowsocks配置文件。输入以下命令： vi /etc/shadowsocks.json 然后在该文件中输入： 12345678910&#123; &quot;server&quot;:&quot;your_server_ip&quot;, &quot;server_port&quot;:8388, &quot;local_address&quot;: &quot;127.0.0.1&quot;, &quot;local_port&quot;:1080, &quot;password&quot;:&quot;auooo.com&quot;, &quot;timeout&quot;:300, &quot;method&quot;:&quot;aes-256-cfb&quot;, &quot;fast_open&quot;: false&#125; 上面各项配置的含义已经很明显了，除了server(vps的ip)、server_port和password之外，其他默认即可。保存该文件。执行： ssserver -c /etc/shadowsocks.json -d start 服务就启动了，如果想要关闭，执行： ssserver -c /etc/shadowsocks.json -d stop 支持多用户的方法与上面的类似 端口问题有时候服务正常启动了，但是发现客户端还是没有办法翻墙。这时要注意检查vps开放的端口： Centos升级到7之后，使用firewalld代替了原来的iptables作为防火墙。 启动：systemctl start firewalld 重启：firewall-cmd –reload 查看状态：systemctl status firewalld 或者 firewall-cmd –state 查看开放的端口：firewall-cmd –list-ports 增加开放端口：firewall-cmd –add-port=9001/tcp –permanent (重启生效) 9001：要开放的端口 tcp：协议 –permanent：永久生效，没有此参数重启后失效其他命令自行查找 锐速加速锐速破解版linux一键自动安装包（8月7日更新） 文章开头的更新内核使用bbr加速或者锐速加速都可以，没试过哪种方式效果更好一些 vps使用ssh密钥登录使用ssh root账户和密码登录的方式是vps一开始会给出的登录主机的方式，这种方式比较简单，但是容易被别人暴力破解登录密码，控制我们的主机。 所以，应该使用ssh密钥登录的方式来增强安全性。 修改root密码第一步应该先把默认的root密码修改为自己的密码，最好复杂一点。 确保自己记住了这个密码。 passwd 创建用户可以先创建一个非root用户： 1useradd yukai 创建账户密码： 1passwd yukai 给予账户sudo权限： 1visudo 在 root ALL=(ALL) ALL 下新增一行： yukai ALL=(ALL) ALL 切换到yukai这个账户： su - yukai 创建密钥1ssh-keygen -t rsa 在 /home/yukai 下生成了一个隐藏目录：.ssh, 执行： 12cd ~/.sshcat id_rsa.pub &gt;&gt; authorized_keyschmod 600 authorized_keys 将 id_rsa文件下载下来保存到本地(使用MobaXterm等工具) 使用密钥认证登录打开MobaXterm工具，新建一个session，选择ssh，在Advanced SSH settings选项中选择 use private keygen复选框，并把上一步下载好的id_rsa选择进来。 以用户yukai登录，提示输入密钥文件的密码，输入生成密钥时所填的密码，如果能够登录，则设置正确了 禁用root用户登录和密码登录确保自己记住了root密码，并且上一步密钥认证方式登录成功。 1sudo vi /etc/ssh/sshd_config 找到以下几项，进行如下设置： 1234RSAAuthentication yesPubkeyAuthentication yesPermitRootLogin noPasswordAuthentication no 重启ssh服务： 1service sshd restart 多台主机管理可以将生成的密钥文件authorized_keys保存到多个主机的相同位置：~/.ssh 然后进行上面的配置。此时就可以使用一份私钥文件id_rsa登录多个主机了。 ss多用户管理前端使用ss-panel，后台使用shadowsocks-manyuser 教程参见： 可能是最好的 ss-panel 部署教程 ShadowSocks多用户管理系统搭建（moeSS+manyuser） 在Linux上使用shadowsocks服务翻墙开启shadowsocks客户端确认安装了shadowsocks服务并从配置好的shadowsocks服务器端获得配置文件: /etc/shadowsocks/config.json 1234567891011&#123; &quot;server&quot;:&quot;remote-shadowsocks-server-ip-addr&quot;, &quot;server_port&quot;:443, &quot;local_address&quot;:&quot;127.0.0.1&quot;, &quot;local_port&quot;:1080, &quot;password&quot;:&quot;your-passwd&quot;, &quot;timeout&quot;:300, &quot;method&quot;:&quot;aes-256-cfb&quot;, &quot;fast_open&quot;:false, &quot;workers&quot;:1&#125; 在config.json所在目录下运行sslocal即可： sslocal -c /etc/shadowsocks/config.json 也可以手动指定参数运行： sslocal -s 服务器地址 -p 服务器端口 -l 本地端端口 -k 密码 -m 加密方法 使用chrome代理在chrome应用商店中查找 Proxy SwitchyOmega,并安装该扩展 新建情景模式，代理协议选择SOCKS5，代理服务器选择 127.0.0.1， 代理端口选择上一步中的local_port,即1080 启用该扩展程序，此时可顺利使用google了 附录安装vimvim编辑器需要安装三个包： 123vim-enhanced-7.0.109-7.el5vim-minimal-7.0.109-7.el5vim-common-7.0.109-7.el5 输入 rpm -qa|grep vim 这个命令，如何vim已经正确安装，则会显示上面三个包的名称 如果缺少了其中某个，比如说： vim-enhanced这个包少了，执行：yum -y install vim-enhanced 命令，它会自动下载安装 如果上面三个包一个都没有显示，则直接输入命令： 1yum -y install vim* 安装net-tools1yum install net-tools 更改文件所有者chown -R www.www ./ 将本路径下所有文件所有者改为www组的www 参考Shadowsocks Python版一键安装脚本 使用 Shadowsocks 自建翻墙服务器，实现全平台 100% 翻墙无障碍 http://shadowsocks.org/ shadowsocks（影梭）不完全指南]]></content>
      <categories>
        <category>工具</category>
      </categories>
      <tags>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[java异常的学习]]></title>
    <url>%2F2016%2F12%2F13%2Fjava%E5%BC%82%E5%B8%B8%E7%9A%84%E5%AD%A6%E4%B9%A0%2F</url>
    <content type="text"><![CDATA[最近的写代码的过程中，遇到很多异常的处理，以前上大学的时候写代码，遇到异常直接给个try catch了事，只是停留在看懂异常能够找出异常抛出点的水平。真正写代码的时候，不了解java的异常机制给自己编程带来很多不便，基础知识很重要！学习之～～ 异常分类 java异常中的异常大体上可分为两类：Error 与 Exception，他们都继承自Throwable Error：Error表示一些无法恢复的错误，会导致应用程序中断。比如我们喜闻乐见的OutOfMemoryError(内存溢出)， StackOverflowError(堆栈溢出)等，就是一种Error类型的异常。面对这种类型的异常在我们的应用程序中一般是无法挽救的，将直接导致程序错误退出。因此我们在代码中一般不必去特别关心这种类型的异常。 Error类型的异常及其子类 Exception:Exception是一般常见的异常，我们的应用程序可以处理这些异常，比如NullPointerException、IndexOutOfBoundsException等等。发生这些异常时，可以选择通过捕获这些异常进行处理，使程序可以继续往下执行。 Exception又可以分为CheckException(检测型异常)与UncheckException(非检测型异常)。 在Exception的子类当中，非检测型异常为RuntimeException及其子类，剩下的异常则为检测型异常。 检测型异常所谓检测型异常，表示其接受编译器的检测，比如 12345678910public void readFile(String filePath)&#123; //编译无法通过 File file = new File(filePath); FileReader fileReader = new FileReader(file);//FileNotFoundException BufferedReader bReader = new BufferedReader(fileReader); String line = null; while ((line = bReader.readLine()) != null) &#123;//IOException System.out.println(line); &#125;&#125; 编译上述代码，编译器会报错，编译无法通过。如果是用Eclipse等ide去写这段代码，ide通常就会告诉你这段代码有错误。原因是上述代码会抛出检测型异常IOException。有以下两种修复错误的方法： 123456789101112131415161718192021222324//第一种public void readFile(String filePath) throws IOException&#123; File file = new File(filePath); FileReader fileReader = new FileReader(file); BufferedReader bReader = new BufferedReader(fileReader); String line = null; while ((line = bReader.readLine()) != null) &#123; System.out.println(line); &#125;&#125;//第二种public void readFile(String filePath) &#123; File file = new File(filePath); try &#123; FileReader fileReader = new FileReader(file); BufferedReader bReader = new BufferedReader(fileReader); String line = null; while ((line = bReader.readLine()) != null) &#123; System.out.println(line); &#125; &#125; catch (IOException e) &#123; // TODO: handle exception &#125;&#125; 第一种方式通过声明throws关键字将该异常继续向上抛出，这种方式下，该方法就抛出了检测型异常，他的调用者就会遇到一样的问题，调用者可以选择使用这种方式继续向调用链上层抛出，或者采用第二种方式处理异常。 第二种方式通过将抛出异常的代码使用try..catch块包裹起来，处理该异常。这种方式下他的调用者无需再次处理该异常。 上面这种类型的异常就是检测型异常，我们必须显示的去处理他，代表的有SQLException、IOException等等。 非检测型异常与检测型异常相对的，编译阶段不会检测这种类型的异常，当代码中有这种类型的异常抛出时，我们不需要像上面那样显示的处理他，比如： 1234public void test() &#123; //编译可以通过 throw new NullPointerException();&#125; 通过throw关键字抛出了一个NullPointerException异常，该异常是RunTimeException的子类，是一个非检测类型的异常。这种类型的异常一般是由程序逻辑错误引起的，比如空指针或者数组越界等等。 对于非检测类型的异常，我们也可以去使用try..catch捕获他，从而进行一些处理。如果我们没有捕获处理这个异常，系统会把异常一直往上层抛，一直到最上层，如果是多线程就由Thread.run()抛出，如果是单线程就被main()抛出。抛出之后，如果是线程，这个线程也就退出了。如果是主程序抛出的异常，那么这整个程序也就退出了。 Error实际上也是一种非检测型异常。 异常处理关键字了解了异常的分类，我们就可以愉快的处理异常了。记得上大学的时候写的代码，由于不理解java的异常机制，每当遇到检测型异常时，ide会要求在代码中处理这种情况。于是简单的try..catch解决，并在catch块中 e.printStackTrace()，就解决了IDE的报警问题。现在想来，这种代码如果运行在生产环境中，将会多么可怕。 通过上面的总结，我们已经了解了四个关键字：try catch throw throws. throw表示将要抛出一个异常，后面跟一个Throwable的实例，throws置于函数的声明当中，表示该函数将会抛出何种类型的异常。 try catch 一般配合使用，还有一个关键字finally,也是与try catch 配合使用的。有这三种使用方式： try..catch try..finally try..catch..finally catch 可以有多个，try只能有一个，finally可选。 finally用于保证一些资源的释放，因为一般情况下，finally中的语句总会在方法返回之前得到执行。 try catch finally执行顺序try catch finally的执行顺序为 try-&gt;catch-&gt;finally。 有多个catch时，按照catch块的先后顺序进行匹配，一旦一个异常与一个catch块匹配，则不会再与后面的catch块进行匹配。因此，如果我们使用多个catch块捕获异常时，如果多个catch块捕获的异常具有继承关系，注意把继承链中低层次(也就是子类)的放在前面，把继承链中高层次的(也就是父类)放在后面。这样做的目的很简单，就是尽量使异常被适合的catch所捕获，这样处理起来比较明确。 finally块中的代码一般是在try与catch内的控制转移语句执行之前执行的，用来做一些资源释放的操作。控制转移语句包括：return、throw、break 和 continue。 关于finally块的详细解析，参考关于 Java 中 finally 语句块的深度辨析 另外有一点需要注意：不要在finally中return，因为finally中的return会覆盖已有的返回值，比如try或者catch中的返回值。比如： 1234567891011121314151617181920212223public class TestException &#123; public static void main(String[] args) &#123; String str = new TestException().readFile(); System.out.println(str); &#125; public String readFile() &#123; try &#123; FileInputStream inputStream = new FileInputStream(&quot;D:/test.txt&quot;); int ch = inputStream.read(); return &quot;try&quot;; &#125; catch (FileNotFoundException e) &#123; System.out.println(&quot;file not found&quot;); return &quot;FileNotFoundException&quot;; &#125;catch (IOException e) &#123; System.out.println(&quot;io exception&quot;); return &quot;IOException&quot;; &#125;finally&#123; System.out.println(&quot;finally block&quot;); //return &quot;finally&quot;; &#125; &#125;&#125; D:/test.txt 并不存在，执行结果为:file not found finally block FileNotFoundException去掉finally中的注释，执行结果为：file not found finally block finally 一些建议了解了异常机制的基本原理，不一定能够很好的处理异常。当我们遇到异常需要处理的时候，需要遵循几个原则，才能写出更好的代码： 不要使用空的catch块正如前面所说，上学的时候遇到异常时，直接try..catch了事，只是简单地e.printStackTrace(),把堆栈打印出来了。这样可能对定位异常比较有帮助，但是对异常的处理却没有帮助，既没有处理异常，上层代码也无法得知异常的抛出，程序会继续运行，有可能出现无法预料的结果。当然，如果程序的逻辑容忍异常可以不用处理，那么可以不处理异常，简单的输出到日志记录即可。处理还需视实际情况而定。 在能够处理异常的地方处理异常换句话说，就是在高层代码中处理异常。尽量将异常抛给上层调用者，由上层调用者统一进行处理。这样会使得程序流程比较清晰。 日志打印只在必要的地方打印日志，如只在异常发生的地方输出日志，然后将异常抛到上层。这样比较容易定位异常，避免每次向上抛出异常时都打印日志，反复打印同一个异常会使得日志变得混乱 检测异常与非检测异常的选择为可恢复的条件使用检查型异常，为编程错误使用运行时异常 在web项目中，我们经常把代码层次分为controller，service,dao等几层。在dao层中一搬会抛出SQLException,这就使得他的调用者必须显示的捕获该异常或者继续抛出。这样提高了代码的耦合性，污染了上层代码。在比如接口的声明当中，我们为方法声明了一个检测型异常，那么他的所有实现类都必须作出同样的声明，即使实现类不会抛出异常。而且，所有的调用者都必须显示的捕获异常或者抛出异常，异常就会扩散开来，会使代码变得混乱。所以我们应该正确的选择检测型异常和非检测型异常。个人认为，检测型异常的意义就在于提醒用户进行处理，比如一些资源的释放等等。如果该异常出现的很普遍，需要提醒调用者进行处理，那么就是用检测型异常，否则，就使用非检测型异常。 对于已经抛出的检测型异常，我们可以进行封装处理，比如对于第一种情况，污染上层代码的问题： 12345678910111213141516//处理前public Data getDataById(Long id) throw SQLException &#123; //根据 ID 查询数据库&#125;//处理后public Data getDataById(Long id) &#123; try&#123; //根据 ID 查询数据库 &#125;catch(SQLException e)&#123; //利用非检测异常封装检测异常，降低层次耦合 throw new RuntimeException(SQLErrorCode, e); &#125;finally&#123; //关闭连接，清理资源 &#125;&#125; 我们将一个检测型异常封装成了非检测型异常向上抛出。 不要使用Exception捕捉所有潜在的异常针对具体的异常进行处理，而不是使用Exception捕获所有的异常。这样不利于异常情况的处理，并且如果再次向上抛出时可能会丢书原有的异常信息。 抛出与抽象相适应的异常换句话说，一个方法所抛出的异常应该在一个抽象层次上定义，该抽象层次与该方法做什么相一致，而不一定与方法的底层实现细节相一致。例如，一个从文件、数据库或者 JNDI 装载资源的方法在不能找到资源时，应该抛出某种 ResourceNotFound 异常（通常使用异常链来保存隐含的原因），而不是更底层的 IOException 、 SQLException 或者 NamingException 。 我们有时候在捕获一个异常后抛出另一个封装后的异常信息，并且希望将原始的异常信息也保持起来，throw抛出的是一个新的异常信息，这样势必会导致原有的异常信息丢失，如何保持？在Throwable及其子类中的构造器中都可以接受一个cause参数，该参数保存了原有的异常信息，通过getCause()就可以获取该原始异常信息。 多线程中的异常在java多线程程序中，所有线程都不允许抛出未捕获的检测型异常（比如sleep时的InterruptedException),也就是说各个线程需要自己把自己的检测型处理掉。这一点是通过java.lang.Runnable.run()方法声明(因为此方法声明上没有throw exception部分)进行了约束。但是线程依然有可能抛出非检测型异常，当此类异常跑抛出时，线程就会终结，而对于主线程和其他线程完全不受影响，且完全感知不到某个线程抛出的异常(也是说完全无法catch到这个异常)。 如果我们不考虑线程内可能出现的异常而导致线程的终结，那么就有可能造成意想不到的后果。如果是使用线程池的话，就有可能导致线程泄漏，这样的错误可能难以察觉，最终导致程序挂掉或者内存溢出等等意想不到的问题，但是往往不好追踪问题出现的原因。Java 理论与实践: 嗨，我的线程到哪里去了？这篇文章很好的展示了一个多线程发生异常后产生的一系列后果。 对于线程可以自己处理的异常，比较好解决。我们可以在线程内部捕获异常，作一些处理，防止线程退出。比如，Java 理论与实践: 嗨，我的线程到哪里去了？这篇文章中的一个示例： 12345678910111213141516171819202122private class SaferPoolWorker extends Thread &#123; public void run() &#123; IncomingResponse ir; while (true) &#123; ir = (IncomingResponse) queue.getNext(); PlugIn plugIn = findPlugIn(ir.getResponseId()); if (plugIn != null) &#123; try &#123; plugIn.handleMessage(ir.getResponse()); &#125; catch (RuntimeException e) &#123; // Take some sort of action; // - log the exception and move on // - log the exception and restart the worker thread // - log the exception and unload the offending plug-in &#125; &#125; else log(&quot;Unknown plug-in for response &quot; + ir.getResponseId()); &#125; &#125;&#125; 但是，当子线程发生异常时，我们需要父线程或者主线程可以感知子线程的异常，也就是得到子线程产生的异常，然后做一些处理。Java线程池异常处理最佳实践这篇文章给出了很好的总结，摘抄其总结如下：1234567处理线程池中的异常有两种思路： 1）提交到线程池中的任务自己捕获异常并处理，不抛给线程池 2）由线程池统一处理对于execute方法提交的线程，有两种处理方式 1）自定义线程池并实现afterExecute方法 2）给线程池中的每个线程指定一个UncaughtExceptionHandler,由handler来统一处理异常。对于submit方法提交的任务，异常处理是通过返回的Future对象进行的。 其他还发现了一个比较有趣的异常处理情况，虽然可能很少碰到，但是碰到了可以参考作者的思路。 技巧：当不能抛出异常时这篇文章介绍了一种不是很常见的情况：即不能处理，也不能抛出异常(包括非检测型异常)时怎么办？ 参考Java 异常处理的误区和经验总结 Java异常处理和设计 Java 理论与实践: 关于异常的争论]]></content>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[java远程调试学习]]></title>
    <url>%2F2016%2F12%2F07%2Fjava%E8%BF%9C%E7%A8%8B%E8%B0%83%E8%AF%95%E5%AD%A6%E4%B9%A0%2F</url>
    <content type="text"><![CDATA[集群前后台协议需要做一些修改，我负责jdbc这边的修改。按照协议内容修改完代码之后却面临一个测试的问题：修改后的后台又部署在北京，但北京并不是所有的机器都对天津这边开放，只给提供一台机器A，就是集群的服务器。这样的话,就无法创建节点的连接，测试没有办法进行。 一开始用了最简单的办法，把打好的jar包通过远程ssh放到A上面，再通过ssh去跑用例，打印结果看看正确与否。但是这样的效率真的太低了，每做一次修改都要打包、部署、运行、分析log。于是借这个机会学习一下java程序的远程调试。以下为总结。 一些概念JDPA: java平台调试架构 JVMTI: JVM端调试接口 JDI: java端调试接口 JDWP: java调试网络协议 JPDA 定义了一套如何开发调试工具的接口和规范。 JPDA 由三个独立的模块 JVMTI、JDWP、JDI 组成。 调试者通过 JDI 发送接受调试命令。 JDWP 定义调试者和被调试者交流数据的格式。 JVMTI 可以控制当前虚拟机运行状态。 上图中的前端工具就是我们要用到的调试工具。如JDB、Eclipse等等。这些工具实现了JDI接口，通过这些工具我们可以达到在命令行或者图形界面下调试的目的。 关于这部分，只是简单的了解一下概念，更多的关于JDPA的介绍：JDPA体系 使用JDB进行本地调试JDB 是jdk自带的一个调试工具，用于命令行下调试java程序 jdb.exe就位于jdk安装目录的bin目录下，安装好jdk并设置好环境变量之后就可以愉快的使用jdb了。 12345678910111213141516171819202122232425262728293031323334C:\Users\kyu&gt;jdb -help用法: jdb &lt;options&gt; &lt;class&gt; &lt;arguments&gt;其中, 选项包括: -help 输出此消息并退出 -sourcepath &lt;由 &quot;;&quot; 分隔的目录&gt; 要在其中查找源文件的目录 -attach &lt;address&gt; 使用标准连接器附加到指定地址处正在运行的 VM -listen &lt;address&gt; 等待正在运行的 VM 使用标准连接器在指定地址处连接 -listenany 等待正在运行的 VM 使用标准连接器在任何可用地址处连接 -launch 立即启动 VM 而不是等待 &apos;run&apos; 命令 -listconnectors 列出此 VM 中的可用连接器 -connect &lt;connector-name&gt;:&lt;name1&gt;=&lt;value1&gt;,... 使用所列参数值通过指定的连接器连接到目标 VM -dbgtrace [flags] 输出信息供调试jdb -tclient 在 HotSpot(TM) 客户机编译器中运行应用程序 -tserver 在 HotSpot(TM) 服务器编译器中运行应用程序转发到被调试进程的选项: -v -verbose[:class|gc|jni] 启用详细模式 -D&lt;name&gt;=&lt;value&gt; 设置系统属性 -classpath &lt;由 &quot;;&quot; 分隔的目录&gt; 列出要在其中查找类的目录 -X&lt;option&gt; 非标准目标 VM 选项&lt;class&gt; 是要开始调试的类的名称&lt;arguments&gt; 是传递到 &lt;class&gt; 的 main() 方法的参数要获得命令的帮助, 请在jdb提示下键入 &apos;help&apos; 上面是启动JDB的语法说明。 现假设运行程序的工程目录如下： 1234567JDBTest |----bin(编译生成的class文件) | |----*.class |----src(源文件) | |----*.java |----lib(依赖的第三方jar) | |----*.jar 开始启动JDB调试： Y:\project\JavaProject\JDBTest&gt;jdb -classpath ./bin/;./lib/* -sourcepath ./src/ test.JDBTest 注意，如果有多个文件，windows下使用 &quot;;&quot; 分隔每个文件或目录，Linux下使用 &quot;:&quot; 分隔每个文件或目录 -classpath 指定了类路径，-sourcepath 指定了源文件的路径 回车，出现如下信息： 123Y:\project\JavaProject\JDBTest&gt;jdb -classpath ./bin/;./lib/* -sourcepath ./src/ test.JDBTest正在初始化jdb...&gt; 此时，JDB调试器等待用户的输入，输入help，出现如下信息： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100Y:\project\JavaProject\JDBTest&gt;jdb -classpath ./bin/;./lib/* -sourcepath ./src/ test.JDBTest正在初始化jdb...&gt; help** 命令列表 **connectors -- 列出此 VM 中可用的连接器和传输run [class [args]] -- 开始执行应用程序的主类threads [threadgroup] -- 列出线程thread &lt;thread id&gt; -- 设置默认线程suspend [thread id(s)] -- 挂起线程 (默认值: all)resume [thread id(s)] -- 恢复线程 (默认值: all)where [&lt;thread id&gt; | all] -- 转储线程的堆栈wherei [&lt;thread id&gt; | all]-- 转储线程的堆栈, 以及 pc 信息up [n frames] -- 上移线程的堆栈down [n frames] -- 下移线程的堆栈kill &lt;thread id&gt; &lt;expr&gt; -- 终止具有给定的异常错误对象的线程interrupt &lt;thread id&gt; -- 中断线程print &lt;expr&gt; -- 输出表达式的值dump &lt;expr&gt; -- 输出所有对象信息eval &lt;expr&gt; -- 对表达式求值 (与 print 相同)set &lt;lvalue&gt; = &lt;expr&gt; -- 向字段/变量/数组元素分配新值locals -- 输出当前堆栈帧中的所有本地变量classes -- 列出当前已知的类class &lt;class id&gt; -- 显示已命名类的详细资料methods &lt;class id&gt; -- 列出类的方法fields &lt;class id&gt; -- 列出类的字段threadgroups -- 列出线程组threadgroup &lt;name&gt; -- 设置当前线程组stop in &lt;class id&gt;.&lt;method&gt;[(argument_type,...)] -- 在方法中设置断点stop at &lt;class id&gt;:&lt;line&gt; -- 在行中设置断点clear &lt;class id&gt;.&lt;method&gt;[(argument_type,...)] -- 清除方法中的断点clear &lt;class id&gt;:&lt;line&gt; -- 清除行中的断点clear -- 列出断点catch [uncaught|caught|all] &lt;class id&gt;|&lt;class pattern&gt; -- 出现指定的异常错误时中断ignore [uncaught|caught|all] &lt;class id&gt;|&lt;class pattern&gt; -- 对于指定的异常错误, 取消 &apos;catch&apos;watch [access|all] &lt;class id&gt;.&lt;field name&gt; -- 监视对字段的访问/修改unwatch [access|all] &lt;class id&gt;.&lt;field name&gt; -- 停止监视对字段的访问/修改trace [go] methods [thread] -- 跟踪方法进入和退出。 -- 除非指定 &apos;go&apos;, 否则挂起所有线程trace [go] method exit | exits [thread] -- 跟踪当前方法的退出, 或者所有方法的退出 -- 除非指定 &apos;go&apos;, 否则挂起所有线程untrace [methods] -- 停止跟踪方法进入和/或退出step -- 执行当前行step up -- 一直执行, 直到当前方法返回到其调用方stepi -- 执行当前指令next -- 步进一行 (步过调用)cont -- 从断点处继续执行list [line number|method] -- 输出源代码use (或 sourcepath) [source file path] -- 显示或更改源路径exclude [&lt;class pattern&gt;, ... | &quot;none&quot;] -- 对于指定的类, 不报告步骤或方法事件classpath -- 从目标 VM 输出类路径信息monitor &lt;command&gt; -- 每次程序停止时执行命令monitor -- 列出监视器unmonitor &lt;monitor#&gt; -- 删除监视器read &lt;filename&gt; -- 读取并执行命令文件lock &lt;expr&gt; -- 输出对象的锁信息threadlocks [thread id] -- 输出线程的锁信息pop -- 通过当前帧出栈, 且包含当前帧reenter -- 与 pop 相同, 但重新进入当前帧redefine &lt;class id&gt; &lt;class file name&gt; -- 重新定义类的代码disablegc &lt;expr&gt; -- 禁止对象的垃圾收集enablegc &lt;expr&gt; -- 允许对象的垃圾收集!! -- 重复执行最后一个命令&lt;n&gt; &lt;command&gt; -- 将命令重复执行 n 次# &lt;command&gt; -- 放弃 (无操作)help (或 ?) -- 列出命令version -- 输出版本信息exit (或 quit) -- 退出调试器&lt;class id&gt;: 带有程序包限定符的完整类名&lt;class pattern&gt;: 带有前导或尾随通配符 (&apos;*&apos;) 的类名&lt;thread id&gt;: &apos;threads&apos; 命令中报告的线程编号&lt;expr&gt;: Java(TM) 编程语言表达式。支持大多数常见语法。可以将启动命令置于 &quot;jdb.ini&quot; 或 &quot;.jdbrc&quot; 中位于 user.home 或 user.dir 中&gt; 上面的帮助信息说明了如何进行JDB调试，解释一下其中的几个： step: – 执行当前行 相当于Eclipse中的F5 step up: – 一直执行, 直到当前方法返回到其调用方 相当于Eclipse中的F7 next: – 步进一行 (步过调用) 相当于Eclipse中的F6 cont: – 从断点处继续执行 相当于Eclipse中的F8 此时，继续输入： 1234567891011121314&gt; stop at test.JDBTest:7正在延迟断点test.JDBTest:7。将在加载类后设置。&gt; run运行test.JDBTest设置未捕获的java.lang.Throwable设置延迟的未捕获的java.lang.Throwable&gt;VM 已启动: 设置延迟的断点test.JDBTest:7断点命中: &quot;线程=main&quot;, test.JDBTest.main(), 行=7 bci=07 JDBTest jdbTest = new JDBTest();main[1] stop at test.JDBTest:7 表示在这个类文件的第7行处打一个断点 接着，输入run，就开始进入调试步骤了。现在可以输入上面帮助中的语法来了解当前程序的执行情况了。一试便知 注意, 若想要在调试时能够正常输出调试信息如变量值等等，需要在编译java文件时指定 -g 参数，否则无法获得其运行时的调试信息 另外，使用list可以打印当前断点处的源代码，如果没有在启动JDB时指定源代码路径 -sourcepath ./src/ ，那么会提示没有源代码信息，无法输出。此时可以使用命令 use ./src/ 来指定源代码路径，再使用list命令时可以正常打印了。 以上就是使用JDB调试本地程序的方法，具体的使用可根据实际情况参照语法说明去执行。 使用JDB进行远程调试如果程序不是运行在本机，而是在其他机器或者现场的时候，可以使用java提供的远程调试功能。 假设程序现运行在主机 192.168.101.72 这台机器上，该机器为linux环境，且只可以通过ssh作为一个普通用户连接。我们想要在自己的机器上调试运行在192.168.101.72这台机器上的程序。 启动要调试的程序在192.168.101.72这台主机上以下面的方式启动java程序：还是以JDBTest为例 java -Xdebug -Xrunjdwp:transport=dt_socket,server=y,address=8899 -classpath ./bin/:./lib/* test.JDBTest 此时，命令行输出 Listening for transport dt_socket at address: 8899 并处于等待状态 下面是几个参数的解释： -Xdebug 启用调试特性。 -Xrunjdwp: 在目标 VM 中加载 JDWP 实现。它通过传输和 JDWP 协议与独立的调试器应用程序通信。下面介绍一些特定的子选项。从 Java V5 开始，您可以使用 -agentlib:jdwp 选项，而不是 -Xdebug 和 -Xrunjdwp。但如果连接到 V5 以前的 VM，只能选择 -Xdebug 和 -Xrunjdwp。下面简单描述 -Xrunjdwp 子选项。 transport 这里通常使用套接字传输。但是在 Windows 平台上也可以使用共享内存传输。 server 如果值为 y，目标应用程序监听将要连接的调试器应用程序。否则，它将连接到特定地址上的调试器应用程序。 address 这是连接的传输地址。如果服务器为 n，将尝试连接到该地址上的调试器应用程序。否则，将在这个端口监听连接。 suspend 如果值为 y，目标 VM 将暂停，直到调试器应用程序进行连接。 本机连接远程程序并启动调试在本机上命令行下输入： jdb -connect com.sun.jdi.SocketAttach:hostname=192.168.101.72,port=8899 然后就进入了调试界面，你可以像调试本机程序那样使用JDB的一些命令来调试了。当退出调试程序时，远程主机上的程序也就退出了。 使用Eclipse进行远程调试可以使用Eclipse进行远程调试，就上上面使用JDB一样。 启动要调试的程序与JDB远程调试一样，启动远程主机上的程序： java -Xdebug -Xrunjdwp:transport=dt_socket,server=y,address=8899 -classpath ./bin/:./lib/* test.JDBTest 本机启动Eclipse进行调试首先要右键工程-&gt;java compiler 上图中的几个选项最好全部打勾，否则调试时会出现无法打断点或者获取不到行号等问题(关于这几个选项的含义在之前的总结中有提到) 接着，右键工程-&gt;Debug As-&gt;Run Configurations, 在出现的对话框中选择Remote Java Application, 右键-&gt;New, 出现如下界面： 在Connect页中，选择对应的java 工程，Connection Type选择 Socket Attach，然后填写远程主机的ip和端口，这里应该填写192.168.101.72和8899。在Source页中可以添加源代码，如用到的第三方jar的源代码或者引用的工程，调试时就可以进入到这部分代码查看。在Common页可以设置编码的配置。 接下来点击Debug按钮，就可以愉快的在本机调试远程程序了，就像调试本地程序那样。只不过可能有一点一点慢，不过比打Log的方式要好很多了。 参考使用 Eclipse 远程调试 Java 应用程序 JDB的简单使用 深入 Java 调试体系: 第 1 部分，JPDA 体系概览]]></content>
      <categories>
        <category>编程</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>调试</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[java中的路径]]></title>
    <url>%2F2016%2F12%2F04%2Fjava%E4%B8%AD%E7%9A%84%E8%B7%AF%E5%BE%84%2F</url>
    <content type="text"><![CDATA[每次写java代码的时候，免不了需要加载一些外部资源，比如配置文件等等。每当需要读取这些文件时，都是去网上谷歌，写过就忘。于是今天来总结一些java中有关路径的一些用法。 绝对路径无论是在linux还是windows中，路径都分为绝对路径和相对路径两种。 绝对路径就是系统中唯一能够定位资源的某个URI，即完整的描述文件的路径就是绝对路径。比如： linux中的绝对路径：/home/yukai/test.txt windows中的绝对路径：E:\yukai\test.txt 绝对路径都是以根目录起始的。 相对路径相对路径即目标文件相对与某个基准目录的路径。比如: 存在文件： A: /home/yukai/test.txt B: /home/yukai/test1.txt C: /home/yukai/test/test.txt 那么： 若基准目录为A, B的路径表示为”test1.txt” 若基准目录为B, C的路径表示为”test/test.txt” 若基准目录为C, B的路径表示为”../test1.txt” 另外，“./”表示当前目录，“../”表示上级目录 java io定位文件资源那么，我们在java中如何读取某个文件？上代码： 12345678910// 目录结构src | |--test | | | |--PathTest.java |resource | |--data.txt 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657public class PathTest &#123; public static String dataFilePath = "resource/data.txty"; public static String getUserDir() &#123; //打印运行程序的目录，即启动java程序的目录 String userDir = System.getProperty("user.dir"); System.out.println("运行java的工作目录 System.getProperty(\"user.dir\")： " + userDir); return userDir; &#125; public static void testDataPath1() &#123; String msg = "&gt;&gt; Path = System.getProperty(\"user.dir\") + \"resource/data.txt\""; String userDir = getUserDir(); //等同于 "resource/data.txt" String filePath = userDir + System.getProperty("file.separator") + dataFilePath; printFileContent(filePath ,msg); &#125; public static void testDataPath2() &#123; String msg = "Path = \"resource/data.txt\""; String filePath = dataFilePath; printFileContent(filePath, msg); &#125; public static void testDataPath3() &#123; String msg = "Path = \"./resource/data.txt\""; String filePath = "./resource/data.txt"; printFileContent(filePath, msg); &#125; private static void printFileContent(String filePath, String msg) &#123; System.out.println("****************************"); System.out.println(msg); File file = new File(filePath); InputStream stream; try &#123; stream = new FileInputStream(file); BufferedReader reader = new BufferedReader(new InputStreamReader(stream)); String line = null; while ((line = reader.readLine()) != null) &#123; System.out.println(line); &#125; &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; finally &#123; System.out.println("****************************"); &#125; &#125; public static void main(String[] args) &#123; testDataPath1(); testDataPath2(); testDataPath3(); &#125;&#125; 其中testDataPath2、testDataPath1、testDataPath3这三个方法的效果是一样的。 System.getProperty(&quot;user.dir&quot;)这个方法获取了当前的工作目录，也就是启动jvm的目录。例如： ps: 更多关于System.getProperty()的介绍：System Properties 你的java程序位于：/home/yukai/code/test.jar 若你在目录/home/yukai下使用命令 java -cp code/test.jar test.PathTest 启动java程序时，目录/home/yukai就是你的工作目录。 在testDataPath2当中，直接使用”resource/data.txty”来作为文件读取路径时，java会默认为基准目录为当前的工作目录，”resource/data.txty”此时就是相对于这个基准目录的路径。也就是说，java会把工作目录与”resource/data.txty”拼接起来，作为一个绝对路径去读取文件，也就是testDataPath1中的例子。 有Eclipse中启动你的java工程的目录就是工程根目录，工程根目录也就是工作目录，如果你读取文件的方式类似于testDataPath2的话，他会在工程根目录下找你的文件。有时候我们会遇到，在Eclipse中读取文件没有问题，但是打成jar包之后运行(像上面运行jar包的例子)就会报找不到文件的错误。那么此时就要检查你的当前工作目录下(/home/yukai)是否有这些文件的存在了。 File.getPath &amp; File.getAbsolutePath &amp; File.getCanonicalPath12345678910public static void testGetPath() &#123; File file = new File("./resource/data.txt"); System.out.println("File.getPath(): " + file.getPath()); System.out.println("File.getAbsolutePath(): "+ file.getAbsolutePath()); try &#123; System.out.println("File.getCanonicalPath(): " + file.getCanonicalPath()); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125;&#125; 上述代码运行结果： 123File.getPath(): ./resource/data.txtFile.getAbsolutePath(): /home/yukai/workspace/test/./resource/data.txtFile.getCanonicalPath(): /home/yukai/workspace/test/resource/data.txt 摘抄一段stackoverflow上的答案: 12345getPath() gets the path string that the File object was constructed with, and it may be relative current directory.getAbsolutePath() gets the path string after resolving it against the current directory if it&apos;s relative, resulting in a fully qualified path.getCanonicalPath() gets the path string after resolving any relative path against current directory, and removes any relative pathing (. and ..), and any file system links to return a path which the file system considers the canonical means to reference the file system object to which it points. 读取classpath下的文件1234567public static void getClassPath() &#123; System.out.println("PathTest.class.getResource(\"/\"): " + PathTest.class.getResource("/")); System.out.println("PathTest.class.getResource(\"\"): " + PathTest.class.getResource("")); System.out.println("PathTest.class.getClassLoader().getResource(\"/\"): " + PathTest.class.getClassLoader().getResource("/")); System.out.println("PathTest.class.getClassLoader().getResource(\"\"): " + PathTest.class.getClassLoader().getResource(""));&#125; 运行结果(Eclipse)： 12345678//以“/”开头，表示相对于package根目录PathTest.class.getResource(&quot;/&quot;): file:/home/yukai/workspace/test/bin///不以“/”开头，表示相对于class文件所在目录PathTest.class.getResource(&quot;&quot;): file:/home/yukai/workspace/test/bin/test///PathTest.class.getClassLoader().getResource(&quot;/&quot;): null//getClassLoader().getResource(&quot;&quot;)不以“/”开头，相对于package根目录PathTest.class.getClassLoader().getResource(&quot;&quot;): file:/home/yukai/workspace/test/bin/ 获取jar包路径java开发中常常需要取得程序生成的jar包所在的路径，比如生成一些log文件的时候，需要把该程序生成的log放到jar包的的同级目录下。此时，我们需要知道jar包所在的位置，注意，不是启动jvm实例的位置。 12345678910111213141516URL url = Config.class.getProtectionDomain().getCodeSource().getLocation();String path = new URI(url.getProtocol(), url.getHost(), url.getPath(), url.getQuery(), null).getPath(); if (path != null) &#123; if (path.endsWith(&quot;/&quot;) || path.endsWith(&quot;\\&quot;)) &#123; path = path.substring(0, path.length() - 1); &#125; if (path.endsWith(&quot;.jar&quot;)) &#123; int index = path.lastIndexOf(&quot;/&quot;); if (index != -1) &#123; path = path.substring(0, index); &#125; defultLogPath = path + File.separator + &quot;log&quot;; &#125; else &#123; defultLogPath = path + File.separator + &quot;..&quot; + File.separator + &quot;log&quot; ; &#125;&#125; Path.javajdk1.7之后，新增了一个类File,位于java.nio.file下，该类提供了一些路径的操作。 具体的使用不一一介绍，用到时可查找oracle的官方手册，已经写的很详细了：Path Operations]]></content>
      <categories>
        <category>编程</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[java 中的int/byte转换]]></title>
    <url>%2F2016%2F11%2F24%2Fjava%E4%B8%AD%E7%9A%84int%5Cbyte%E4%BA%92%E8%BD%AC%2F</url>
    <content type="text"><![CDATA[前言好久没有动博客了，看了下，将近两个月了吧。最近的两个月里面变懒了，没有了记录的动力。。。最近好像也没啥收获，惭愧。之前电脑中病毒之后(cryptolcker)，还好没有神马重要的东西，索性把硬盘重新格式化一遍，重做了系统。保留一套windows（实在受不了win10的自动更新了…）,又装了一套opensuse的系统。希望可以坚持学点linux。 这段时间没有怎么看书，说一下读书情况。《重构》这本还是没有看完，读了大半。《深入理解jvm虚拟机》这本算是大致上浏览了一遍，发现确实是一本挺好的java书籍，日后还需多加翻阅理解。《大话设计模式》也是浏览了一遍，其中比较常见的模式有时候也可以用到，需要的时候再看吧。双十一买了一本《java并发编程实战》，看了大半，似懂非懂，但也是有收获的。不得不吐槽一下该书的翻译，实在是不敢恭维，但是想想自己的英语水平，目前还是忍了。。 必须要振作起精神来了，总觉得自己每天无所事事呢。接下来的计划…..还是把并发编程这块看完吧，虽然没有什么实战的机会，总比不看强。要多写总结了，不然看了跟不看差不多。异常、反射、动态代理、注解等等这些也要学习然后做一个记录。网络、io、并发这三块，并发还在看，也要做好记录，然后网络这部分把大学课本重读一遍，至于io不知道有什么好的书籍，放到最后规划学习把。 嗯，又想起来最近还写了一个自动打卡的程序，增加了短信通知的功能。总觉得有些不诚信的感觉呢，但是没有迟到早退过呀，好玩罢了。读了webmagic的core部分的源码，感觉理解起来轻松许多。记得大学那会看这个的时候还是一头雾水，结果现在两个小时就把代码搞清楚了（主要是代码量也不大拉）。嗯，说明自己还是在进步的麻，哈哈哈。下载了junit的源码都没有看过，有空研究把。 终于要进入正题了。这次的记录很短很简单，是关于java中int和byte之间的转换的。虽然简单，但是以前就是拿来即用，没有搞清楚其中的原理，在byte这块就很纠结（只能说基础比较差），今天来学习一下。 正文java中: byte: 1字节 int: 4字节 12int i = -123byte x = (byte)i; //-123 ps：([]代表几进制，()代表前面的内容重复几次) ps: -123[2] = 11111111(3)10000101 int 强转为 byte，直接截取低8位即10000101 java把byte当做有符号处理，故此时x=-123 1int j = (int)x; //-123 ps: byte强转为int，高24位补1(自动扩展) 此时，j[2]=11111111(3)11101010 即，j=-123 负数似乎没有问题… 12int i = 234;byte x = (byte)i; //-22 ps: 234[2] = 00000000(3)11101010 int 强转为 byte，直接截取低8位即11101010 java把byte当做有符号处理，故此时x=-22 1int j = (int)x; //-22 ps: byte强转为int，高24位补1（自动扩展） 此时，j[2]=11111111(3)11101010 即，j=-22 可见，byte单纯的强转为int是行不通的。(注意，示例中int强转为一个byte,如果int值超过255,发生数据丢失，正确的int转为4字节byte方法见下文) 123int i = 234;byte x = (byte)i; //-22int j = x &amp; 0xFF; //j=234 ps: x &amp; 0xFF = 00000000(3)11101010 即，j=234 可见0xFF的作用… http://yukai.space/2016/04/28/java%E4%B8%AD%E7%9A%84%E7%B1%BB%E5%9E%8B%E8%BD%AC%E6%8D%A2/ byte short char 他们三者在计算时，首先会转换为int类型,故下面几个表达式进行|运算时，是int类型之间的|运算，存在自动扩展(移位操作也会出现这种情况,即int转byte的时候),不进行&amp; 0xFF的运算，则有可能造成第一种情况的出现。 java字节序 java为大端字节序（bigendian）：高字节数据存放在低地址处，低字节数据存放在高地址处。 0x01020304 故b[0]=0x01,b[1]=0x02,b[2]=0x03,b[3]=0x04 12345678910111213141516//byte 数组与 int 的相互转换 public static int byteArrayToInt(byte[] b) &#123; return b[3] &amp; 0xFF | (b[2] &amp; 0xFF) &lt;&lt; 8 | (b[1] &amp; 0xFF) &lt;&lt; 16 | (b[0] &amp; 0xFF) &lt;&lt; 24; &#125; public static byte[] intToByteArray(int a) &#123; return new byte[] &#123; (byte) ((a &gt;&gt; 24) &amp; 0xFF), (byte) ((a &gt;&gt; 16) &amp; 0xFF), (byte) ((a &gt;&gt; 8) &amp; 0xFF), (byte) (a &amp; 0xFF) &#125;; &#125;]]></content>
      <categories>
        <category>编程</category>
      </categories>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[java泛型学习]]></title>
    <url>%2F2016%2F10%2F10%2Fjava%E6%B3%9B%E5%9E%8B%E5%AD%A6%E4%B9%A0%2F</url>
    <content type="text"><![CDATA[有一段时间没有更新博客了，过了国庆之后，好像变得更懒了~~前两天开发了一个用于记账的公众号，功能很简单，就是普通的增删查改…由于是个人开发者，无法进行公众号的认证，所以没什么高级的接口权限，只能搞的简陋一点了…下一步计划再丰富丰富，目前想到了这几个功能：配合有道或者金山词霸的Api进行中英互译（API怎么用，可不可以用目前还不清楚），配合微博的Api接口整点微博热门什么的，配合豆瓣的Api接口做一个电影或者书籍查询的功能等等….公众号的服务器代码目前还部署在自己的电脑上，用nat123做了一下公网ip的映射，接下来考虑是不是要换成云服务器更为妥当…. 公众号在这里： 目前，公众号已经开源：WechatSubscriptionNumber 好了，言归正传。今天学习了java的泛型知识，不总结一下老是觉得跟没学一样… 泛型的好处使用泛型的好处我觉得有两点：1：类型安全 2：减少类型强转 下面通过一个例子说明: 假设有一个Test类，通用的实现是: 123456789101112131415class Test &#123; private Object o; public Test(Object o) &#123; this.o = o; &#125; public Object getObject() &#123; return o; &#125; public void setObject(Object o) &#123; this.o = o; &#125;&#125; 我们可以这样使用它： 123456public static void main(String[] args) &#123; Test test = new Test(new Integer(1)); //编译时不报错 //运行时报 java.lang.ClassCastException: java.lang.Integer cannot be cast to java.lang.String String o = (String) test.getObject();&#125; 看一个使用泛型的例子： 123456789101112131415161718192021222324class Test&lt;T&gt; &#123; private T o; public Test(T o) &#123; this.o = o; &#125; public T getObject() &#123; return o; &#125; public void setObject(T o) &#123; this.o = o; &#125;&#125;public static void main(String[] args) &#123; Test1&lt;Integer&gt; test = new Test1&lt;Integer&gt;(new Integer(1)); //编译时报错，无法通过编译 //String o = test.getObject(); //正常运行 Integer o = test.getObject();&#125; 从上面的对比中能够看出两点： 1.使用泛型之后在编译时报错而非运行时，减少了出错的几率； 2.使用泛型之后编译器不再要求强转 定义泛型泛型的机制能够在定义类、接口、方法时把类型参数化，也就是类似于方法的形参一样，把类型当做参数使用。 泛型参数部分使用&lt;&gt;包裹起来，比如&lt;T&gt;，T声明了一种类型，习惯上，这个类型参数使用单个大写字母来表示，指示所定义的参数类型。有如下惯例： E：表示元素 T：表示类型 K：表示键 V：表示值 N：表示数字 定义泛型类上面的例子就是一个很好的演示 123456789101112131415class Test&lt;T&gt; &#123; private T o; public Test(T o) &#123; this.o = o; &#125; public T getObject() &#123; return o; &#125; public void setObject(T o) &#123; this.o = o; &#125;&#125; 使用泛型定义类之后，泛型参数 T 可以运用到该类中：可以声明成员变量类型、可以声明成员函数返回值类型、可以声明成员函数参数类型。 要注意：泛型参数T不能用于声明静态变量，同时也不能用于new一个对象比如：T o = new T(); 下面的类型擦除会说到原因。 定义泛型接口123interface Test&lt;T&gt; &#123; public T test(T t);&#125; 使用泛型定义接口之后，泛型参数 T 可以运用到该接口中：可以声明接口函数返回值类型、可以声明接口函数参数类型。 定义泛型方法可以单独给方法使用泛型，而不是泛化整个类： 123public static &lt;T&gt; T getT(T t)&#123; return t;&#125; 使用泛型定义方法后，泛型参数 T 可以声明该方法的返回值类型、可以声明该方法的参数类型。 要注意，定义方法所用的泛型参数需要在修饰符之后添加。 定义多个泛型参数以接口为例： 123456789interface Test&lt;T, S&gt; &#123; public T testT(T t); public S testS(S s);&#125;public static void main(String[] args) &#123; //编译时报错 //getT("s");&#125; 多个泛型参数在尖括号中使用逗号隔开。类的泛化与方法的泛化类似。 泛型参数的界限定义泛型参数界限有这样两种意义： 1.有时候我们希望限定这个泛型参数的类型为某个类的子类或者超类； 2.上面的例子中可以看到，我们定义了泛型参数，向方法中传入某种类型，这种类型是未知的，因此我们无法使用这种类型定义的变量，不能够调用它的方法。 123public static &lt;T extends Number&gt; Integer getT(T t) &#123; return new Integer(t.intValue());&#125; 上面例子中，&lt;T extends A&gt;表示T是A或A的子类，他限定了传入泛型方法参数的类型必须为A或A的子类，同时，在方法体中我们也可以使用t这个实参就像使用A的实例一样，调用Number具有的public方法。 除了&lt;T extends A&gt;限定T是A或A的子类外，还可以使用&lt;T super A&gt;这种方式来限定T是A或A的超类。 A可以是某个类或者接口。 除此以外，还可以为泛型参数限定多个限制范围，如&lt;T extends A &amp; B &amp; C&gt;，限定范围中最多只能有一个类(某个类只能有一个父类~~)，并且他必须是限定列表中的第一个。 12345678Class A &#123; // &#125;interface B &#123; // &#125;interface C &#123; // &#125;//正确class D &lt;T extends A &amp; B &amp; C&gt; &#123; // &#125;//编译时报错class D &lt;T extends A &amp; B &amp; C&gt; &#123; // &#125; 泛型的继承看一下jdk中List的泛型继承例子： 1public interface List&lt;E&gt; extends Collection&lt;E&gt;&#123;//...&#125; List&lt;String&gt; 就是 Collection&lt;String&gt; 的子类。 假如定义自己的接口： 1234interface MyList&lt;E,P&gt; extends List&lt;E&gt; &#123; void setPay(E e,P p); //...&#125; MyList&lt;String,String&gt;、MyList&lt;String,Integer&gt;、MyList&lt;String,Exception&gt;都是List&lt;String&gt;的子类。 使用泛型上面的例子中已经列举了一些使用泛化类或者泛化函数的例子，但是还有一些问题需要指出： 1.泛型参数只接受引用类型，不适用于基本类型 比如： 123456class Test&lt;T&gt; &#123;&#125;public static void main(String[] args) &#123; //无法通过编译，不接受int类型的泛化参数 //Test&lt;int&gt; test = new Test();&#125; 而我们使用泛化函数时： 12345public static void main(String[] args) &#123; getT(1);&#125;public static &lt;T&gt; void getT(T t) &#123;&#125; 是没有问题的，通过查看生成的字节码，发现getT(1)这个方法的字节码中1被自动装箱为Integer类型。 2.通配符的使用 考虑下面的情况： 123456789class Test&lt;T&gt; &#123;&#125;public static void getT(Test&lt;Number&gt; t) &#123;&#125;public static void main(String[] args) &#123; Test&lt;Double&gt; test = new Test(); //编译时报错 //getT(test);&#125; 报错的原因很好理解，虽然Double是Number的子类，但Test并不是Test的子类，故类型检查无法通过。这一点一定要明白。 那么如果我们确实想要传入一个Test类型的形参呢？可以使用通配符： 12345678class Test&lt;T&gt; &#123;&#125;public static void main(String[] args) &#123; Test&lt;Double&gt; test = new Test(); //正常运行 getT(test);&#125;public static void getT(Test&lt;? extends Number&gt; t) &#123;&#125; Test&lt;? extends Number&gt;扩展了形参的类型，可以是Test&lt;Double&gt;、Test&lt;Integer&gt;等，尖括号中的类型必须是Number或继承于Number。同样的，通配符也适用于super，如Test&lt;? super A&gt;。 如果类型参数中既没有extends 关键字，也没有super关键字，只有一个?，代表无限定通配符。 Test&lt;?&gt;与Test&lt;Object&gt;并不相同，无论T是什么类型，Test&lt;T&gt; 是 Test&lt;?&gt;的子类，但是，Test&lt;T&gt; 不是 Test&lt;Object&gt; 的子类，想想上面的例子。 通常在两种情况下会使用无限定通配符： 如果正在编写一个方法，可以使用Object类中提供的功能来实现 代码实现的功能与类型参数无关，比如List.clear()与List.size()方法，还有经常使用的Class&lt;?&gt;方法，其实现的功能都与类型参数无关。 一般情况下，通配符&lt;? extends Number&gt;只是出现在使用泛型的时候，而不是定义泛型的时候，就像上面的例子那样。而&lt;T extends Number&gt;这种形式出现在定义泛型的时候，而不是使用泛型的时候，不要搞混了。 结合泛型的继承和通配符的使用，理解一下泛型的类型系统，也就是泛型类的继承关系： 以下内容来自：Java深度历险（五）——Java泛型 引入泛型之后的类型系统增加了两个维度：一个是类型参数自身的继承体系结构，另外一个是泛型类或接口自身的继承体系结构。第一个指的是对于 List&lt;String&gt;和List&lt;Object&gt;这样的情况，类型参数String是继承自Object的。而第二种指的是 List接口继承自Collection接口。对于这个类型系统，有如下的一些规则： 相同类型参数的泛型类的关系取决于泛型类自身的继承体系结构。即List&lt;String&gt;是Collection&lt;String&gt; 的子类型，List&lt;String&gt;可以替换Collection&lt;String&gt;。这种情况也适用于带有上下界的类型声明。当泛型类的类型声明中使用了通配符的时候， 其子类型可以在两个维度上分别展开。如对Collection&lt;? extends Number&gt;来说，其子类型可以在Collection这个维度上展开，即List&lt;? extends Number&gt;和Set&lt;? extends Number&gt;等；也可以在Number这个层次上展开，即Collection&lt;Double&gt;和 Collection&lt;Integer&gt;等。如此循环下去，ArrayList&lt;Long&gt;和 HashSet&lt;Double&gt;等也都算是Collection&lt;? extends Number&gt;的子类型。如果泛型类中包含多个类型参数，则对于每个类型参数分别应用上面的规则。 关于通配符的理解可以参考Java 泛型 &lt;? super T&gt; 中 super 怎么 理解？与 extends 有何不同？ 类型擦除类型擦除发生在编译阶段，对于运行期的JVM来说，List&lt;int&gt;与List&lt;String&gt;就是同一个类，因为在编译结束之后，生成的字节码文件中，他们都是List类型。 1.java编译器会在编译前进行类型检查 java编译器承担了所有泛型的类型安全检查工作。 2.类型擦除后保留的原始类型 原始类型（raw type）就是擦除去了泛型信息，最后在字节码中的类型变量的真正类型。无论何时定义一个泛型类型，相应的原始类型都会被自动地提供。类型变量被擦除（crased），并使用其限定类型（无限定的变量用Object）替换。 3.自动类型转换 因为类型擦除的问题，所以所有的泛型类型变量最后都会被替换为原始类型。这样就引起了一个问题，既然都被替换为原始类型，那么为什么我们在获取的时候，不需要进行强制类型转换呢？ 比如： 1234567public class Test &#123; public static void main(String[] args) &#123; ArrayList&lt;Date&gt; list=new ArrayList&lt;Date&gt;(); list.add(new Date()); Date myDate=list.get(0); &#125;&#125; Date myDate=list.get(0);这里我们并没有对其返回值进行强转就可以直接获取Date类型的返回值。原因在于在字节码当中，有checkcast这么一个操作帮助我们进行了强转，这是java自动进行的。 更多的关于类型擦除的知识，参考 java泛型（二）、泛型的内部原理：类型擦除以及类型擦除带来的问题 实践最近在重构公众号服务器的过程中，用到了泛型编程的知识。 12345public interface BaseServiceContext&lt;T extends ReqBaseMessage, R&gt; &#123; public void selectService(T reqMeg); public R executeRequest();&#125; 上面是一个选择service的上下文接口，接收到用户请求后通过这个接口选择对应的service并且执行service。这个接口相当于一个工厂和策略模式的结合体。下面是这个接口的一种实现： 12345678910111213//请求为文本类型，返回string类型的处理结果public class TextServiceContext implements BaseServiceContext&lt;ReqTextMessage,String&gt; &#123; @Override public void selectService(ReqTextMessage reqMeg) &#123; //..... &#125; @Override public String executeRequest() &#123; //..... &#125;&#125; 可以看到，BaseServiceContext限定了selectService方法的参数类型和executeRequest方法的返回值类型，使其能够灵活的支持各种类型的参数和返回值。 看一下在没有学习泛型之前，这个接口是怎么实现的： 1234567891011121314151617181920public interface BaseServiceContext &#123; public void selectService(ReqBaseMessage reqMeg); public Object executeRequest();&#125;public class TextServiceContext implements BaseServiceContext &#123; @Override public void selectService(ReqBaseMessage reqMeg) &#123; //根据业务逻辑对reqMeg进行强转，需要程序员自己判断 //很有可能强转失败 &#125; @Override public Object executeRequest() &#123; //返回类型为object，在调用方法的外部强转为需要的类型 //很有可能强转失败 &#125;&#125; 可以看到没有使用泛型接口的情况下，类型不安全且增大了强转失败的风险。同时也需要程序员根据业务逻辑去判断该强转成什么类型。使用泛型接口之后就没有了这些问题，只需要在使用接口时声明好他的泛型参数就o了。 上面只是我在开发过程中体会到泛型的一个好处，类似的例子还有很多。 注意事项参考java 泛型编程（一） 泛型：工作原理及其重要性 Java深度历险（五）——Java泛型 java泛型详解 Java 泛型 &lt;? super T&gt; 中 super 怎么 理解？与 extends 有何不同？]]></content>
      <categories>
        <category>编程</category>
      </categories>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ssl使用总结]]></title>
    <url>%2F2016%2F09%2F25%2Fssl%E6%80%BB%E7%BB%93%2F</url>
    <content type="text"><![CDATA[这次维护的web服务器要求使用Https双向认证，了解了一下如何在客户端和服务器之间进行ssl的配置，在此记录。另外，这篇日志主要记录如何使用，并不深入底层原理。 简单认识ssl和证书在理解这部分内容之前，建议先看看前面对的一篇总结：关于加密的一点总结 SSL(Secure Sockets Layer 安全套接层),及其继任者传输层安全（Transport Layer Security，TLS）是为网络通信提供安全及数据完整性的一种安全协议。TLS与SSL在传输层对网络连接进行加密。 SSL协议提供的服务主要有： 1、认证用户和服务器，确保数据发送到正确的客户机和服务器； 2、加密数据以防止数据中途被窃取； 3、维护数据的完整性，确保数据在传输过程中不被改变。 其实，ssl就是一种协议。我们知道Http协议是明文传输的，安全性不高。Https就是在Http基础之上加一层ssl协议，来达到加密通信的目的。具体的ssl握手过程，可以参考百度百科 附上一张图方便理解： 图片来自网络 可以看到ssl握手过程中服务器向客户端发送了自己的证书。这个证书是加密过程的重要内容。在前面的关于加密的一点总结这篇博客中，在关于数字证书的一节，我们知道了数字证书可以证明服务器的身份，服务器证书中包含了服务器的公钥，用于之后的通信。 那么，简单了解下证书的工作原理。 首先看一下证书中有哪些内容： 上面是我从谷chorme浏览器中截取的支付宝所使用证书的信息截图。 可以看到，里面有颁发者和使用者。颁发者就是颁发此证书的CA(证书颁发机构),使用者就是与我们通信的服务器，也就是该证书的持有者。证书中还包含了我们上面提到的公钥。 我们知道，证书能够证明服务器的身份，那么他是如何证明的呢？我们以浏览器为例： 首先，浏览器(客户端)接收到服务器发来的证书A之后，会去验证这个证书A是否被篡改或者是伪造的。浏览器首先会去操作系统中内置根证书库中搜索A的颁发者的证书。关于这一点要解释一下，数字证书的颁发机构也有自己的证书，这个证书就是根证书，这个根证书在我的系统刚安装好时，就被微软等公司默认安装在操作系统当中了。 如果在操作系统中找到了服务器证书中的颁发者的证书Root，那么继续下一步，否则，就知道这个服务器证书的颁发者是个不受信任的CA发布的，此时，浏览器会给出警告。若我们选择相信这个CA并继续，则继续下一步。 接下来，浏览器从Root中得到Root的公钥，然后用该公钥对A中的指纹算法和指纹进行解密。注意，为了保证安全，在证书的发布机构发布证书时，证书的指纹和指纹算法，都会加密后再和证书放到一起发布，以防有人修改指纹后伪造相应的数字证书。 那么什么是指纹算法和指纹呢？这个是用来保证证书的完整性的，也就是说确保证书没有被修改过。 其原理就是在发布证书时，发布者根据指纹算法(一个hash算法)计算整个证书的hash值(指纹)并和证书放在一起，使用者在打开证书时，自己也根据指纹算法计算一下证书的hash值(指纹)，如果和刚开始的值对得上，就说明证书没有被修改过，因为证书的内容被修改后，根据证书的内容计算的出的hash值(指纹)是会变化的。 此时就可以判断该证书是否是仿冒或者经过伪造篡改的。如没有，则证明这个服务器是可信任的。接下来就可以使用该服务器提供的公钥来进行通信了。 通过上面的分析我们知道了，ssl协议中，首先通过证书来证明服务器的身份，然后取出证书中的公钥，接下来就可以按照关于加密的一点总结这篇博客中说到的通信方式通信了。这大概上就是ssl的原理，当然实际中ssl的细节还是要复杂很多。 了解了ssl的基本原理，对我们实现服务器的https通信有很大的帮助。 Https 单向认证单向认证就是服务器必须向客户端发送自己的证书来证明自己的身份，然后进行加密通信。现在服务器的基础框架是springboot，演示如何配置服务器和客户端： 服务器： 打开springboot的配置文件application.properties: server.ssl.key-store=server.keystore server.ssl.key-store-password=123456 server.ssl.keyStoreType=JKS server.ssl.keyAlias:server 先解释一下上面几个配置： .keystore: keystore文件中存储了密钥和证书。密钥包括私钥和公钥，而证书中只包含公钥。这个证书就是我们上面所说的证书。注意：密钥和证书是一一对应的。 password: 生成keystore文件时所填的密码。 keyStoreType: keystore类型。 keyAlias: 生成密钥的别名。 keysotre文件是怎么生成的呢？使用jdk自带的工具：keytool。生成keystore文件的命令如下： keytool -genkey -alias server -keyalg RSA -validity 365 -keystore server.keystore 其中：-alias 指定生成密钥的别名，-keystore 指定生成的keystore文件的位置和名称。其他的参数的含义可以通过keytool -help来查找。 一个keystore文件中可以存储多个证书和证书对应的密钥，这些证书和其对应的密钥通过唯一的别名alias来指定，也就是说，通过alias可以导出证书。但是要注意，无法通过keytool导出私钥。 看一下如何从keystore文件中导出证书： keytool -export -alias server -keystore server.keystore -file serverCA.crt -alias指定了要导出的证书文件，-file 指定了要导出的证书文件的位置和名称。 了解了上面的几个配置，再结合之前对ssl原理的总结，不难知道： 我们指定的别名(server.ssl.keyAlias:server)之后,服务器通过该别名从keystore文件中获得对应的证书，并将其发送给客户端，同时使用keystore中alias对应的私钥(keytool虽然导不出私钥，但可以通过代码等方式获得)可以对与客户端通信的内容进行加密和解密。这便是keystore文件的作用：存储证书和私钥。 服务器端的配置完成了。现在有一个问题，虽然服务器可以发送证书到客户端了，但是客户端并不会信任我们这个证书。如果这个时候通过浏览器以https的方式访问服务器，浏览器会提醒你，此连接不受信任。那是因为虽然服务器将证书发送到了浏览器(客户端)，但是浏览器并不认为这个证书能够证明服务器的身份。那为什么https访问支付宝等网站没有报这个警告呢？想想上面的内容，浏览器或操作系统内置了颁发给支付宝证书的机构的根证书，通过这个根证书的公钥对支付宝发来的证书进行解密可以证明这个证书确实是由支付宝发过来的，从而证明了服务器的身份。 虽然浏览器并不能验证我们的证书，我们可以手动的把证书添加到浏览器的信任列表中。这个证书就是我们上面通过keytool导出的证书，将这个证书手动添加到浏览器信任列表里面，再次访问服务器就不会有警告啦。(具体的添加方式不再赘述)(从这点上也可以看出自签名证书的不安全性，有可能被假冒和伪造) so,通过上面的方式我们已经将ssl单向验证配置好了。那么，如果客户端是自己用java写的呢？下面举一个例子，使用HttpsURLConnection实现： 首先生成客户端的信任证书库，用来存放客户端所信任的证书： keytool -keystore truststore.jks -alias client -import -trustcacerts -file serverCA.crt -file 指定要信任的证书，此例中应该是我们上面导出的证书serverCA.crt -keystore 指定要生成的信任库路径和名称。 然后生成我们自己的信任证书管理器： 参考了网上的代码： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465public class MyX509TrustManager implements X509TrustManager &#123; /* * The default X509TrustManager returned by SunX509. We'll delegate * decisions to it, and fall back to the logic in this class if the default * X509TrustManager doesn't trust it. */ X509TrustManager sunJSSEX509TrustManager; public MyX509TrustManager() throws Exception &#123; // create a "default" JSSE X509TrustManager. KeyStore ks = KeyStore.getInstance("JKS"); //注意 src/clientTrustCA.jks就是上面生成的信任证书库 ks.load(new FileInputStream("src/clientTrustCA.jks"), "123456".toCharArray()); TrustManagerFactory tmf = TrustManagerFactory.getInstance("SunX509", "SunJSSE"); tmf.init(ks); TrustManager tms[] = tmf.getTrustManagers(); /* * Iterate over the returned trustmanagers, look for an instance of * X509TrustManager. If found, use that as our "default" trust manager. */ for (int i = 0; i &lt; tms.length; i++) &#123; if (tms[i] instanceof X509TrustManager) &#123; sunJSSEX509TrustManager = (X509TrustManager) tms[i]; return; &#125; &#125; /* * Find some other way to initialize, or else we have to fail the * constructor. */ throw new Exception("Couldn't initialize"); &#125; /* * Delegate to the default trust manager. */ public void checkClientTrusted(X509Certificate[] chain, String authType) throws CertificateException &#123; try &#123; sunJSSEX509TrustManager.checkClientTrusted(chain, authType); &#125; catch (CertificateException excep) &#123; // do any special handling here, or rethrow exception. &#125; &#125; /* * Delegate to the default trust manager. */ public void checkServerTrusted(X509Certificate[] chain, String authType) throws CertificateException &#123; try &#123; sunJSSEX509TrustManager.checkServerTrusted(chain, authType); &#125; catch (CertificateException excep) &#123; /* * Possibly pop up a dialog box asking whether to trust the cert * chain. */ &#125; &#125; /* * Merely pass this through. */ public X509Certificate[] getAcceptedIssuers() &#123; return sunJSSEX509TrustManager.getAcceptedIssuers(); &#125;&#125; 接着使用这个管理器： 1234567891011TrustManager[] tm = &#123; new MyX509TrustManager() &#125;;SSLContext sslContext = SSLContext.getInstance("SSL", "SunJSSE");sslContext.init(null, tm, new java.security.SecureRandom());// 从上述SSLContext对象中得到SSLSocketFactory对象SSLSocketFactory ssf = sslContext.getSocketFactory();// 创建URL对象URL myURL = new URL(url);// 创建HttpsURLConnection对象，并设置其SSLSocketFactory对象HttpsURLConnection httpsConn = (HttpsURLConnection) myURL.openConnection();httpsConn.setSSLSocketFactory(ssf); 接下来就可以使用这个HttpsURLConnection来访问服务器啦。 Https双向认证所谓的Https双向认证就是不仅仅客户端要验证浏览器的身份，浏览器也要向服务器证明自己的身份，也就是第一幅图片中的5。 理解了单向认证，双向认证实现起来也就不难了。 首先像我们之前一样使用keytool生成keystore文件client.keystore，这个文件是为客户端使用准备的。 然后通过client.keystore导出证书client.crt。 接着生成信任库文件serverTrust.jks,将client.crt导入其中。 在单向认证中我们给出了客户端单向认证时的java代码，用来下面给出双向认证的代码： 生成读取keystore的类： 123456789101112131415161718192021public class MyKeyManager&#123; // 相关的 jks 文件及其密码定义 private final static String CERT_STORE="src/client.keystore"; private final static String CERT_STORE_PASSWORD="123456"; public static KeyManager[] getKeyManagers() throws Exception&#123; // 载入 jks 文件 FileInputStream f_certStore=new FileInputStream(CERT_STORE); KeyStore ks=KeyStore.getInstance("jks"); ks.load(f_certStore, CERT_STORE_PASSWORD.toCharArray()); f_certStore.close(); // 创建并初始化证书库工厂 String alg=KeyManagerFactory.getDefaultAlgorithm(); KeyManagerFactory kmFact=KeyManagerFactory.getInstance(alg); kmFact.init(ks, CERT_STORE_PASSWORD.toCharArray()); KeyManager[] kms=kmFact.getKeyManagers(); return kms; &#125;&#125; 像上面单向认证中那样使用它： 123456789101112TrustManager[] tm = &#123; new MyX509TrustManager() &#125;;KeyManager[] km = MyKeyManager.getKeyManagers();SSLContext sslContext = SSLContext.getInstance("SSL", "SunJSSE");sslContext.init(km, tm, new java.security.SecureRandom());// 从上述SSLContext对象中得到SSLSocketFactory对象SSLSocketFactory ssf = sslContext.getSocketFactory();// 创建URL对象URL myURL = new URL(url);// 创建HttpsURLConnection对象，并设置其SSLSocketFactory对象HttpsURLConnection httpsConn = (HttpsURLConnection) myURL.openConnection();httpsConn.setSSLSocketFactory(ssf); 然后使用HttpsURLConnection就可以使用了。但是此时服务器端还需要配置，因为客户端仅仅是将自己的证书发过去了，服务器应该如何信任它呢？ 打开springboot的配置文件application.properties添加以下配置: #Whether client authentication is wanted (“want”) or needed (“need”). Requires a trust store. server.ssl.client-auth=need server.ssl.trust-store=serverTrust.jks server.ssl.trust-store-password=123456 其中，serverTrust.jks就是刚刚生成的服务器端信任库。 以上步骤全部做完，服务器和客户端就可以愉快的使用Https进行双向认证通信了。 关于证书的一些格式在使用keytool和openssl的时候，会发现有好多种格式让人头晕眼花。不妨参考这篇文章：那些证书相关的玩意儿(SSL,X.509,PEM,DER,CRT,CER,KEY,CSR,P12等) 我现在也不是理解的十分清楚，故不再赘述。 总结感觉这篇博客没有把自己想要总结的内容全部记录下来，但是现在也不想再写了。服务器实际测试的时候是使用curl这样一个命令行浏览器进行的，使用curl作为客户端进行双向认证的时候也遇到了不少问题，总结了一份配置的readme，放在github上面，以作记录。readme中的配置方法可能还有一些瑕疵，有些格式转换可能会有冗余，但是整个配置是没有问题的，经过了自己的验证。证书这一块内容感觉还不是理解的特别透彻，尤其是ssl协议的交互和证书格式的一些问题，留作以后学习吧！真的不想看了… 参考数字证书原理:这篇一定要看，总结的很好！ 浏览器和SSL证书通讯过程 Java安全通信：HTTPS与SSL Java 安全套接字编程以及 keytool 使用最佳实践 openssl生成SSL证书的流程 如何添加自签名SSL证书 自签名SSL证书存风险 keystore提取私钥和证书(重要×××)]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>加密</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[记录工作遇到的坑]]></title>
    <url>%2F2016%2F09%2F24%2F%E8%AE%B0%E5%BD%95%E8%BF%99%E5%91%A8%E5%B7%A5%E4%BD%9C%E9%81%87%E5%88%B0%E7%9A%84%E5%9D%91%2F</url>
    <content type="text"><![CDATA[昨天晚上12.30才进的家门，回来之后还远程合了个代码打了个包，发布restAPI新版本之用。这一周的主要工作就是在做一个web服务器，是一个集群的中间件。因为着急发布新版本，所以昨晚加班到12点多… 主要实现了几个接口，实现了ssl双向验证功能。其实ssl双向验证的功能主要是了解ssl原理之后如何配置的问题。期间还学习了session和cookie的原理。ssl与cookie、session单开一篇进行总结。这篇日志记录一下这周工作中遇到的一些坑，不一定是技术上的，但是遇到这些小问题还是耽误了一些时间。这篇日志也会持续更新，把以后遇到的坑都总结到这里来。 希望以后遇到类似的情况能够迅速找到原因将其解决，同时也希望能帮助到可能会看到这篇文章的人。 Spring项目通过export方法打包为jar的问题在前面的日志中已经有专门的一篇来总结这个问题:当通过export方式打包Spring项目时，一定要记得勾选Add Directory Entries这个选项，否则spring无法正确扫描到controller，发生404 使用@PathVariable注解时抛出java.lang.IllegalArgumentException异常假如你的项目中有一个类似下面的controller来接收一个请求： 12345678@GET@RequestMapping("web/&#123;groupName&#125;")@Consumes(MediaType.APPLICATION_JSON)@Produces(MediaType.APPLICATION_JSON)public void getWorkerAddress(HttpServletRequest request, HttpServletResponse response, @PathVariable String groupName) &#123; doSomething...&#125; 当你的项目运行时你发起一个http://ip:port/web/groupName1这样的请求，那么很有可能服务器会报这样一个异常：java.lang.IllegalArgumentException: Name for argument type [java.lang.String] not available, and parameter name information not found in class file either. 大概的意思就是参数名称信息没有在类文件中找到。若是浏览器为客户端，浏览器的页面是这样的： 解决这个异常的方法有两种： 1.在@PathVariable注解后面加上参数名，比如：@PathVariable(“groupName”) 2.编译时将debug信息勾选进去： 编译时把上图绿色框中的单选框勾选，就不会报异常。原因在于Local variable属性建立了方法的栈帧中局部变量部分内容与源代码中局部变量名称和描述符之间的映射关系。 顺便了解一下上面四个选项的作用： 图片截取自：Eclipse用户手册 其实就是java工程编译时的一些选项。当我们在debug时遇到问题，比如断点打不上，source not found等等或许修改这些选项可以得到解决。 参考一篇文章：java编译时生成调试信息选项详解（javac -g） Windows环境下使用Curl，要使用双引号包裹内容web服务器是通过curl来测试的。之前自己也没用过这个所谓的命令行浏览器工具。在机器上装好curl之后，把测试那边提供的脚本拿过来，由于脚本是linux环境下的，做了一点修改之后(其实就是直接换成.bat啦)就直接跑了。脚本内容类似这样： 1curl -X POST -H &apos;content-type: application/json&apos; -d @del.txt https://localhost:8899/web/rest/data/load/topictarget -k -b cookie.txt&gt;delresult.txt 但是实际测试的过程中，发现收到的post的数据为null，确定了不是服务器的问题之后，感觉应该是curl使用的问题。查了一些资料，是说post的数据要使用双引号包裹，而不是单引号。由于是从del.txt中提取post的数据，所以不存在这个问题。后来将content-type: application/json 的单引号换成双引号之后，问题解决。 所以：Windows环境下使用Curl，要使用双引号包裹需要加引号的内容，而不是单引号 Spring项目运行过程中，@Autowired注解的变量为null的问题2016/09/09 更新 这两天开发了一个公众账号来做一些简单的记账工作。后台服务器是用springboot搭建的，测试过程中遇到了这么个情况: 在运行时服务器报了空指针NullPointerException异常，debug看了一下，发现是一个使用了@Autowired注解的变量没有被初始化。但是按理来说使用了@Autowired注解某个变量后spring会自动为我们实例化这个变量的啊！谷歌了一下，找到了一个类似的情况：Why is my Spring @Autowired field null?. 下面模拟一下问题出现的场景(代码来自上面的链接)： 12345678910111213141516171819202122232425262728293031@Controllerpublic class MileageFeeController &#123; @RequestMapping("/mileage/&#123;miles&#125;") @ResponseBody public float mileageFee(@PathVariable int miles) &#123; MileageFeeCalculator calc = new MileageFeeCalculator(); return calc.mileageCharge(miles); &#125;&#125;@Servicepublic class MileageFeeCalculator &#123; @Autowired private MileageRateService rateService; // &lt;--- should be autowired, is null public float mileageCharge(final int miles) &#123; return (miles * rateService.ratePerMile()); // &lt;--- throws NPE &#125;&#125;@Servicepublic class MileageFeeCalculator &#123; @Autowired private MileageRateService rateService; // &lt;--- should be autowired, is null public float mileageCharge(final int miles) &#123; return (miles * rateService.ratePerMile()); // &lt;--- throws NPE &#125;&#125; 访问MileageFeeController时报错： 123java.lang.NullPointerException: null at com.chrylis.example.spring_autowired_npe.MileageFeeCalculator.mileageCharge(MileageFeeCalculator.java:13) at com.chrylis.example.spring_autowired_npe.MileageFeeController.mileageFee(MileageFeeController.java:14) 可以看到，变量rateService是个空值。导致空指针异常… 原因就在于MileageFeeController.mileageFee中使用了new这种方式实例化了MileageFeeCalculator对象，该对象中的rateService为空，我们使用new这种方式实例化对象时，无法通过spring的@Autowired注解自动实例化对象中的属性。解决的方法就是实例化对象时应该通知spring，使其能够自动配置。 我采用了上述链接中的第三种方法，解决了问题： 1234567891011121314151617181920212223@Componentpublic class ApplicationContextHolder implements ApplicationContextAware &#123; private static ApplicationContext context; @Override public void setApplicationContext(ApplicationContext applicationContext) throws BeansException &#123; context = applicationContext; &#125; public static ApplicationContext getContext() &#123; return context; &#125;&#125;@Controllerpublic class MileageFeeController &#123; @RequestMapping("/mileage/&#123;miles&#125;") @ResponseBody public float mileageFee(@PathVariable int miles) &#123; MileageFeeCalculator calc = ApplicationContextHolder.getContext().getBean(MileageFeeCalculator.class); return calc.mileageCharge(miles); &#125;&#125; 发生这些问题的原因还是在于对框架的不熟悉，内部原理不甚明了。有机会真得研究研究spring的源码~~ @RestController与@Controller2016/10/24 更新 Springboot 使用 Thymeleaf 模板 打算给公众号加一点地图功能，按照这个教程在springboot项目中配置Thymeleaf，但是每次都没有正确返回html页面，反而是返回了这个html的名称。试了几次才发现自己用错了@RestController这个注解…Controller代码如下： 12345678910111213@RestController@RequestMapping("/wechat")public class MapController &#123; @RequestMapping("/map/showRestaurant") public String showRestaurant(@RequestParam(value = "location_x", required = true) String location_x, @RequestParam(value = "location_y", required = true) String location_y, @RequestParam(value = "label", required = true) String label, Model model) &#123; model.addAttribute("locationx", location_x); model.addAttribute("locationy", location_y); model.addAttribute("label",label); return "hello"; &#125;&#125; 问题原因就在于上面的@RestController这个注解，将其替换为@Controller便解决了。 根本原因在于@RestController与@Controller这两个注解之间的区别 Linux下可靠的启动webservice2016/12/14 更新 今天线上webservice发现了一个问题，技服把出现的问题描述和日志发给了我，需要解决一下。最终确定不是代码的问题，而是linux下启动程序的方式引发的一个错误。虽然简单，却很容易被疏忽导致问题的发生，值得记录下来。情况是这样的，每次springboot程序会不定时自动停止，观察log发现，每次挂掉之前都会打印一行log,大致意思是，代码中调用的系统程序tail退出了。查看代码时发现确实在tail程序退出时会打印这么一行日志，但却是正常表现，程序运行在一个死循环当中，随后就会重启tail这个程序。循环当中也做了相应的异常捕获，按道理来说webservice不应该挂掉。初步怀疑多次启动tail导致内存泄漏以至于程序退出。由于代码中没有对内存泄漏这种error类型的异常捕获和记录到日志，从日志中无法判断是否发生了内存泄漏。代码中实现了Throwable级别异常的捕获，并记录异常信息到日志，再次抛出该异常。打包，发送给技服到测试机上去跑。一会之后，又挂了。观察新的Log，竟然与之前的没什么区别，并没有什么新的异常信息输出。也就是说，压根没有异常从代码中抛出。很有可能是程序被认为关闭或被系统干掉了。但是之前询问技服，对方否定了这种情况。这就怪了。继续观察日志，此时，发现这么一行：Unregistering JMX-exposed beans on shutdown.确实是springboot退出时打印的信息。google之，大部分的答案是没有添加依赖spring-boot-starter-web所导致springboot无法启动。与现在的情况不符，当前情况是启动正常，运行时突然挂掉。再次询问技服是否kill掉了运行webservice的进程。技服否认，说该程序时运行在后台的，继续询问如何运行在后台，回答是： java -jar MyApplication.jar &amp;果然，使用这种方式运行在后台的程序，当ssh断掉或关闭bash窗口后，程序依然会被系统干掉，父进程都被干掉了，子进程也一并干掉了…正确的启动方式应为：nohup java -jar MyApplication.jar &amp; 1234567891011nohup命令：如果你正在运行一个进程，而且你觉得在退出帐户时该进程还不会结束，那么可以使用nohup命令。该命令可以在你退出帐户/关闭终端之后继续运行相应的进程。nohup就是不挂起的意思( n ohang up)。该命令的一般形式为：nohup command &amp;使用nohup命令提交作业如果使用nohup命令提交作业，那么在缺省情况下该作业的所有输出都被重定向到一个名为nohup.out的文件中，除非另外指定了输出文件：nohup command &gt; myout.file 2&gt;&amp;1 &amp;在上面的例子中，输出被重定向到myout.file文件中。 该问题虽然不是很难解决，但是很容易被忽略。故在此记录。 持续更新中….]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>spring</tag>
        <tag>curl</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Eclipse乱码问题终极解决方案]]></title>
    <url>%2F2016%2F09%2F20%2FEclipse%E7%BC%96%E7%A0%81%E9%97%AE%E9%A2%98%E7%BB%88%E6%9E%81%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88%2F</url>
    <content type="text"><![CDATA[今天在Eclipse中导入一个新项目的时候，出现了乱码问题。研究一番… 显示乱码的根本原因在于：文件本身的编码和编辑器打开和编辑文件使用的编码不一致。当编辑器以不同于文件的编码去解码该文件的时候，就会导致读出来乱码。大部分情况下英文显示正常是因为大部分编码都兼容ASCII，中文则会显示乱码。 编辑器显示乱码问题在Eclipse中，设置编辑器显示和编辑文件所采用编码的方法有四种： 1.Windows-&gt;Preference-&gt;General-&gt;Workspace ：修改整个工作空间 2.右键Project-&gt;Properties-&gt;Resource ：修改某个工程 3.右键文件-&gt;Properties ：修改某个文件 4.Windows-&gt;Preference-&gt;General-&gt;Content types-&gt;Default encoding :全局修改某种类型的文件 其中，3的优先级最高。也就是说某个文件被编辑器以哪种编码读取最终是由3中的Text file encoding决定的。一般情况下，如果我们不在3中显示指定编码(选择Other那一项)，Eclipse都会默认使用Default那一项的编码。那么，这个Default的编码又是如何决定的呢？ 注意上图中圈起来的部分：这部分表示了Default采用哪种编码是如何决定的。 可能会出现三种情况： 1.determined from content: xxx 2.determined from content type: xxx 3.inherit from container 其中： 1表示文件内容本身指定了编码，比如下图。 Encoding Bit Order Mark，简写为BOM，表明文件本身指定了采用哪种编码方式。编辑器会优先采用这种编码。 2表示采用了针对该文件类型的全局修改，也就是上面提到的第4种设置方式。 3表示继承了上一级指定的编码，这个继承关系就是我们在上面提到的：修改某个文件-&gt;修改文件所属的工程-&gt;修改整个工作空间。-&gt;表示继承于。 上面这3种情况的优先级：1&gt;2&gt;3 。也就是说如果文件本身表明了编码方式，Eclipse优先采用这种编码解码文件。若没有指定，Eclipse会查看该文件类型是否在上面的第4种方式设置中指定了编码，如有则采用该编码。如没有指定，则从下往上搜索继承关系链中指定的编码。（继承关系链：文件-&gt;工程-&gt;工作空间） 通过上面的分析明白了Eclipse 编辑器选择显示文件所采用编码的原理，相信再次遇到编辑器中的乱码问题都可以找到合适的解决方案。上面的分析不仅仅适用于java文件，同样适用于xml等其他类型文件的乱码问题。 另外一定要注意：如果通过上面4中方式的某一种修改影响了某个文件的编码，则当你再次编辑完保存该文件时，则采用此时该文件在Eclipse中指定的编码方式保存到本地。 以上的对乱码问题的分析都是基于通过修改Eclipse编辑器显示文件内容采用的编码，使其与文件本身的编码一致的方式来解决的。还有另一种思路是反过来，修改文件编码与Eclipse显示文件内容所采用的编码一致来解决乱码问题。可以使用文件编码批量转换工具进行批量转换，比如UltraCodingSwitch等。 Console显示乱码问题右键要运行的类-&gt;Run As-&gt;Run Configuratios 可修改上图中Other中的编码来指定显示打印内容的编码。 总结通过以上分析知道了如何在Eclipse中解决乱码的问题。其实文章一开始就说了，显示乱码的根本原因在于：文件本身的编码和编辑器打开文件使用的编码不一致。明白了这一点，就算在其他编辑器或编译器中或者任何能够显示文本内容的遇到乱码的情况都能够找到问题的根源，从而解决乱码问题。 至于文件本身的编码，可以通过一定的手段去改变。如通过记事本等工具修改编码后另存为等方式。 Java中输出一段内容到文件可以通过指定流的编码来指定输出字符的编码。 以上]]></content>
      <categories>
        <category>工具</category>
      </categories>
      <tags>
        <tag>Eclipse</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[记一次苦逼经历--关于spring项目打包为jar运行]]></title>
    <url>%2F2016%2F09%2F19%2FSpring%E9%A1%B9%E7%9B%AE%E6%89%93%E5%8C%85%E4%B8%BAjar%2F</url>
    <content type="text"><![CDATA[上周二刚从外包那里接手了一个的项目，主要是实现了一个web服务器，客户端可以以http请求的方式通过该服务器获取一些数据库的信息，技术上主要是使用了SpringBoot和REST API。周三就来新的需求了，实现一个接口，大概看了下代码，感觉soeasy(虽然之前从没有接触过springboot和spring，说来惭愧。不过这也说明了使用框架的好处，可以快速上手)。 中秋假期结束之后把这个接口弄完了。Eclipse里面跑起来完全没有问题。自信心爆棚。该服务器要求以jar包的方式运行，那就打个包吧。结果苦逼的经历开始了。 由于项目没有使用任何工具构建，没有maven，也没有Gradle。想着就凑合着用Eclipse里面自带的export导出jar包的功能吧。于是:右键工程，选择export。然后java-&gt;JAR file jar包打好了。把依赖什么的都放到jar所在的同一个目录，紧接着使用 java -cp interfaceService.jar;lib/* com.XXX.Application 执行。 服务器跑起来了。nice 浏览器输入URL，回车，出现了这样的画面： what? 404?赶紧看看服务器打印的日志，发现dispatcherServlet初始化完之后就没有其他动作了，也没有报错信息。跟在eclipse中正常执行的情况对比了一下，eclipse在打印完这几句Log之后就开始进入controller方法了。 初步怀疑是找不到对应的controller。 输入关键字：springboot jar 和404页面的提示，谷歌之。 找出来一堆答案，基本都是说没有正确添加注解那一类的意思。回头看看代码，该加注解的地方都加了。而且eclipse里跑着没问题啊，说明不是注解的问题。 感觉应该是打包的问题。把没用的.classpath等文件都排除，重新打包。再次执行，结果一样。 把lib和properties文件都打到包里，执行，还是没用。 然后，上图这几个勾选框吸引了我的目光，查了一下这几个框勾选之后的作用，感觉跟这个关系不大，但是也都选上试了一下，失败。 接着又以各种姿势谷歌了一遍，毫无结果。此刻心情比较郁闷，上网刷会微博吧，有点晕… 接下来重新振作精神，再打一次包。 抱着随便试试的心情，把下面的的框也选上了。 结果，这次竟然成功了！服务器返回了正确的结果。激动…原来就因为Add Directory Entries这个单选框没勾选就浪费了我两个多小时！ 然后各种姿势测了一下，没问题了。 Add Directory Entries谷歌之。神了，出现了很多与我这个情况一样的描述和解决办法。看来还是有人掉过坑啊！ 浏览了一下大家的分析，结果就是：当使用export方式打jar包来运行spring项目时，一定要记得把Add Directory Entries这个单选框勾选上！否则会扫描不到指定的controller 原因也很简单：当勾选Add Directory Entries这个选项时，生成的jar会添加文件夹信息。spring就可以扫描到相关的包信息。具体的解释看这篇文章：spring 扫描包不起作用 其实这次遇到的问题也不算是技术上的问题，但前前后后也花了将近三个小时才解决。有三点认识： 1.搜索技巧很重要，如果早一点能用spring、扫描包等关键字去搜索的话，问题早已经解决了。 2.打包尽量用构建工具，避免重复劳动还不易出错。Gradle使用学习中… 3.应该从问题的根源上想才会得到解决方法。比如，如果知道了spring获取controller的实现方式，或许能更快解决这个问题。(spring真的是一点都不懂，需要学习) 以上]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>服务器</tag>
        <tag>spring</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[理解java内存模型]]></title>
    <url>%2F2016%2F09%2F10%2F%E7%90%86%E8%A7%A3java%E5%86%85%E5%AD%98%E6%A8%A1%E5%9E%8B%2F</url>
    <content type="text"><![CDATA[最近一直在看周志明所著的《深入理解Java虚拟机》，看到java内存模型这一章。自己从网上也查了一些资料，算是对java内存模型有了一个大概的认识，对理解和编写java并发有很大的帮助。有一段时间没再写博客了，正好利用周末的时间把自己学到的java内存模型的知识总结一下。Have a nice day~ 并发为啥会出现问题PS：2016/9/13更新：今天在地铁上看到这篇文章：Java 并发原理无废话指南,感觉跟我这一小节要说明的问题比较相似，参考一下。 原子性其实去了解java内存模型主要是为java并发打下基础。我刚学编程接触多线程的时候，关于多线程并发为什么会有并发问题有过一些思考，老师或者网上的例子都会给出一个类似这样的例子： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263public class BankAccount &#123; private static int accountBalance = 10000; static class Save implements Runnable &#123; private int money; public Save(int money) &#123; this.money = money; &#125; @Override public void run() &#123; //存钱 int tempAccount = accountBalance + money; //设置余额 accountBalance = tempAccount; System.out.println("此次存入：" + money); System.out.println("当前余额：" + accountBalance); &#125; &#125; static class Obtain implements Runnable &#123; private int money; public Obtain(int money) &#123; this.money = money; &#125; @Override public void run() &#123; if (money &gt; accountBalance) &#123; System.out.println("余额不足"); return; &#125; //取钱 int tempAccount = accountBalance - money; try &#123; Thread.sleep(1000);//艾玛，卡了一秒 &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; //设置余额 accountBalance = tempAccount; System.out.println("此次取出：" + money); System.out.println("当前余额：" + accountBalance); &#125; &#125; public static void main(String args[]) &#123; int saveMoney = 10000; int obtainMoney = 10000; //自己取钱 Thread obtain = new Thread(new Obtain(obtainMoney)); //老婆存钱 Thread save = new Thread(new Save(saveMoney)); obtain.start(); save.start(); &#125;&#125; 输出结果： 1234此次存入：10000当前余额：20000此次取出：10000当前余额：0 可以看到，老婆往账户上存钱，自己从账户上取钱，两个线程同时发生，（为了保证获得演示效果，我们让取钱过程卡了一秒），结果苦逼了，账户上余额为零了，跟老婆解释不清了。 分析一下出现问题的原因： 出现这个问题的原因就在于两个人操作同一个账户，在一个人修改账户余额的时候另一个人也在修改账户余额，造成结果混乱。账户余额就是共享变量，操作账户的人就是并发线程，我们把这两个线程叫做自己线程和老婆线程。 这就涉及到线程并发的第一个问题：原子性。 我们可以看出来，出现上面的问题的主要原因其实有两部分：取钱和设置余额。取钱和设置余额这两个动作并不是原子操作，他们是分开执行的。如果在取完钱之后自己线程被挂起（这个挂起跟线程调度有关，我们在程序中模拟了这个挂起操作），老婆线程开始存钱。老婆线程存完钱后，自己线程又把刚刚的tempAccount设回余额，使旧的tempAccount覆盖了新的accountBalance，造成结果错误。 12345//取钱int tempAccount = accountBalance - money;//设置余额accountBalance = tempAccount; 为了实现这种错误的效果，我故意把 1accountBalance -= accountBalance; 拆成了上面的两行。其实accountBalance -= accountBalance;本身就不是一个原子操作，拆成两行是为了放大这种效果。 通过上面的分析，我们得出，某些读写共享变量的操作如果不是原子操作，多线程并发的情况下会出现并发问题。如何判断是否需要进行原子操作，跟业务逻辑有关，需要我们自己去判断。注意，常见的x=y,x++等都不是原子操作。 原子性是出现并发问题的重要因素，大多数情况下多线程并发出现问题都跟没有实现原子操作有关。原子性实现了多个线程并发访问某段代码的时候，使这些线程能够有序访问。因为实现原子操作代码的一旦被执行，就不能被打断，其他线程想要访问的时候，只能阻塞等待。 java中实现原子性使用了synchronized关键字，在synchronized块之间的代码具备原子性。把上面代码中的两个run方法声明为synchronized的，这样的话，这段代码中涉及到的对共享变量的操作就不会随意被打断，要么存完钱再去取，要么取完钱再去存，不会有上述代码提到的问题。 那么，该段代码出现并发问题仅仅是因为没有对共享变量实现原子操作吗？下面看内存可见性。 可见性组成原理中学过，为了更充分的利用CPU的性能，往往要在内存与处理器之间加一层：Cache（缓存），来作为内存与处理器之间的缓冲：将处理器需要的数据复制到缓存当中，当运算结束后再从缓存同步回内存当中。因为缓存的速度远远快于内存，这样处理器无需等待缓慢的内存读写，解决了处理器与内存的速度矛盾。 Java虚拟机也有类似的机制，每个线程有其自己的工作内存(类似前面的Cache)，线程对变量的读写必须在工作内存中进行，而不能直接读写主存中的变量。（这里的变量指被各个线程共享的变量，比如堆中的对象和方法区中的变量。） 画个图： 这样的机制会带来另一个问题：缓存一致性。多个线程共同处理同一个变量时，各自的缓存中的数据并不一致，同步回主内存的数据以谁的缓存数据为准呢？这就带来了并发问题。 我们回到上述的例子： 上面例子中的代码出现并发问题仅仅是因为没有对共享变量实现原子操作吗？现在我们知道自己线程和老婆线程有各自的工作内存，他们各自对accountBalance 的读写都是基于工作内存的。然后在恰当的时机同步回主内存。现在我们假设类似accountBalance -= accountBalance;这样的操作是原子性操作，设想以下的场景： 1.老婆线程向账户中存10000，此时操作老婆线程工作内存中的accountBalance~(我们使用~来表明这个变量是工作内存当中的)，此时accountBalance~ = 20000;accountBalance = 10000; 2.自己线程现在向账户中取10000，此时操作自己线程工作内存中的accountBalance~(注意此accountBalance~跟老婆线程中的accountBalance~不是同一个)，此时accountBalance~ = 0;accountBalance = 10000; 3.现在老婆线程把自己的accountBalance~刷回主内存，此时accountBalance = 20000； 4.现在自己线程把自己的accountBalance~刷回主内存，此时accountBalance = 0； 通过以上的分析，看到了即使我们使对共享变量的写操作实现了原子性，但由于内存可见性的问题，依然存在并发问题。这就是造成多线程并发的第二个原因：内存可见性。 我们在原子性分析最后还说了，通过使用synchronized关键字可以保证不存在并发问题，是因为synchronized不仅实现了代码原子性操作，还保证了内存可见性。每次执行加锁和释放锁的同时，都会把线程的工作内存和主内存进行同步。一方面，它使自己线程和老婆线程只能串行操作账户余额，另一方面，他保证了当老婆线程存完钱之后会把自己工作内存中的accountBalance~刷回主内存。设想synchronized没有实现内存可见性的话，上面的问题依旧存在，注意这和互斥没有什么关系，此时两个线程依旧是串行访问。解释这么啰嗦主要是让大家明白原子操作和内存可见是造成并发问题的两个不同因素，但是通过锁可以同时解决这两个因素带来的问题。 有序性Cpu在执行指令的时候，为了优化提高Cpu运行程序的速度，会将多条指令不按程序规定的顺序分发给各个不同的电路单元处理，叫做指令重排序。注意乱序执行的指令之间没有数据依赖关系，因为乱序执行的结果必须保证结果的正确性。理解起来比较麻烦，通过一个例子来看一下。 以下例子来自《深入理解Java虚拟机》： 12345678910111213141516171819Map configOptions;char[] configText;boolean initialized = false;//假设以下代码在线程A中执行//模拟读取配置信息，当读取完成后将initialized设置为true通知其他线程配置可用configOptions = new HashMap();configText = readConfigFile(flieName);processConfigOptions(configText,configOptions);initialized = true;//假设以下代码在线程B中执行//等待initialized为true,代表线程A已经把配置信息初始化完成while(!initialized)&#123; sleep();&#125;//使用线程A中初始化好的配置信息doSomethingWithConfig(); 在上面的例子中，由于指令重排序的优化，导致线程A中最后一句代码initialized=true被提前执行，这样线程B中使用配置信息的代码就可能出现错误。 所以，指令重排序也是造成并发问题的一个因素。在java中，synchronized关键字也可以解决指令重排序带来的并发问题，他可以保证线程之间操作的有序性。如果使用synchronized关键字将上面例子中访问initialized的相关代码包裹起来，就保证了这种多线程之间操作的有序性。因为使用synchronized关键字后，持有同一个锁的两个同步块只能串行的进入，比如： 1234567891011121314151617181920212223Map configOptions;char[] configText;boolean initialized = false;//假设以下代码在线程A中执行//模拟读取配置信息，当读取完成后将initialized设置为true通知其他线程配置可用public synchronized void init()&#123; configOptions = new HashMap(); configText = readConfigFile(flieName); processConfigOptions(configText,configOptions); initialized = true;&#125;//假设以下代码在线程B中执行//等待initialized为true,代表线程A已经把配置信息初始化完成public synchronized void doSomething()&#123; while(!initialized)&#123; sleep(); &#125; //使用线程A中初始化好的配置信息 doSomethingWithConfig();&#125; 注意上面两个方法在同一个类中实现。 至此，我们分析出了造成多线程并发问题的三个原因：原子性、可见性、原子性。并且知道了通过synchronized可以解决这三个因素带来的并发问题。java中大部分的并发控制都能通过synchronized来实现。再结合之前写的一篇synchronized的用法，对synchronized的使用更加得心应手啦！ 先行发生原则没有理解先行发生原则之前，看到网上很多博客提到这个，感觉很高深有木有~~~，理解了他之后，发现其实也挺简单。理解先行发生原则有助于我们判断线程是否安全，并发环境下两个操作之间是否存在数据冲突的问题。通过阅读《深入理解java虚拟机》和参阅网上的一些博客，我认为通过先行发生原则可以使我们知道自己写的多线程程序是否会因为可见性、原子性两个因素导致并发问题产生。至于原子性带来的问题，应该是程序员自己去分析具体的业务逻辑场景，并不能通过套用先行发生原则来判断自己的程序是否有并发问题。 比如我想到了之前宇哥跟我提到的一个bug: 在JDBC中获取日期之后通过一个静态的SimpleDateFormat对象把日期类型转换为字符串返回给用户。高并发情况下出现了这样一个问题：返回的日期是错误的，跟用户期待的日期不一致。 后来通过反复排查，最后发现是这个静态SimpleDateFormat对象造成的并发问题，他内部有一个Calendar对象，每次执行format方法的时候会调用calendar.setTime(date);,很明显当某个线程中在日期转换过程中被挂起的时候，恰好另一个线程也在执行转换日期的代码，他们调用同一个SimpleDateFormat对象中的同一个calendar.setTime(date);，结果肯定就变得混乱了。 上面的问题就是静态SimpleDateFormat对象被共享带来的结果，实际上也是原子性的问题，跟有序性和可见性并没有太大的关系。这就是所谓的业务逻辑相关，需要我们自己去分析。 解释了半天先行发生原则的作用和使用条件，下面该说说先行发生原则本身。 先行发生原则是指：如果说操作A先行发生于操作B，也就是发生在操作B之前，操作A产生的影响能被操作B观察到。 还是用《深入理解java虚拟机》中的例子来解释(真的是一本好书啊，一定要多看几遍)： 12345678//以下操作在线程A中执行i = 1;//以下操作在线程B中执行j = i;//以下操作在线程C中执行i = 2; 假设线程A中的操作i=1先行发生于线程B的操作j=i,那么可以确定在线程B的操作执行之后，j一定等于1。因为：根据先行发生原则，i=1的结果可以被B观察到。 现在保持A先行发生于B，线程C出现在A与B之间，但是线程C与B没有先行发生关系。那么j会等于多少呢？答案至不确定。因为线程C对变量i的影响可能会被B观察到，也可能不会。因为两者之间没有先行发生关系。 其实说白了，先行发生原则就是操作A在时间上或者逻辑上比B先发生，那么B一定能看到A操作带来的影响（修改了共享变量的值等等），那么此时A就是先行发生于B。 你可能会说难道B还有可能不会看到A带来的影响吗？A操作先执行的呀！想一想我们上面提到的内存可见性和有序性… 如果还没有理解所谓的先行发生原则的话，可以看一下这篇文章。 下面介绍几个java内存模型中存在的先行发生关系： 程序次序规则：一个线程内，按照程序代码的顺序，书写在前面的操作先行发生于(逻辑上)书写在后面的操作。 管程锁定规则：一个unlock操作先行发生于后面对同一个锁的lock操作。后面指时间上的先后顺序。 volatile变量规则：对一个volatile变量的写操作先行发生于后面对这个变量的读操作。这里的后面指时间上的先后顺序。 传递性：如果操作A先行发生于操作B，操作B先行发生于操作C，那么，操作A也就先行发生于操作C。 以上只是一部分先行发生关系，其他的不再一一介绍。 那么，先行发生原则如何使用呢？我们看一个例子： 123456789private int value = 0;public void setValue(int value)&#123; this.value = value;&#125;public int getValue()&#123; return value;&#125; 假设存在线程A和B，A先调用了setValue(1),然后线程B调用了同一个对象的getValue(),那么线程B收到的返回值是多少？ 套用上面存在的先行发生关系，我们发现，虽然线程A在操作时间上先行发生于线程B，但是无法确定B中的getValue()方法的返回结果。也就是说，这里的操作是不安全的。此时我们可以通过synchronized关键字来解决。可以看看这个 通过上面的分析，我们了解了先行发生原则的作用：判断内存可见性与重排序是否造成并发问题。 Volatile关键字通过上面的学习，再来看volatile就变得简单很多了。之前我对这个关键字也是看的云里雾里，现在仍然有个小疑问，后面会提到。 volatile关键字想必都不陌生，有时候在同步中会看到他。那么volatile究竟有什么作用呢?其实他实现了两个功能：保证内存可见性和禁止重排序。基于上面的内容应该对这个关键字心里有了个大概。那么，如何使用它呢？看一个例子就会用了。同样来自《深入理解java虚拟机》： 1234567891011121314151617181920212223242526272829public class VolatileTest &#123; public static volatile int race = 0; public static void increase()&#123; race++; &#125; private static int THREAD_COUNT = 20; public static void main(String args[]) &#123; Thread[] threads = new Thread[THREAD_COUNT]; for (int i = 0; i &lt; THREAD_COUNT; i++) &#123; threads[i] = new Thread(new Runnable() &#123; @Override public void run() &#123; for(int i = 0; i&lt; 10000; i++) &#123; increase(); &#125; &#125; &#125;); threads[i].start(); &#125; while (Thread.activeCount()&gt;1) &#123; Thread.yield(); &#125; System.out.println(race); &#125;&#125; 1运行结果：130310 //每次运行结果并不相同 可以看到，虽然使用了volatile关键字，但是并没有达到我们预期的效果：race=200000。Execute me?你特么在逗我？原因就在于race++,我们上面也提到过，这种自增运算并不是原子性的，恰好，volatile也没有保证原子性。所以出现了不理想的结果。 这个时候应该会有人说：volatile不是实现了内存可见性吗？自增运算虽然不是原子性的，但20个线程在访问race的时候不应该看到的是最新的值嘛？赋值的时候不是对主内存中的race操作吗？跟原子性有毛关系？以前的我就是这么想的。 现在我们来了解一下volatile的内存可见性是怎么实现的。前面也说了：每个线程有其自己的工作内存，线程对变量的读写必须在工作内存中进行，而不能直接读写主存中的变量。 当遇到读volatile变量的时候，会立即把主存中的变量值同步到工作内存当中。 当遇到写volatile变量的时候，会立即把工作内存中的变量值同步到主存中。 关于volatile怎么实现内存可见性，是通过一个叫内存屏障的东西来实现的。具体的可以看下这个 所以说：所谓的实现内存可见性并不是直接操作主内存，还是通过工作内存来实现的。当某线程把race的值取到操作栈顶的时候，volatile关键字保证了race值在此时是正确的，与主内存同步的。但是在执行race++的后续指令的时候(race++不是原子性操作，通过多个指令完成)，其他线程可能已经更新了race的值了，操作栈顶的race值变成了过期的数据，race++执行完毕后可能把较小的race值同步回主内存。 关于volatile关键字的禁止重排序，具体的可以看下这个 我们从先行发生原则的角度看一下volatile的禁止重排序： 其中：i是普通变量，x是被volatile修饰的变量。A、B操作在一个线程当中，C、D操作在另一个线程当中。B先于C执行。 根据前面的volatile先行发生关系，我们可以得出，B先行发生于C，又因为A先行发生于B(程序次序规则)，所以A先行发生于C。那么A产生的影响一定会被C观察到，当B被执行的时候，会将当前工作内存中的变量都刷回到主内存当中，并通知其他线程同步主内存到自己的工作内存。这样便保证了A产生的影响一定会被C观察到。同时，A不能被重排序到B之后，因为这样的话，A产生是影响便不能被C观察到了，违背了先行发生原则。 即：普通读写不能与其后的所有写volatile变量重排序。同理，普通读写不能与之前的所有读volatile变量重排序。 下面看看volatile的使用场景： 1.运算结果并不依赖变量的当前值，或者能够确保只有单一的线程修改变量的值。 2.变量不需要与其他状态的变量共同参与不变约束。 第一点就很好理解了，volatile不保证原子性嘛~~ 第二点我也有点疑惑，待研究… 关于volatile的使用场景，可以看看这篇文章：Java 理论与实践: 正确使用 Volatile 变量 最后终于把自己想要总结的写完了~~断断续续写了四个小时…好累… 加油！]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[理解notify notifyall sleep]]></title>
    <url>%2F2016%2F08%2F31%2F%E7%90%86%E8%A7%A3notify%20notifyall%20sleep%2F</url>
    <content type="text"><![CDATA[今天下班时和同事偶尔谈起了锁的一些问题，发现自己对这些基本一无所知。只是会使用synchronized关键字来进行简单的同步。之前也想把java并发包的源码看一下，但是最近一直没有时间，阅读源码计划也搁置了一段时间了，等重构完JDBC就先把java IO部分理一下吧。晚上回来翻了一下操作系统的书，总结一下java中基础的notify、notifyall、sleep。网上关于这三个关键字的文章有很多，理解一下，记下来。 从线程状态说起一般的操作系统中，线程的状态大概有这么几个： 执行：线程获得cpu，程序正在执行 就绪：线程已经准备好运行，只要获得cpu，便立即执行 阻塞：线程等待某些资源，暂时无法执行。这时该线程放弃cpu，引起线程调度 挂起：由于某种原因，线程被挂起，线程处于静止状态。若此时线程正在执行，挂起后暂停执行，让出cpu;若原本处于就绪状态，则暂不接受调度。 激活：把一个挂起的线程激活 着重理解一下几个关键状态的转换： 活动就绪–&gt;静止就绪：当线程处于未被挂起的就绪状态时，称为活动就绪，此时线程接收调度。当该线程被挂起后，转变为静止就绪，暂不接受调度。 活动阻塞–&gt;静止阻塞：当线程处于未被挂起的阻塞状态时，称为活动阻塞。当该线程被挂起后，转变为静止阻塞。当线程等待的事件出现后，从静止阻塞转变为静止就绪。 注意：挂起和阻塞均会使线程让出cpu，不同就在于阻塞一旦获得等待事件，就转变为就绪状态，接受调度；挂起需要激活操作后，转变为就绪状态，接收调度。 画个图理解一下： 线程创建和终止状态不再讨论。 waitwait、notify、notifyAll三个方法都是Object的方法。每个对象都拥有这三个方法。 当在线程中调用某个对象A的wait方法时，释放该对象的锁，同时让出cpu的使用权。前提是需拥有该对象A的锁，故wait方法需要在synchronized(A)的作用域中使用。 调用wait方法，相当于上图中执行-&gt;活动阻塞-&gt;静止阻塞的过程。同时，wait方法释放了对象的锁，然后阻塞，挂起，等待被唤醒。 notify当在线程Y中调用某个对象A的notify方法时，系统从众多等待被唤醒(挂起)的线程(调用了A的wait方法的线程)中选出一个线程X，将其唤醒(激活),这个过程相当于上图中静止阻塞-&gt;活动阻塞的过程。此时该线程X会重新开始对A对象锁的请求。跟wait一样，notify也需要在synchronized(A)的作用域中调用，当Y线程运行出synchronized(A)的作用域后，释放A对象的锁。 此时，线程X会得到A对象的锁(只唤醒了他一个嘛)，这个过程相当于上图活动阻塞-&gt;活动就绪的过程。此时线程等待调度执行。 需要注意的是，notify不恰当使用很有可能造成死锁问题。 notifyAll当在线程Y中调用某个对象A的notifyAll方法时，系统将所有等待被唤醒(挂起)的线程(调用了A的wait方法的线程)唤醒(激活)。这些线程会开始竞争A对象的锁。(注意notify与notifyAll的区别就在于唤醒一个等待线程还是所有的等待线程。线程被唤醒后将参与对锁的竞争，未被唤醒的线程不参与锁的竞争。)之后就跟notify一样了，线程Y运行出synchronized(A)的作用域，释放A对象的锁。 sleep与以上三个关键字不同的是，sleep方法是Thread中的方法。 当调用某个线程Y的sleep(1000)方法时，线程Y挂起，放弃cpu的使用权。与wait不同的是，他不会释放对象的锁。故sleep方法可以在非synchronized作用域使用。调用sleep的目的是不让当前线程独自霸占该进程所获的CPU资源，以留一定时间给其他线程执行的机会; 调用线程Y的sleep(1000)sleep方法，相当于上图中执行-&gt;静止就绪状态。当过1000毫秒之后，线程Y被激活，从静止就绪转为活动就绪状态。此时线程Y等待调度执行。 synchronized当程序执行遇到synchronized关键字的时候，若此时锁被占用，则线程被阻塞。相当于上图中执行-&gt;活动阻塞过程。 PS：上述的几个状态跟java中描述的Thread.state并不尽相同。而且底层真正的运行情况(OS的线程状态)是否是跟以上描述相同也有待考究。但是我理解的这几个关键字对外的表现应该与上述描述是一样的。 参考知乎上的一个提问：java sleep和wait的区别的疑惑? 使用场景Object.wait()方法需要在synchronized的作用域中使用。某线程中调用对象A的wait方法会释放该对象A的锁,线程让出cpu。什么时候会用到这个方法？获得对象的锁却又主动释放它？ 在一些生产者消费者的问题中可能会用到wait和notify方法。比如使用一个buffer，当消费者获得buffer的锁，检测到buffer为空时使用wait方法，释放锁，等待生产者填满buffer后调用buffer的notify方法通知消费者去使用buffer。 例子自己写了一个，感觉挺low，网上很多优秀的例子，代码就不贴了。]]></content>
      <categories>
        <category>编程</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>多线程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[关于加密的一点总结]]></title>
    <url>%2F2016%2F08%2F22%2F%E5%85%B3%E4%BA%8E%E5%8A%A0%E5%AF%86%E7%9A%84%E4%B8%80%E7%82%B9%E6%80%BB%E7%BB%93%2F</url>
    <content type="text"><![CDATA[前两天了解了一下数据库JDBC创建Connection的过程，其中验证用户密码的过程使用了加密算法，研究之。 信息摘要算法简介验证用户名密码的整个过程主要使用了MD5算法。严格来说，MD5不是一种加密算法，而是一种信息摘要算法。 所谓的信息摘要算法，其实就是一种特殊的散列算法。关于散列，之前在这篇总结中提到过。简单来说，就是把给出的”信息”经过哈希之后得到的值，就是这些内容的”摘要”。 特点信息摘要算法有这样几个特点： 1.生成固定长度的摘要。以MD5为例，无论信息有多大，经过MD5哈希之后，得到的是一个128bit的值。 2.算法不可逆。也就是说，不能通过摘要得到信息。可以参考一下知乎上的这个提问. 3.一般来说，信息不同，摘要也不同。虽然说冲突是一定存在的(无限多可能的信息映射到2的128次方这么大的集合当中)，但是好的摘要算法，要求无法找到两条消息，使他们的摘要相同。 满足了以上几点的散列算法，就是一种消息摘要算法。那么消息摘要又有什么作用呢？ 1.一致性检验。 我们在一些网站上下载软件的时候，这些网站会给出软件的MD5校验值。你下载完软件，把整个软件进行MD5散列，得到的值与其给出的校验值一致，则证明这个软件是正版的，未经别人修改的原装软件。这其实很好理解，理解了上面信息摘要算法的特点，就可以知道这种一致性检验的原理。MD5也可以用来检验压缩包的完整性等等。 下面是jdk-7u79对应的MD5校验值，从官方网站截图。 2.数字签名 其实数字签名就是加密后的摘要，保证了信息的完整性。后面会说到。 3.登陆验证 模拟一次数据库用户名密码验证过程(只是模拟，真实的验证过程稍复杂)。 1.首先客户端向数据库后台发起创建connection的请求，将要连接数据库名DB和用户名User发送到后台。 2.数据库后台查到确实存在数据库DB与用户User，返回success 3.客户端将密码经过MD5计算后的散列值发给数据库后台 4.数据库后台取出之前收到的User对应的密码(假设密码是明文)，使用MD5进行散列 5.将4中得到的散列值与3中的散列值比较，一致则返回连接创建成功，否则创建连接失败 从上面的过程中可以看出，我们并没有在网络中传输密码的明文，而是经过散列之后的散列值。即使黑客截获了这个密码的散列值，他也无法逆向推算出我们的密码。 那么，设想一种情况，黑客截获了密码的散列值，是不是他可以向后台发送这个散列值来进行数据库的连接呢？好像是存在这种风险，所以，我们就需要一种 加盐 的手段来保证我们密码的安全。 所谓加盐，就是在密码的任意固定位置插入一段随机字符串，让散列后的结果和使用原始密码的散列结果不相符。 使用加盐手段后，上面的验证过程改为如下： 1.首先客户端向数据库后台发起创建connection的请求，将要连接数据库名DB和用户名User发送到后台。 2.数据库后台查到确实存在数据库DB与用户User，返回盐Salt 3.客户端将密码与2中得到的Salt拼接，将得到新的字符串经过MD5计算后的散列值发给数据库后台 4.数据库后台取出之前收到的User对应的密码(假设密码是明文)，与2中发给客户端的Salt拼接得到新的字符串，使用MD5进行散列 5.将4中得到的散列值与3中的散列值比较，一致则返回连接创建成功，否则创建连接失败 注意，每次后台向客户端返回的Salt都是一个随机值，所以即使黑客截获了我们经过散列后的值，也是无法用在下一次登陆的。 java中的MD5123456789101112131415161718192021222324252627282930313233343536373839404142434445public static String stringMD5(String input) &#123; try &#123; // 拿到一个MD5转换器（如果想要SHA1参数换成”SHA1”） MessageDigest messageDigest =MessageDigest.getInstance("MD5"); // 输入的字符串转换成字节数组 byte[] inputByteArray = input.getBytes(); // inputByteArray是输入字符串转换得到的字节数组 messageDigest.update(inputByteArray); // 转换并返回结果，也是字节数组，包含16个元素 byte[] resultByteArray = messageDigest.digest(); // 字符数组转换成字符串返回 return byteArrayToHex(resultByteArray); &#125; catch (NoSuchAlgorithmException e) &#123; return null; &#125; &#125; public static String byteArrayToHex(byte[] byteArray) &#123; // 首先初始化一个字符数组，用来存放每个16进制字符 char[] hexDigits = &#123;'0','1','2','3','4','5','6','7','8','9', 'A','B','C','D','E','F' &#125;; // new一个字符数组，这个就是用来组成结果字符串的（解释一下：一个byte是八位二进制，也就是2位十六进制字符（2的8次方等于16的2次方）） char[] resultCharArray =new char[byteArray.length * 2]; // 遍历字节数组，通过位运算（位运算效率高），转换成字符放到字符数组中去 int index = 0; int pos,tmp; for (byte b : byteArray) &#123; //当时对这段代码不是很理解，使用计算器二进制、十进制、十六进制倒腾一下就好啦！ //为便于理解，此处对原文进行修改 int tmp = b &amp; 0xFF; pos = tmp &gt;&gt; 4;//得到低四位 resultCharArray[index++] = hexDigits[pos]; pos = tmp &amp; 0xF;//得到高四位 resultCharArray[index++] = hexDigits[pos]; &#125; // 字符数组组合成字符串返回 return new String(resultCharArray); &#125; 代码参考自叉叉哥的BLOG 数字签名前面也说了，数字签名其实就是加密后的摘要，也用到了信息摘要算法。 首先了解一下两个概念：对称加密和非对称加密。 对称加密，就是信息加密解密使用相同的密钥。 非对称加密，有两种密钥，公钥和私钥。 公钥私钥满足以下几个特点： 1.公钥与私钥一一对应，一把公钥只对应一把私钥，反过来也成立。 2.顾名思义，公钥是可以公开的，而私钥是不公开的。 3.公钥与私钥，知道其中一个，并不能计算出另外一个。即公开的公钥不能威胁到私钥的秘密性质。 4.公钥可以解密私钥加密的内容，私钥也可以解密公钥加密的内容 5.公钥加密的内容，通过公钥无法解密，只能由私钥解密。私钥同理。 与对称密钥加密相比，公钥加密无需共享的通用密钥，解密的私钥不发往任何用户。即使公钥在网上被截获，如果没有与其匹配的私钥，也无法解密，所截获的公钥是没有任何用处的。 下面看一下数字签名使用过程： 1.数字签名是将摘要信息用发送者A的私钥加密，与原始信息一起传送给接收者B。 2.B使用A的公钥对A私钥加密后的摘要信息进行解密，如果解密成功，则说明接收到的内容确实由A发出。这就完成了发送者A的身份认证。 3.B对收到的原始信息使用信息摘要算法得到其哈希值，与2中解密的内容进行比较，如果一致，证明原始信息未经篡改。保证了信息完整性（一致性检验）。 上面的过程能够得出数字签名的作用：身份认证与完整性检验 使用数字签名可以用来声明版权，检查盗版等等。Android中也有数字签名的影子。 数字证书数字证书是用来解决公钥从哪里来的问题。 可能有以下两种方法： a)把公钥放到互联网的某个地方的一个下载地址，事先给“客户”去下载。 b)每次和“客户”开始通信时，“服务器”把公钥发给“客户”。 但是这个两个方法都有一定的问题， 对于a)方法，“客户”无法确定这个下载地址是不是“服务器”发布的，你凭什么就相信这个地址下载的东西就是“服务器”发布的而不是别人伪造的呢，万一下载到一个假的怎么办？另外要所有的“客户”都在通信前事先去下载公钥也很不现实。 对于b)方法，也有问题，因为任何人都可以自己生成一对公钥和私钥，他只要向“客户”发送他自己的私钥就可以冒充“服务器”了 所以，数字证书就出现了。数字证书可以保证数字证书里的公钥确实是这个证书的所有者(Subject)的，或者证书可以用来确认对方的身份。 关于数字证书，网上也有很多解释。由于我自己也没有十分了解数字证书，故不再赘述。 参考网上看到一篇文章，对数字签名和数字证书进行了十分生动的介绍。 以下内容来自无恙-数字证书原理 http://www.cnblogs.com/JeffreySun/archive/2010/06/24/1627247.html &amp;&amp;&amp;&amp;&amp;&amp;&amp;&amp;&amp;&amp;&amp;&amp;&amp;&amp;&amp;&amp;&amp;&amp;&amp;&amp;&amp;&amp;&amp;&amp;&amp;&amp;&amp;&amp;&amp;&amp;&amp;&amp;&amp;&amp;&amp;&amp;&amp;&amp;&amp;&amp;&amp;&amp;&amp;&amp;&amp;&amp;&amp;&amp;&amp;&amp;&amp;&amp;&amp;&amp;&amp;&amp;&amp;&amp;&amp;&amp;&amp;&amp;&amp;&amp;&amp;&amp;&amp;&amp;&amp;&amp;&amp;&amp;&amp;&amp;&amp;&amp;&amp;&amp;&amp;&amp;&amp; 2、一个加密通信过程的演化 我们来看一个例子，现在假设“服务器”和“客户”要在网络上通信，并且他们打算使用RSA(参看前面的RSA简介)来对通信进行加密以保证谈话内容的安全。由于是使用RSA这种公钥密码体制，“服务器”需要对外发布公钥(算法不需要公布，RSA的算法大家都知道)，自己留着私钥。“客户”通过某些途径拿到了“服务器”发布的公钥，客户并不知道私钥。“客户”具体是通过什么途径获取公钥的，我们后面再来说明，下面看一下双方如何进行保密的通信： 2.1 第一回合： “客户”-&gt;“服务器”：你好 “服务器”-&gt;“客户”：你好，我是服务器 “客户”-&gt;“服务器”：？？？？ 因为消息是在网络上传输的，有人可以冒充自己是“服务器”来向客户发送信息。例如上面的消息可以被黑客截获如下： “客户”-&gt;“服务器”：你好 “服务器”-&gt;“客户”：你好，我是服务器 “客户”-&gt;“黑客”：你好 // 黑客在“客户”和“服务器”之间的某个路由器上截获“客户”发给服务器的信息，然后自己冒充“服务器” “黑客”-&gt;“客户”：你好，我是服务器 因此“客户”在接到消息后，并不能肯定这个消息就是由“服务器”发出的，某些“黑客”也可以冒充“服务器”发出这个消息。如何确定信息是由“服务器”发过来的呢？有一个解决方法，因为只有服务器有私钥，所以如果只要能够确认对方有私钥，那么对方就是“服务器”。因此通信过程可以改进为如下： 2.2 第二回合： “客户”-&gt;“服务器”：你好 “服务器”-&gt;“客户”：你好，我是服务器 “客户”-&gt;“服务器”：向我证明你就是服务器 “服务器”-&gt;“客户”：你好，我是服务器 {你好，我是服务器}[私钥|RSA] // 注意这里约定一下，{} 表示RSA加密后的内容，[ | ]表示用什么密钥和算法进行加密，后面的示例中都用这种表示方式，例如上面的 {你好，我是服务器}[私钥|RSA] 就表示用私钥对“你好，我是服务器”进行加密后的结果。 为了向“客户”证明自己是“服务器”， “服务器”把一个字符串用自己的私钥加密，把明文和加密后的密文一起发给“客户”。对于这里的例子来说，就是把字符串 “你好，我是服务器”和这个字符串用私钥加密后的内容 {你好，我是服务器}[私钥|RSA] 发给客户。 “客户”收到信息后，她用自己持有的公钥解密密文，和明文进行对比，如果一致，说明信息的确是由服务器发过来的。也就是说“客户”把 {你好，我是服务器}[私钥|RSA] 这个内容用公钥进行解密，然后和“你好，我是服务器”对比。因为由“服务器”用私钥加密后的内容，由并且只能由公钥进行解密，私钥只有“服务器”持有，所以如果解密出来的内容是能够对得上的，那说明信息一定是从“服务器”发过来的。 假设“黑客”想冒充“服务器”： “黑客”-&gt;“客户”：你好，我是服务器 “客户”-&gt;“黑客”：向我证明你就是服务器 “黑客”-&gt;“客户”：你好，我是服务器 {你好，我是服务器}[？？？|RSA] //这里黑客无法冒充，因为他不知道私钥，无法用私钥加密某个字符串后发送给客户去验证。 “客户”-&gt;“黑客”：？？？？ 由于“黑客”没有“服务器”的私钥，因此它发送过去的内容，“客户”是无法通过服务器的公钥解密的，因此可以认定对方是个冒牌货！ 到这里为止，“客户”就可以确认“服务器”的身份了，可以放心和“服务器”进行通信，但是这里有一个问题，通信的内容在网络上还是无法保密。为什么无法保密呢？通信过程不是可以用公钥、私钥加密吗？其实用RSA的私钥和公钥是不行的，我们来具体分析下过程，看下面的演示： 2.3 第三回合： “客户”-&gt;“服务器”：你好 “服务器”-&gt;“客户”：你好，我是服务器 “客户”-&gt;“服务器”：向我证明你就是服务器 “服务器”-&gt;“客户”：你好，我是服务器 {你好，我是服务器}[私钥|RSA] “客户”-&gt;“服务器”：{我的帐号是aaa，密码是123，把我的余额的信息发给我看看}[公钥|RSA] “服务器”-&gt;“客户”：{你的余额是100元}[私钥|RSA] 注意上面的的信息 {你的余额是100元}[私钥]，这个是“服务器”用私钥加密后的内容，但是我们之前说了，公钥是发布出去的，因此所有的人都知道公钥，所以除了“客户”，其它的人也可以用公钥对{你的余额是100元}[私钥]进行解密。所以如果“服务器”用私钥加密发给“客户”，这个信息是无法保密的，因为只要有公钥就可以解密这内容。然而“服务器”也不能用公钥对发送的内容进行加密，因为“客户”没有私钥，发送个“客户”也解密不了。 这样问题就又来了，那又如何解决呢？在实际的应用过程，一般是通过引入对称加密来解决这个问题，看下面的演示： 2.4 第四回合： “客户”-&gt;“服务器”：你好 “服务器”-&gt;“客户”：你好，我是服务器 “客户”-&gt;“服务器”：向我证明你就是服务器 “服务器”-&gt;“客户”：你好，我是服务器 {你好，我是服务器}[私钥|RSA] “客户”-&gt;“服务器”：{我们后面的通信过程，用对称加密来进行，这里是对称加密算法和密钥}[公钥|RSA] //蓝色字体的部分是对称加密的算法和密钥的具体内容，客户把它们发送给服务器。 “服务器”-&gt;“客户”：{OK，收到！}[密钥|对称加密算法] “客户”-&gt;“服务器”：{我的帐号是aaa，密码是123，把我的余额的信息发给我看看}[密钥|对称加密算法] “服务器”-&gt;“客户”：{你的余额是100元}[密钥|对称加密算法] 在上面的通信过程中，“客户”在确认了“服务器”的身份后，“客户”自己选择一个对称加密算法和一个密钥，把这个对称加密算法和密钥一起用公钥加密后发送给“服务器”。注意，由于对称加密算法和密钥是用公钥加密的，就算这个加密后的内容被“黑客”截获了，由于没有私钥，“黑客”也无从知道对称加密算法和密钥的内容。 由于是用公钥加密的，只有私钥能够解密，这样就可以保证只有服务器可以知道对称加密算法和密钥，而其它人不可能知道(这个对称加密算法和密钥是“客户”自己选择的，所以“客户”自己当然知道如何解密加密)。这样“服务器”和“客户”就可以用对称加密算法和密钥来加密通信的内容了。 总结一下，RSA加密算法在这个通信过程中所起到的作用主要有两个： 因为私钥只有“服务器”拥有，因此“客户”可以通过判断对方是否有私钥来判断对方是否是“服务器”。客户端通过RSA的掩护，安全的和服务器商量好一个对称加密算法和密钥来保证后面通信过程内容的安全。如果这里您理解了为什么不用RSA去加密通信过程，而是要再确定一个对称加密算法来保证通信过程的安全，那么就说明前面的内容您已经理解了。(如果不清楚，再看下2.3和2.4，如果还是不清楚，那应该是我们说清楚，您可以留言提问。) 到这里，“客户”就可以确认“服务器”的身份，并且双方的通信内容可以进行加密，其他人就算截获了通信内容，也无法解密。的确，好像通信的过程是比较安全了。 但是这里还留有一个问题，在最开始我们就说过，“服务器”要对外发布公钥，那“服务器”如何把公钥发送给“客户”呢？我们第一反应可能会想到以下的两个方法： a)把公钥放到互联网的某个地方的一个下载地址，事先给“客户”去下载。 b)每次和“客户”开始通信时，“服务器”把公钥发给“客户”。 但是这个两个方法都有一定的问题， 对于a)方法，“客户”无法确定这个下载地址是不是“服务器”发布的，你凭什么就相信这个地址下载的东西就是“服务器”发布的而不是别人伪造的呢，万一下载到一个假的怎么办？另外要所有的“客户”都在通信前事先去下载公钥也很不现实。 对于b)方法，也有问题，因为任何人都可以自己生成一对公钥和私钥，他只要向“客户”发送他自己的私钥就可以冒充“服务器”了。示意如下： “客户”-&gt;“黑客”：你好 //黑客截获“客户”发给“服务器”的消息 “黑客”-&gt;“客户”：你好，我是服务器，这个是我的公钥 //黑客自己生成一对公钥和私钥，把公钥发给“客户”，自己保留私钥 “客户”-&gt;“黑客”：向我证明你就是服务器 “黑客”-&gt;“客户”：你好，我是服务器 {你好，我是服务器}[黑客自己的私钥|RSA] //客户收到“黑客”用私钥加密的信息后，是可以用“黑客”发给自己的公钥解密的，从而会误认为“黑客”是“服务器” 因此“黑客”只需要自己生成一对公钥和私钥，然后把公钥发送给“客户”，自己保留私钥，这样由于“客户”可以用黑客的公钥解密黑客的私钥加密的内容，“客户”就会相信“黑客”是“服务器”，从而导致了安全问题。这里问题的根源就在于，大家都可以生成公钥、私钥对，无法确认公钥对到底是谁的。 如果能够确定公钥到底是谁的，就不会有这个问题了。例如，如果收到“黑客”冒充“服务器”发过来的公钥，经过某种检查，如果能够发现这个公钥不是“服务器”的就好了。 为了解决这个问题，数字证书出现了，它可以解决我们上面的问题。先大概看下什么是数字证书，一个证书包含下面的具体内容： 证书的发布机构证书的有效期公钥证书所有者（Subject）签名所使用的算法指纹以及指纹算法证书的内容的详细解释会在后面详细解释，这里先只需要搞清楚一点，数字证书可以保证数字证书里的公钥确实是这个证书的所有者(Subject)的，或者证书可以用来确认对方的身份。也就是说，我们拿到一个数字证书，我们可以判断出这个数字证书到底是谁的。至于是如何判断的，后面会在详细讨论数字证书时详细解释。现在把前面的通信过程使用数字证书修改为如下： 2.5 第五回合： “客户”-&gt;“服务器”：你好 “服务器”-&gt;“客户”：你好，我是服务器，这里是我的数字证书 //这里用证书代替了公钥 “客户”-&gt;“服务器”：向我证明你就是服务器 “服务器”-&gt;“客户”：你好，我是服务器 {你好，我是服务器}[私钥|RSA] 注意，上面第二次通信，“服务器”把自己的证书发给了“客户”，而不是发送公钥。“客户”可以根据证书校验这个证书到底是不是“服务器”的，也就是能校验这个证书的所有者是不是“服务器”，从而确认这个证书中的公钥的确是“服务器”的。后面的过程和以前是一样，“客户”让“服务器”证明自己的身份，“服务器”用私钥加密一段内容连同明文一起发给“客户”，“客户”把加密内容用数字证书中的公钥解密后和明文对比，如果一致，那么对方就确实是“服务器”，然后双方协商一个对称加密来保证通信过程的安全。到这里，整个过程就完整了，我们回顾一下： 2.6 完整过程： step1： “客户”向服务端发送一个通信请求 “客户”-&gt;“服务器”：你好 step2： “服务器”向客户发送自己的数字证书。证书中有一个公钥用来加密信息，私钥由“服务器”持有 “服务器”-&gt;“客户”：你好，我是服务器，这里是我的数字证书 step3： “客户”收到“服务器”的证书后，它会去验证这个数字证书到底是不是“服务器”的，数字证书有没有什么问题，数字证书如果检查没有问题，就说明数字证书中的公钥确实是“服务器”的。检查数字证书后，“客户”会发送一个随机的字符串给“服务器”用私钥去加密，服务器把加密的结果返回给“客户”，“客户”用公钥解密这个返回结果，如果解密结果与之前生成的随机字符串一致，那说明对方确实是私钥的持有者，或者说对方确实是“服务器”。 “客户”-&gt;“服务器”：向我证明你就是服务器，这是一个随机字符串 //前面的例子中为了方便解释，用的是“你好”等内容，实际情况下一般是随机生成的一个字符串。 “服务器”-&gt;“客户”：{一个随机字符串}[私钥|RSA] step4： 验证“服务器”的身份后，“客户”生成一个对称加密算法和密钥，用于后面的通信的加密和解密。这个对称加密算法和密钥，“客户”会用公钥加密后发送给“服务器”，别人截获了也没用，因为只有“服务器”手中有可以解密的私钥。这样，后面“服务器”和“客户”就都可以用对称加密算法来加密和解密通信内容了。 “服务器”-&gt;“客户”：{OK，已经收到你发来的对称加密算法和密钥！有什么可以帮到你的？}[密钥|对称加密算法] “客户”-&gt;“服务器”：{我的帐号是aaa，密码是123，把我的余额的信息发给我看看}[密钥|对称加密算法] “服务器”-&gt;“客户”：{你好，你的余额是100元}[密钥|对称加密算法] …… //继续其它的通信 &amp;&amp;&amp;&amp;&amp;&amp;&amp;&amp;&amp;&amp;&amp;&amp;&amp;&amp;&amp;&amp;&amp;&amp;&amp;&amp;&amp;&amp;&amp;&amp;&amp;&amp;&amp;&amp;&amp;&amp;&amp;&amp;&amp;&amp;&amp;&amp;&amp;&amp;&amp;&amp;&amp;&amp;&amp;&amp;&amp;&amp;&amp;&amp;&amp;&amp;&amp;&amp;&amp;&amp;&amp;&amp;&amp;&amp;&amp;&amp;&amp;&amp;&amp;&amp;&amp;&amp;&amp;&amp;&amp;&amp;&amp;&amp;&amp;&amp;&amp;&amp;&amp;&amp;&amp;&amp;&amp; 另外，也可以看看这篇博客：阮一峰-数字签名是什么？]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>加密</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java集合框架学习总结]]></title>
    <url>%2F2016%2F08%2F16%2FJava%E9%9B%86%E5%90%88%E6%A1%86%E6%9E%B6%E5%AD%A6%E4%B9%A0%E6%80%BB%E7%BB%93%2F</url>
    <content type="text"><![CDATA[看Jdk的源码有大概一个月时间了，中间零零散散算是把Java的集合看了个大概。源码还有很多地方不甚明白，但对java集合框架总体上有了个认识。总结一下，以后有时间再把源码理一遍。下一步的Jdk源码阅读计划是：Java IO 框架 上图并没有把所有的接口和类都列出来，只是把我认为最常用和最核心的几个类和接口的继承关系表示出来。 通过上图可以看出，java集合框架主要分为两棵树，一棵继承自Collection，一棵继承自Map。接下来分四个部分总结一下。 ListIterator在总结List之前，先看一下Iterable这个接口,它只包含一个方法: 1Iterator&lt;T&gt; iterator(); 这个方法返回一个Iterator，也就是一个迭代器，通过这个迭代器，我们可以在不了解集合内部实现的情况下遍历他,这也是设计模式中很重要的一个模式：迭代器模式(关于设计模式，待学习透彻后，会再写一篇博客总结).关于迭代器模式的好处就不再多说，顺便提一下，我们经常用到的foreach循环，内部也是通过迭代器实现的。 CollectionCollection 提供了集合的一些基本操作,Collection 接口提供的主要方法： 1234567891011boolean add(Object o) 添加对象到集合；boolean remove(Object o) 删除指定的对象；int size() 返回当前集合中元素的数量；boolean contains(Object o) 查找集合中是否有指定的对象；boolean isEmpty() 判断集合是否为空；Iterator iterator() 返回一个迭代器；boolean containsAll(Collection c) 查找集合中是否有集合 C 中的元素；boolean addAll(Collection c) 将集合 C 中所有的元素添加给该集合；void clear() 删除集合中所有元素；void removeAll(Collection c) 从集合中删除 C 集合中也有的元素；void retainAll(Collection c) 从集合中删除集合 C 中不包含的元素。 没发现有什么好说的。 ListList]]></content>
      <categories>
        <category>编程</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>源码</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[synchronized的用法]]></title>
    <url>%2F2016%2F08%2F16%2Fsynchronized%E7%9A%84%E4%B8%80%E4%BA%9B%E7%94%A8%E6%B3%95%2F</url>
    <content type="text"><![CDATA[以前的工作过程中，偶尔会遇到synchronized的使用，比如这篇总结。今天来总结一下自己对synchronized的关键字的一些认识。 同步锁synchronized顾名思义，就是用来进行一些同步工作的，我们常常在多线程的环境中使用到它，实现互斥的效果。 每一个java对象都可以当做一个同步锁，线程进入同步代码块或方法的时候会自动获得该锁，在退出同步代码块或方法时会释放该锁。获得锁的唯一途径就是进入这个锁的保护的同步代码块或方法。这里的同步代码块和同步方法，就是使用synchronized关键字标记的代码块和方法。比如： 123synchronized (object) &#123; //doSomething... &#125; 上面的 ‘{‘ ‘}’ 中间的内容，就是同步代码块，object可以认为是同步锁。同步锁实现了互斥的效果，这就是意味着最多只有一个线程能够获得该锁，当线程A尝试去获得线程B持有的锁时，线程A必须等待或者阻塞，知道线程B释放这个锁，如果B线程不释放这个锁，那么A线程将永远等待下去。 synchronized修饰代码块synchronized同步锁为普通对象12345public void function()&#123; synchronized (object) &#123; //doSomething... &#125;&#125; 当某个线程要访问上面同步代码块中的内容时，若此时没有其他线程获得object对象的锁，则此线程获得object对象的锁，获得了这段代码的执行权，否则，此线程被阻塞，直到其他线程释放了object对象的锁。 下面的例子： 1234567891011121314151617181920212223242526272829public class SyncTest &#123; public static void main(String args[])&#123; Sync[] syncs = new Sync[5]; for (int i = 0; i &lt; syncs.length; i++) &#123; syncs[i] = new Sync(new Object()); &#125; for(Sync sync : syncs)&#123; sync.start(); &#125; &#125;&#125;class Sync extends Thread&#123; Object syncObj; public Sync(Object syncObj) &#123; this.syncObj = syncObj; &#125; public void run()&#123; synchronized (syncObj) &#123; System.out.println(Thread.currentThread().getName()+"运行中..."); try &#123; Thread.sleep(1000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; System.out.println(Thread.currentThread().getName()+"结束..."); &#125; &#125;&#125; 运行结果： 12345678910Thread-0运行中...Thread-1运行中...Thread-2运行中...Thread-3运行中...Thread-4运行中...Thread-1结束...Thread-0结束...Thread-3结束...Thread-4结束...Thread-2结束... 跟我们的预期不一样，这5个线程并没有按顺序执行，他们之间不是同步的。这是因为：5个线程中的syncObj并不是指向同一个对象，他们之间不存在同步锁的竞争，所以是非同步的。将程序改为： 123456789101112131415161718192021222324252627282930public class SyncTest &#123; public static void main(String args[])&#123; Sync[] syncs = new Sync[5]; Object object = new Object(); for (int i = 0; i &lt; syncs.length; i++) &#123; syncs[i] = new Sync(object); &#125; for(Sync sync : syncs)&#123; sync.start(); &#125; &#125;&#125;class Sync extends Thread&#123; Object syncObj; public Sync(Object syncObj) &#123; this.syncObj = syncObj; &#125; public void run()&#123; synchronized (syncObj) &#123; System.out.println(Thread.currentThread().getName()+"运行中..."); try &#123; Thread.sleep(1000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; System.out.println(Thread.currentThread().getName()+"结束..."); &#125; &#125;&#125; 运行结果： 12345678910Thread-0运行中...Thread-0结束...Thread-4运行中...Thread-4结束...Thread-2运行中...Thread-2结束...Thread-3运行中...Thread-3结束...Thread-1运行中...Thread-1结束... 5个线程达到了同步的效果。但是5个线程的执行顺序并不是固定的，这是编译时重排序造成的。 重点要理解：若想要多个线程同步，则这些线程必须竞争同一个同步锁。 synchronized同步锁为类类也是一个对象，可以按照普通对象的方式去理解。他们的不同之处在于，普通对象作用于某个实例，而类对象作用于整个类。 将上面的例子修改一下： 12345678910111213141516171819202122232425public class SyncTest &#123; public static void main(String args[])&#123; Sync[] syncs = new Sync[5]; for (int i = 0; i &lt; syncs.length; i++) &#123; syncs[i] = new Sync(); &#125; for(Sync sync : syncs)&#123; sync.start(); &#125; &#125;&#125;class Sync extends Thread&#123; public void run()&#123; synchronized (SyncTest.class) &#123; System.out.println(Thread.currentThread().getName()+"运行中..."); try &#123; Thread.sleep(1000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; System.out.println(Thread.currentThread().getName()+"结束..."); &#125; &#125;&#125; 运行结果： 12345678910Thread-0运行中...Thread-0结束...Thread-3运行中...Thread-3结束...Thread-1运行中...Thread-1结束...Thread-4运行中...Thread-4结束...Thread-2运行中...Thread-2结束... 这些线程同样实现了同步，因为他们的同步锁是同一个对象–SyncTest类对象。 需要注意的是，类对象锁和普通对象锁是两个不同的锁（即使这个对象是这个类的实例），他们之间互不干扰。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546public class SyncTest &#123; public static void main(String args[])&#123; Sync[] syncs = new Sync[5]; for (int i = 0; i &lt; syncs.length; i++) &#123; syncs[i] = new Sync(); &#125; Sync1 sync1 = new Sync1(new SyncTest()); for(Sync sync : syncs)&#123; sync.start(); &#125; sync1.start(); &#125;&#125;class Sync extends Thread&#123; public void run()&#123; synchronized (SyncTest.class) &#123; System.out.println(Thread.currentThread().getName()+"运行中..."); try &#123; Thread.sleep(1000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; System.out.println(Thread.currentThread().getName()+"结束..."); &#125; &#125;&#125;class Sync1 extends Thread&#123; SyncTest syncTest; public Sync1(SyncTest syncTest)&#123; this.syncTest = syncTest; &#125; public void run()&#123; synchronized (syncTest) &#123; System.out.println(Thread.currentThread().getName()+"运行中..."); try &#123; Thread.sleep(1000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; System.out.println(Thread.currentThread().getName()+"结束..."); &#125; &#125;&#125; 运行结果： 123456789101112Thread-0运行中...Thread-5运行中...Thread-0结束...Thread-5结束...Thread-4运行中...Thread-4结束...Thread-2运行中...Thread-2结束...Thread-3运行中...Thread-3结束...Thread-1运行中...Thread-1结束... 可以看到，虽然Sync1中的对象锁是SyncTest的实例，但是Sync1与Sync的run方法中的synchronized代码块并没有实现同步，他们可以同时访问这段代码。 synchronized修饰方法synchronized修饰方法在本质上和修饰代码块是一样的，他们都是通过同步锁来实现同步的。 synchronized修饰普通方法123public synchronized void syncFunction()&#123; //doSomething...&#125; synchronized修饰普通方法中的同步锁就是这个对象本身，即”this”。 下面的代码： 123456789101112131415class Sync extends Thread&#123; public synchronized void syncFunction()&#123; doSomething(); &#125; public void syncFunction2()&#123; synchronized (this) &#123; doSomething(); &#125; &#125; private void doSomething()&#123; //doSomething... &#125;&#125; 上面syncFunction()与syncFunction2()实现的同步效果是一样的。 当类中某个方法test()被synchronized关键字所修饰时，所有不同的线程访问这个类的同一个实例的test()方法都会实现同步的效果。不同的实例之间不存在同步锁的竞争，也就是说，不同的线程访问这个类不同实例的test()方法并不会实现同步。这很容易理解，因为不同的实例同步锁不同，每个实例都有自己的”this”。 synchronized修饰静态方法123public static synchronized void syncFunction()&#123; //doSomething...&#125; 同样的，synchronized作用于静态方法时，跟使用类对象作为静态锁的效果是一样的，此时的类对象就是静态方法所属的类。 不同的线程访问某个类不同实例的syncFunction()方法(被synchronized修饰的静态方法，如上)时，他们之间实现了同步效果。结合上面的解释，这种情况也很好理解：此时不同线程竞争同一把同步锁，这就是这个类的类对象锁。 总结理解synchronized的关键就在于：若想要多个线程同步，则这些线程必须竞争同一个同步锁。这个同步锁，可以理解为一个对象。]]></content>
      <categories>
        <category>编程</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>多线程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[一些计划]]></title>
    <url>%2F2016%2F08%2F15%2F%E4%B8%80%E4%BA%9B%E8%AE%A1%E5%88%92%2F</url>
    <content type="text"><![CDATA[转眼之间毕业已有整整两个月。这两个月里，大家各奔东西，找工作的找工作，考研的继续考研。跟我一起工作了一个多月的哥们也要辞职去考研了，直接原因是刚发的工资让我们都很失望，房价的飞速上涨又让我们这些刚刚步入工作岗位的年轻人感到一阵恐慌。最后或许考研是个不错的解决方案，起码三年内不用考虑这些烂事了，而且据说考研后薪资与本科生大大的不同，具体情况因人而异吧。生活就是这样，真的猛士，敢于直面这操蛋的人生。是时候来点正能量了，无论如何生活都是要继续的。砖，还是要搬的。 上周末把博客从Jekyll迁移到了Hexo，使用了PacMan的模板。在此要感谢模板的作者，使我这样一个对前端一窍不通的菜鸟也能整出另自己满意的博客效果。花了61大洋买了五年的域名www.yukai.space作为博客的新域名。域名是从阿里云上买的，我认为是相当便宜了。希望有一个新的开始。在此作出一些生活和学习上的计划，让自己能有所改变吧。 关于学习程序员的价值在于不断学习，工作中我也发现自己真的是太菜了，专业水平有待提高，从以下几个方面开始吧： java吃饭的家伙，必须得用好了。虽然用java写过不少”小DEMO”,但是java中的很多东西自己并没有涉及，或者只是知道怎么用。说白了就是基础上还要下功夫。这点上决定从读JDK源代码开始，现在在读java中的集合类。前段时间在重构JDBC的过程中，发现自己对面向对象好像理解的较之前更为深刻了。面向对象和设计模式也是我接下来要重点关注的地方。毕竟是要励志成为架构师的男人，哈哈哈。下面列出读书清单： Thinking In Java Effect Java 大话设计模式 深入理解Jvm虚拟机 重构：改善既有的代码 前两本书可以作为工具书来使用。后三本计划在今年之前读一遍。 Linux一直都有学习Linux的想法，但是自己的工作跟Linux基本不沾边，所以给了我偷懒的理由。接下来的学习计划中，要开始接触Linux，不求有多懂，起码要到会用的程度吧，比如熟悉命令行，shell等这些最基本的东西，顺利的话，希望将来的开发环境可以逐渐转移到Linux上去，我也不知道为什么要这么做，就是觉得应该这么做。 从 鸟哥的Linux私房菜 开始吧。 Groovy第一次知道这个语言还是在学校弄安卓的时候，Gradle所使用的构建语言。Groovy可以说是java平台的脚本语言。如今函数式编程大火，自己也应该多接触一些类似的东西，方便以后向java8过渡。 数据库说来惭愧，自己虽然是在开发数据库产品的公司工作，但数据库知识却匮乏的一塌糊涂，甚至于书写基本的sql语句都有问题。先把&lt;&lt;数据库系统概论&gt;&gt;通读一遍吧。贪多嚼不烂。 以上说的都是一些大概的学习计划，至于具体的细节，我现在也没有清晰的想法。本来还想定一些关于英语及前端知识等的学习计划，但是发现在当前的工作中并不是能够体现其作用。所以先把上面所说的几点做好吧。至于所谓的做好我也无法论断是多好，只是自己心里有个谱。上面所列几点的学习时间暂定为到今年年底。 关于减肥确切的说，应该叫健身，因为本身也不算很胖，140上下吧。去年的现在大概是120左右，刚上大学那会才112。工作之后猛涨十多斤，这让人感到恐慌。女票也一直催我减肥，六块腹肌也逐渐要融为一体了。前段时间每天跑步，坚持了不到一个月吧，因为种种原因停止了（说实话，上一天班去跑步真的有点累）。还是应该健身的，毕竟还有八块腹肌的梦。那样应该感觉很帅吧。下面是我定的每天要锻炼的项目： 腹肌轮：80 卷腹：50 哑铃深蹲：40 俯卧撑：80 其他健身动作：若干 跑步：一周至少三次 关于理财写下这个题目我都有点不好意思。现在浑身上下就剩一千多块，工资也不多。下个月初又要交房租了。刚工作就遭遇经济危机。前几天看了一篇理财的文章，觉得自己也应该把钱管理起来了，起码做到收支平衡吧。具体的计划就不在这里写了，今晚好好计划计划，先从记账开始。 写了上面这些，感觉对于接下来的规划还不是很清晰。但起码心中有数，希望在接下来的日子里可以充实一些。 以上]]></content>
      <categories>
        <category>生活</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[为什么是final]]></title>
    <url>%2F2016%2F07%2F31%2F%E4%B8%BA%E4%BB%80%E4%B9%88%E6%98%AFfinal%2F</url>
    <content type="text"><![CDATA[之前一直知道这样一个事实：在java中，匿名内部类或局部内部类访问包含自己的函数的局部变量或形参时，该变量或形参必须声明为final类型的。今天逛博客时偶尔看到有人提问：为什么必须是final呢？？？对啊，为什么必须是final呢？翻了很多资料，网上关于这个问题的总结还挺多，但是都不懂他们在说什么（可能是自己理解不到位），所以自己总结一下。 注：以下提到的局部变量和形参，都是指产生这个匿名内部类的函数的局部变量和形参。 例子是这样的： 123456789101112131415161718192021222324252627public class Outer &#123; private int outerVar=0; public void testInner(final String paramVal)&#123; final Integer localVal = 1; Inner inner = new Inner()&#123; @Override public void doSomething() &#123; System.out.println(localVal+paramVal); &#125; &#125;; final int localVal1 = 2; class Inner2&#123; public void testInner2()&#123; System.out.println(localVal1); &#125; &#125; &#125; interface Inner&#123; public void doSomething(); &#125; public static void main(String args[])&#123; Outer outer = new Outer(); outer.testInner("hello"); &#125;&#125; 可以看到，paramVal，localVal，localVal1都是final的,去掉final关键字，编译就会报错。 后来在网上看到说，匿名内部类编译之后会形成一个新的.class文件，与他的外围类之间是相互独立的，java会帮助匿名内部类自动创建一个构造函数，构造函数参数即为匿名内部类用到的局部变量或形参。 我自己反编译了一下，并没有看到所谓的构造函数（难道是跟jdk有关？） 但是确实生成了这样几个.class文件： Outer.class:class Outer Outer$1.class:匿名内部类 new Inner(){…} Outer$1Inner2.class:class Inner2 Outer$Inner.class:interface Inner 这说明，匿名内部类与他的外围类之间确实是相互独立的。 为了能看到这几个类是怎么构造的，还是看看他的字节码吧。使用 javap -c Outer$1.class命令，查看匿名内部类的字节码： 123456789101112131415161718192021222324class kyu.java.util.Outer$1 implements kyu.java.util.Outer$Inner &#123; final java.lang.Integer val$localVar; final java.lang.String val$paramVal; final kyu.java.util.Outer this$0; kyu.java.util.Outer$1(kyu.java.util.Outer, java.lang.Integer, java.lang.String); Code: 0: aload_0 1: aload_1 2: putfield #1 // Field this$0:Lkyu/java/util/Outer; 5: aload_0 6: aload_2 7: putfield #2 // Field val$localVar:Ljava/lang/Integer; 10: aload_0 11: aload_3 12: putfield #3 // Field val$paramVal:Ljava/lang/String; 15: aload_0 16: invokespecial #4 // Method java/lang/Object."&lt;init&gt;":()V 19: return ..... &#125; 上面只截取了构造函数那一部分字节码。可以看到匿名内部类生成了几个自己的成员变量，他们都是final类型的，其中 this$0 对应包含自己的外围类，其他两个成员变量对应匿名内部类中使用到的局部变量和形参。在他的构造函数Outer$1中可以看到，这三个成员变量被赋值。即：之前提到的paramVal，localVal引用被各自复制了一份，存到了匿名内部类当中。 所以，现在有两个问题： 为什么需要在匿名内部类中通过构造函数将使用到的局部变量或形参的引用再复制一份，直接使用不是更方便吗？ 我们通常使用匿名内部类来执行一个异步的操作（在android中经常遇到的回调），这就存在一个生命周期不一致的问题。假如我们在匿名内部类中新开了一个线程，这个线程执行过程中需要使用局部变量或形参。但是极有可能当这个新开的线程执行到这一步的时候，产生这个匿名内部类的函数早已经执行完毕了，他的局部变量和形参也早已被回收了（局部变量和形参都存在于栈内存中），新开的线程所使用的局部变量或形参都是空的，不指向任何实例。这样就造成空指针问题。 局部变量或形参为什么必须是final类型？ 在1中我们知道匿名内部类将局部变量和形参的引用复制了一份，他们指向同一个实例。我们通过分析匿名内部类的字节码得到这个真相。但是从源代码的角度看，好像是匿名内部类直接使用了这个局部变量或形参，并不存在什么复制啊，他们明明就是同一个引用。 1234567final Integer localVal = 1;Inner inner = new Inner()&#123; @Override public void doSomething() &#123; System.out.println(localVar+paramVal); &#125;&#125;; 这样就会给我们造成一个错觉：我们在这个局部变量存在的函数中继续修改这个局部变量引用时（将他指向另一个实例），修改的就是匿名内部类中使用的那个引用（反之在匿名内部类中修改局部变量指向的引用），因为他们看上去是同一个啊。实际上我们从1知道了，实际情况不是这样的。但是仅仅从代码的角度来看，是察觉不出这种变化的。所以如果要在语义上保证局部变量和副本的一致性，就应当使用final来保证该局部变量不变（干脆就不让你修改了）。 ps:后来在stackoverflow上看到Why are only final variables accessible in anonymous class?，可以参考一下。]]></content>
      <categories>
        <category>编程</category>
      </categories>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[java编程技巧]]></title>
    <url>%2F2016%2F07%2F24%2Fjava_Tips%2F</url>
    <content type="text"><![CDATA[突然想到把自己平时用到的，网上看到的java编程过程中的小技巧总结下来~~ 1. 循环中尽量不要使用try..catch 代码块，应该将其放在最外层 2. if语句中,判断条件尽量不要使用if(!…)的形式，这样只会使代码更加难以理解 3. 循环内不要不断创建对象引用，而应该： 1234Object obj = null;for (int i = 0; i &lt;= count; i++) &#123; obj = new Object(); &#125; 4. 不要在循环条件中重复计算变量，比如： 1for (int i = 0; i &lt;= obj.size(); i++)&#123;...&#125; 5. 避免使用”魔术数字”,所有的数字值都应该赋予一个有意义的变量，使用这个变量，而不是数字 6. 尽量采用懒加载的策略，即在需要的时候才创建,例如： 1234String str = "aaa";if (i == 1) &#123; list.add(str);&#125; 建议替换为： 1234if (i == 1) &#123; String str = "aaa"; list.add(str); &#125; 7. 使用同步代码块替代同步方法,同步代码块里只放需要同步的代码 8. 乘(除)2或者2的倍数时，尽量选择移位操作，提高性能 9. 使用&amp;&amp; ,|| 操作符时，将首先需要满足的条件置于操作符之前。因为&amp;&amp; 和 || 具有短路性。另外，体会if(e. key==k||k.equals(e.key)) 的细节。判断条件的目的是要求满足k.equals(e.key)。用||将（e.key==k）与 k.equals(e.key)连接起来，在性能上有更好的表现。（HashMap源码） 10. 尽量用for each语句代替for循环 11. 在java中小数类型默认为double,若对精度没有很高要求，应该显示的声明为float.如 3.14f。 12. 调用equals()函数时(或其他类似函数)，将string字符串放在左边进行比较，防止空指针异常。 1if("hello".equals(variable))&#123;...&#125; 13. 在使用一些通过返回int判断状态的函数时，不要相信-1。比如： 1if(string.indexof(character) != -1)&#123;...&#125;` 应改为： 1if(string.indexof(character) &gt;0 )&#123;...&#125; 14. 避免意外的赋值，比如： 1if(variable == 5)&#123;...&#125;` 应改为： 1if(5 == variable)&#123;...&#125; 避免不小心将5赋给variable。但是在我使用jdk1.7的时候，倘如你在条件判断语句中写出if(variable = 5)这样的句子，编译器会自动报警。不过，养成好的编程习惯总是没有错的~ 15. 检查NULL。在调用集合或者数组的成员函数时，请确保他已经存在，而不是NULL。这是我编程时很容易犯的错误。比如： 1if(array.length &gt; 0)&#123;...&#125; 应改为： 1if(array != null &amp;&amp; array.length &gt; 0)&#123;...&#125; 16. 确保只有一个退出点。比如： 123456789101112private boolean isEligible(int age)&#123; if(age &gt; 18) &#123; return true; &#125; else &#123; return false; &#125;&#125; 应改为： 1234567891011121314private boolean isEligible(int age)&#123; boolean result; if(age &gt; 18) &#123; result = true; &#125; else &#123; result = false; &#125; return result;&#125; 17. 以final类型标记方法参数。当你不小心修改参数值时，编译器会报警。 1private boolean isEligible(final int age)&#123;...&#125; 18. 把多个if语句组合成单一if语句。比如： 123if(age &gt; 18)&#123; if(!man)&#123;...&#125;&#125; 应改为： 1if(age &gt; 18 &amp;&amp; !man)&#123;...&#125; 19. 尽量不返回null null可以表达两种意思，一种是不存在、为空，一种是出现错误。返回null会让调用者感到迷惑，同时也会因为传递null造成很多意想不到的错误。可以针对需要返回null的情况为null专门构造一个类，比如函数返回一个connection，可以为返回null的情况实现一个名为FakeConnection的类，返回这个类的对象。需要把null放进“容器数据结构”里面的情况同理。 20. if嵌套不超过三层。 21. 实现RandomAccess接口的类实例，假如是随机访问的，使用普通for循环效率将高于使用foreach循环；反过来，如果是顺序访问的，则使用Iterator会效率更高。(for each底层通过Iterator实现) 实现RandomAccess接口的代表类：ArrayList未实现RandomAccess接口的代表类：LinkedList]]></content>
      <categories>
        <category>编程</category>
      </categories>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ANT的使用]]></title>
    <url>%2F2016%2F07%2F18%2FAnt%E7%9A%84%E4%BD%BF%E7%94%A8%2F</url>
    <content type="text"><![CDATA[之前写Android的时候一直想学习构建工具Gradle，但一直没有花功夫去研究。由于平时工作中使用的IDE为Eclipse，所以免不了和Ant打交道。今天工作的时候需要自己使用Ant打包一个工程，遂研究一番。 教程Ant是一个很成熟的构建工具了，网上也有许多教程。参考了很多。学习下面两篇教程可以快速上手。 Ant Tutorial Ant 实践 另外附上Ant常用命令： Overview of Apache Ant Tasks 实践下面是自己写的build.xml。存在这里，以后用到可以参考。 下面的例子用来编译、打包一个java工程，这个工程是一个Hibernate方言包的开发。该工程还引用到了其他jar包。 build.xml 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;!-- Oscar XcluseterHibernate Ant build file--&gt;&lt;project name="OSCAR-XCLUSETER-HIBERNATE" default="usage" basedir="."&gt; &lt;target name="build" depends="clean" /&gt; &lt;target name="init" description="default init"&gt; &lt;property file="build.properties" /&gt; &lt;!-- Project Properties --&gt; &lt;property name="project" value="oscarXcluseterHibernate3" /&gt; &lt;property name="name" value="OSCAR HIBERNATE" /&gt; &lt;tstamp&gt; &lt;format property="year" pattern="yyyy" locale="zh_CN" /&gt; &lt;format property="builddate" pattern="yyMMdd" locale="zh_CN" /&gt; &lt;/tstamp&gt; &lt;property name="version" value="$&#123;version.major&#125;.$&#123;version.minor&#125;.$&#123;version.revision&#125;$&#123;version.suffix&#125;" /&gt; &lt;property name="version.number" value="$&#123;version.major&#125;.$&#123;version.minor&#125;.$&#123;version.revision&#125;" /&gt; &lt;property name="version.major.minor" value="$&#123;version.major&#125;.$&#123;version.minor&#125;" /&gt; &lt;property name="final.name" value="$&#123;project&#125;" /&gt; &lt;property name="vesrion.build" value="build$&#123;builddate&#125; $&#123;version.subbuild&#125; $&#123;version.buildID&#125; for ALL " /&gt; &lt;!-- Build Defaults --&gt; &lt;property name="src.dir" value="$&#123;basedir&#125;/src" /&gt; &lt;property name="lib.dir" value="$&#123;basedir&#125;/lib" /&gt; &lt;property name="build.home" value="$&#123;basedir&#125;" /&gt; &lt;property name="build.src" value="$&#123;basedir&#125;/build" /&gt; &lt;property name="build.dest" value="$&#123;basedir&#125;/antClasses" /&gt; &lt;property name="build.release" value="$&#123;basedir&#125;/release" /&gt; &lt;property name="build.tmp" value="$&#123;basedir&#125;/tmp" /&gt; &lt;!-- JAR artifacts --&gt; &lt;property name="hiberante3.jar" value="$&#123;lib.dir&#125;/hibernate3.jar" /&gt; &lt;!-- Version info filter set --&gt; &lt;tstamp&gt; &lt;format property="DSTAMP" pattern="yyyyMMdd" locale="zh_CN" /&gt; &lt;format property="TSTAMP" pattern="hhmm" /&gt; &lt;/tstamp&gt; &lt;filterset id="version.filters"&gt; &lt;filter token="VERSION_NUMBER" value="$&#123;version.number&#125;" /&gt; &lt;filter token="BUNDLE_NAME" value="$&#123;vesrion.name&#125;" /&gt; &lt;filter token="BUNDLE_VERSION" value="$&#123;version&#125;$&#123;DSTAMP&#125;$&#123;TSTAMP&#125;" /&gt; &lt;filter token="BUILD_VERSION" value="$&#123;vesrion.build&#125;" /&gt; &lt;/filterset&gt; &lt;path id="classpath"&gt; &lt;pathelement location="$&#123;hiberante3.jar&#125;" /&gt; &lt;/path&gt; &lt;/target&gt; &lt;target name="usage" depends="init"&gt; &lt;echo message="$&#123;name&#125; Build file" /&gt; &lt;echo message="-------------------------------------------------------------" /&gt; &lt;echo message="" /&gt; &lt;echo message=" available targets are:" /&gt; &lt;echo message="" /&gt; &lt;echo message=" package --&gt; generates oscarXcluseterHibernate file" /&gt; &lt;echo message=" build --&gt; compiles the source code" /&gt; &lt;echo message=" clean --&gt; cleans up the directory" /&gt; &lt;echo message="" /&gt; &lt;echo message=" See the comments inside the build.xml file for more details." /&gt; &lt;echo message="-------------------------------------------------------------" /&gt; &lt;echo message="" /&gt; &lt;echo message="" /&gt; &lt;/target&gt; &lt;!-- Just build --&gt; &lt;target name="compile-prepare" depends="init" description="Prepare for compile"&gt; &lt;!-- create directories --&gt; &lt;mkdir dir="$&#123;build.src&#125;" /&gt; &lt;mkdir dir="$&#123;build.dest&#125;" /&gt; &lt;!-- copy src files --&gt; &lt;copy todir="$&#123;build.src&#125;" overwrite="yes"&gt; &lt;fileset dir="$&#123;src.dir&#125;"&gt; &lt;exclude name="**/*.MF" /&gt; &lt;/fileset&gt; &lt;/copy&gt; &lt;/target&gt; &lt;target name="compile" depends="compile-prepare" description="compile the project"&gt; &lt;!-- Compiles the source directory --&gt; &lt;javac srcdir="$&#123;build.src&#125;" destdir="$&#123;build.dest&#125;" debug="$&#123;build.debug&#125;" deprecation="$&#123;build.deprecation&#125;" source="$&#123;build.source&#125;" target="$&#123;build.target&#125;" compiler="$&#123;build.compiler&#125;" optimize="$&#123;build.optimize&#125;" includes="**/*.java" excludes="**/CVS/**,**/.svn/**" encoding="GB18030" includeantruntime="false" executable="C:\Program Files\Java\jdk1.5.0_22\bin\javac" fork="yes"&gt; &lt;classpath refid="classpath" /&gt; &lt;/javac&gt; &lt;!-- copy src files exclude java file--&gt; &lt;copy todir="$&#123;build.dest&#125;" overwrite="yes"&gt; &lt;fileset dir="$&#123;build.src&#125;"&gt; &lt;exclude name="**/*.java" /&gt; &lt;/fileset&gt; &lt;/copy&gt; &lt;/target&gt; &lt;target name="build-manifests" depends="init,compile-prepare"&gt; &lt;!-- Filtering tokens for JAR manifests--&gt; &lt;filter token="source.jdk" value="$&#123;build.source&#125;" /&gt; &lt;filter token="target.jdk" value="$&#123;build.target&#125;" /&gt; &lt;mkdir dir="$&#123;build.tmp&#125;" /&gt; &lt;copy todir="$&#123;build.tmp&#125;" overwrite="yes" filtering="yes" encoding="GB18030"&gt; &lt;filterset refid="version.filters" /&gt; &lt;fileset dir="src/META-INF" includes="MANIFEST.MF" /&gt; &lt;/copy&gt; &lt;/target&gt; &lt;target name="package" depends="compile,build-manifests" description="create jar file"&gt; &lt;mkdir dir="$&#123;build.release&#125;" /&gt; &lt;jar jarfile="$&#123;build.release&#125;/$&#123;final.name&#125;.jar" manifest="$&#123;build.tmp&#125;/MANIFEST.MF" basedir="$&#123;build.dest&#125;" includes="**" /&gt; &lt;/target&gt; &lt;target name="clean" depends="package"&gt; &lt;delete dir="$&#123;build.src&#125;" /&gt; &lt;delete dir="$&#123;build.dest&#125;" /&gt; &lt;delete dir="$&#123;build.tmp&#125;" /&gt; &lt;/target&gt;&lt;/project&gt; build.properties 1234567891011121314151617181920212223# -----------------------------------------------------------------------------# build.properties## This is an example "build.properties" file, used to customize building # OSCAR-JDBC for your local environment. It defines the location of all external# modules that OSCAR-JDBC depends on.# -----------------------------------------------------------------------------# ----- Version Control Flags -----vesrion.name=Mainversion.major=1version.minor=0version.revision=0version.suffix=xversion.subbuild=001version.buildID=00000000build.source=1.5build.target=1.5build.debug=falsebuild.optimize=truebuild.compiler=javac1.5]]></content>
      <categories>
        <category>工具</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>ant</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[毕业了]]></title>
    <url>%2F2016%2F06%2F30%2F%E6%AF%95%E4%B8%9A%E4%BA%86%2F</url>
    <content type="text"><![CDATA[毕业的日子真的过的很快。原来以为很遥远的事情，现在回头看，好像是一个瞬间。 转眼之间已经毕业13天了，毕业后上班第三天。有时候会细细回味大学时光，趁现在还记得。隐约想起高中毕业后感伤的自己，如同现在一样。曾经心中暗自海誓山盟，却也敌不过时间的风化。曾经拼命想要记住的细节也早就淡的跟阳光下的影子一样，好像从来没有发生过。曾经要好的兄弟一年也不见的联系几次。害怕过几年之后，对大学的感情也就麻木了。 但是时间总会过去，没有人能够阻止。我们要做的，就是在剩下的时光里，慢慢品味这段逝去的青春。失去的才是美好的，不是么？ 大学四年里，成绩不好不坏，人缘不多不少。很感谢这段大学时光，给我的人生留下无限美好的回忆。首先要感谢我的父母，作为农民，供养一个大学生着实不易，他们给了我向上的勇气。然后是我的女朋友，她是一个又懒又笨的女生，但是很可爱也很美丽。希望以后的平淡时光有你陪伴我，我会好好珍惜。还有陪我度过大学四年操蛋时光的兄弟们，一起打球互损，一起声色犬马。希望若干年后的我们再次遇见依然能够如同当初一样，啤酒虽好，可不要贪杯噢。当然还有帮助我的老师们，希望我们一直是好朋友，珍重。 希望若干年以后再看到这些话，我能如同现在的心情一样，满足，遗憾，感怀。]]></content>
      <categories>
        <category>生活</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[java中的枚举]]></title>
    <url>%2F2016%2F06%2F30%2Fjava%E4%B8%AD%E7%9A%84%E6%9E%9A%E4%B8%BE%2F</url>
    <content type="text"><![CDATA[已经好久没有动博客了，毕业之后的第一篇。下班了单开一篇，把毕业照补上。 Java中的枚举是在JDK1.5以后出现的。之前的开发过程中并没有用过，但是有碰到过关于枚举的代码。貌似是一种更为简单有效的常量定义方式。学习之，希望以后的写代码过程中可以熟悉并掌握枚举的用法。 使用场景：每当需要一组固定的常量的时候，如一周的天数、一年四季等。或者是在我们编译前就知道其包含的所有值的集合，比如定义了一些状态等等。这个时候就有可能需要使用枚举了。 与 public static final 的常量定义方式进行比较：在以上的场景中，回顾以往的做法，比如我们定义这样一些状态： 12345public class State &#123; public static final int Normal = 0;//正常 public static final int Update = 1;//已更新 public static final int Delete = 2;//已删除&#125; 使用的时候，在程序中直接使用 类名.常量名 就可以了。但是这样还存在一些问题。比如： 123456789101112131415public void doSomething(int state)&#123; switch(state)&#123; case State.Normal: ... break; case State.Update: ... break; case State.Delete: ... break; default: ... &#125;&#125; 在程序运行过程中，传入的state变量很有可能并不是我们期待的。比如 doSomething(4) 这样的调用方式有可能出现问题，因为我们想要的参数值仅仅是Normal、Update、Delete中的一个。为此，我们不得不在default分支中做一些处理来应对这种情况。换句话说，这是类型不安全的。 另外，在我们对程序进行调试的过程中，上面定义的常量会转换成一些毫无意义的整数值，也就是所谓的魔术数字。给我们的调试带来痛苦。 因为整形枚举属于编译期常量，所以编译过程完成后，所有客户端和服务器端引用的地方，会直接将整数值写入。这样，当你修改旧的枚举整数值后或者增加新的枚举值后，所有引用地方代码都需要重新编译，否则运行时刻就会出现错误。 那如果换成枚举常量呢？ 123public enum State &#123; Normal,Update,Delete&#125; 类型安全检查： 123456789101112131415public void doSomething(State state)&#123; switch(state)&#123; case Normal: ... break; case Update: ... break; case Delete: ... break; default: ... &#125;&#125; 调用doSomething(State state)方法时，在编译期间就会限定类型，不允许越界的情况出现。 另外，枚举提供了一些内置的方法，比如，列出所有的枚举值等。这些方法简化了常量的使用。 枚举类型的使用 常量： 123public enum State&#123; Normal,Update,Delete&#125; 遍历枚举常量： 123for(State state:State.values())&#123; System.out.println(state);&#125; 自定义属性、方法： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051public enum State&#123; //若之后为枚举类型添加属性或方法，最后一个枚举常量后面记得加分号 Normal("正常",0),Update("已更新",1),Delete("已删除",2); private String name; private int index; // 构造方法，注意：构造方法不能为public，因为enum并不可以被实例化 private State(String name, int index) &#123; this.name = name; this.index = index; &#125; // get set 方法 public String getName() &#123; return name; &#125; public void setName(String name) &#123; this.name = name; &#125; public int getIndex() &#123; return index; &#125; public void setIndex(int index) &#123; this.index = index; &#125; // 普通方法 public static String getName(int index) &#123; for (State c : State .values()) &#123; if (c.getIndex() == index) &#123; return c.name; &#125; &#125; return null; &#125; //覆盖toString方法,这样调试就不会看到魔术数字啦 @Override public String toString()&#123; return name+":"+index; &#125; &#125;public void test()&#123; for (State state : State.values()) &#123; //输出：正常:0 已更新:1 已删除:2 System.out.println(state); &#125;&#125; 实际上，以上枚举声明定义的类型是一个final类，因此枚举类型不可以被继承。所有的枚举都继承自java.lang.Enum类。其中，Normal、Update、Delete是这个枚举类的三个实例，他们都是static final类型的对象。Normal(“正常”,0),Update(“已更新”,1),Delete(“已删除”,2)正是调用了State类的私有构造函数State(String name, int index)进行实例化的。 因此，枚举类型可以作为一个类来使用，其不能被继承。所以他比常量枚举更加强大。 实现接口 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152public interface HandleState&#123; void printState();&#125;public enum State implements HandleState&#123; //若之后为枚举类型添加属性或方法，最后一个枚举常量后面记得加分号 Normal("正常",0),Update("已更新",1),Delete("已删除",2); private String name; private int index; // 构造方法，注意：构造方法不能为public，因为enum并不可以被实例化 private State(String name, int index) &#123; this.name = name; this.index = index; &#125; // get set 方法 public String getName() &#123; return name; &#125; public void setName(String name) &#123; this.name = name; &#125; public int getIndex() &#123; return index; &#125; public void setIndex(int index) &#123; this.index = index; &#125; // 普通方法 public static String getName(int index) &#123; for (State c : State .values()) &#123; if (c.getIndex() == index) &#123; return c.name; &#125; &#125; return null; &#125; //覆盖toString方法,这样调试就不会看到魔术数字啦 @Override public String toString()&#123; return name+":"+index; &#125; public void printState() &#123; System.out.println(this); &#125;&#125; 可以看到，枚举和一般的类一样都可以实现接口。 Enum 相关工具类 JDK5.0 中在增加 Enum 类的同时，也增加了两个工具类 EnumSet 和 EnumMap，这两个类都放在 java.util 包中。具体的使用就查看官方文档吧，这里不再赘述。 参考java enum的用法详解[转] Java 语言中Enum类型的使用介绍]]></content>
      <categories>
        <category>编程</category>
      </categories>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[java中的ThreadLocal]]></title>
    <url>%2F2016%2F06%2F21%2Fjava%E4%B8%AD%E7%9A%84ThreadLocal%2F</url>
    <content type="text"><![CDATA[今天测试那边在做压力测试的时候，发现新版本的Jdbc占用CPU很高，导致并发量降低，研究半天，发现出问题的地方在于每条语句执行过后都会调用ThreadLocal的get方法。研究一番ThreadLocal… 问题背景：每次sql语句执行结束之后，最后都会接受后台传回的ReadyForQueryPacket包，标记语句执行完毕。在新版本的协议当中，针对读写分离的功能，在这个包中增加了一些要接收的数据：标记数据库主机状态的lsn。这个lsn标志着主备机之间的数据是否存在差异。每次执行完sql语句之后，都要将数据库后台传回来的lsn与当前主机的lsn进行比较，从而决定下一步的读写过程。每次取本机的lsn操作长这样： 1LsnVo lv = ((LsnVo)DispatchConnection.threadLocalLsn.get()); 其中，threadLocalLsn是DispatchConnection中的一个ThreadLocal类的静态对象。由于每次执行sql语句之后都会执行它的get方法，导致不必要的cpu浪费。这就是cpu异常的原因。 遂改之： 1LsnVo lv = ((DispatchConnection) conn).getLsnVo(); 将threadLocalLsn的get方法的执行提前到DispatchConnection的构造函数中去，之后的每次读取都是直接读取在DispatchConnection保存的成员变量。避免了频繁的get方法调用。 曾经在这里还有个疑问，那就是我认为不可以将这个get方法提前到DispatchConnection初始化当中，理由是如果有多个线程操作同一个DispatchConnection对象的时候，他们其实读取的是同一个lsn,造成共享变量的问题，而实际上lsn是一个线程级变量，不应该被多个线程共享。 后来，宇哥跟我解释说一般不会有多个线程操作同一个connection 的场景，因为这样很容易造成不可预知的后果（事务提交等被打乱）。看来还是对数据库这块的知识太缺乏啊！ PS:后来还是出问题了，使用线程池的时候，确实有可能发生上面多线程并发的情况。改回原来版本，性能下降问题依然存在，现未找到合适的解决办法。2016/7/29 so,按照上面的改法问题解决了。 那为什么要使用ThreadLocal存储lsn呢？前面也说了lsn是一个线程级变量，每个线程可以有多个connection，但这多个connection应当操作同一个lsn对象。 这就是ThreadLocal的一个典型应用场景。 ThreadLocal原理：使用ThreadLocal存储变量，实现了线程级别的变量，即同一个线程内这个变量只有一个。 ThreadLocal的set和get方法： 12345678910111213141516171819202122public void set(T value) &#123; Thread t = Thread.currentThread(); ThreadLocalMap map = getMap(t); if (map != null) map.set(this, value); else createMap(t, value);&#125;public T get() &#123; Thread t = Thread.currentThread(); ThreadLocalMap map = getMap(t); if (map != null) return (T)map.get(this); // Maps are constructed lazily. if the map for this thread // doesn't exist, create it, with this ThreadLocal and its // initial value as its only entry. T value = initialValue(); createMap(t, value); return value;&#125; 可以看到，我们存入ThreadLocal的变量最终存到一个ThreadLocalMap中，这个ThreadLocalMap实际上是Thread的成员变量。这个ThreadLocalMap以ThreadLocal为键，是因为，在一个线程中很可能不只有一个ThreadLocal对象，每个ThreadLocal所要存储的Value值也不同。每次调用ThreadLocal的get方法时，都会去当前线程的ThreadLocalMap中找到对应的值。起到线程隔离的效果。 很容易明白他的工作原理。 应用场景之前看了网上很多资料说ThreadLocal的应用场景： 1.解决了多线程共享对象的问题， 2.实现线程间的数据隔离，每个线程都有他自己的变量副本。 对于1，这样的说法现在看起来也有些勉强，首先不能说解决了多线程共享对象的问题，因为如果一个对象需要多个线程共享（在某些场景下这是必须的），那么他在内存中应该只有一份，但是使用ThreadLocal之后会有多个内存对象存在，而不是多个引用指向同一片内存。这样的话只能通过线程同步或者其他方法解决这种问题。但是在上面的场景中，说ThreadLocal解决了多线程共享对象的问题，也说得通。但是要加一个前提，那就是这个所谓的共享对象其实是可以不共享的，并不是必须共享的。比如上面的场景中，DispatchConnection 中 的masterLsn代表主机的状态，这个Lsn是可以不设为全局的（虽然主机只有一台，代表主机真实状态的Lsn也只有一个），每个线程可以有自己的masterLsn来表示当前主机的状态，因为在同一个线程中，每次的数据库读写操作是基于上一次操作进行的。 对于2，每个线程有自己的变量副本。在上面的场景中，每个线程都应该操作同一个masterLsn。比如，首先创建了一个DispatchConnection，使用这个connection对数据库进行了更新操作，更新DispatchConnection中的masterLsn，然后关闭这个connection。紧接着又创建一个新的DispatchConnection，使用这个connection对数据库进行一些新的操作，比如查询刚才的更新。这个时候，需要将刚刚获得的masterLsn发送到备机，使备机与主机进行同步工作，然后才可以查询到上一个DispatchConnection所做的更新。所以，虽然创建了新的DispatchConnection，但前后两个DispatchConnection中的masterLsn应该是一样的，即这个masterLsn在同一个线程中应该只有一个，无论创建多少DispatchConnection（masterLsn是DispatchConnection的成员变量），这些connection中的Lsn都指向同一个对象。 故，使用ThreadLocal保存该masterLsn到DispatchConnection中。 我们总结一下使用ThreadLocal存储某个变量的场景，或者说条件： 1.这个变量在同一个线程中只允许有一个，比如上面的masterLsn，尽管包含masterLsn的DispatchConnection被创建了多次，但是他们的成员变量masterLsn指向同一个对象。 2.要满足1中的条件，可以将该变量设为static的。此时多个线程共享这同一个变量，内存中独一份。但是这个时候会产生同步问题，代码的复杂度上升，也容易出问题。 所以，使用ThreadLocal的场景应该是这样：这个变量不同的线程之间不需要共享，也就是这个变量不要求是全局的。同时，在同一个线程中，这个变量要求只有一个，即这个变量为线程级别的变量。 PS:既然说这个变量是线程级别的变量，那为什么不在这个线程类中创建这样一个变量呢？注意，线程的创建有时是不可控的，在上面的场景中，创建线程的基本上是使用DispatchConnection的用户，我们不能要求用户去创建masterLsn，更何况，这个masterLsn是属于DispatchConnection这个类，而DispatchConnection有可能创建销毁多次。 另外，网上提到使用ThreadLocal的一个好处：避免了参数的传递增加程序复杂性。 我不太理解这个好处从哪里体现出来。如果说要避免参数传递，将这个参数设为类的成员变量也可以解决。应用ThreadLocal的情况是：把ThreadLocal设为了成员变量，把这个参数存入ThreadLocal中。这个虽然说是避免了参数的传递，但这与使用ThreadLocal的目的相去甚远。使用ThreadLocal最主要还是解决线程级别的变量的问题。 2016/11/01更新今天在地铁上看到了一篇不错的文章，介绍ThreadLocal内存泄漏的实例–ThreadLocal 内存泄露的实例分析. 另外，该作者的另一篇blog，讲解ThreadLocal的原理，也很清晰深入分析 ThreadLocal 内存泄漏问题 拜读完作者的文章后，回家又翻了一遍ThreadLocal的源码，认为和作者所要解释的一致，并且对ThreadLocal的理解更加深了。 ThreadLocal instances are typically private static fields in classes that wish to associate state with a thread 上面的话出自java doc oracle鼓励我们将ThreadLocal对象声明为一个private static类型的变量A。结合上述文章和源码来看，A的生命周期将变得和保存他的类对象一样长，这样ThreadLocalMap中设置的A的弱引用就失去了弱引用的作用，该键A对应的value也不会得到释放，直到此线程销毁。这样一来，如果是使用了线程池的话，当该线程复用时，很有可能会取得错误的值，造成业务逻辑混乱。 解决这个问题的方法就是当ThreadLocal不再使用时，一定要及时调用ThreadLocal的remove方法把已经存储的值清掉。另外，有一个例子展示了ThreadLocal的应用场景，现在贴过来。同样来自java doc。例子虽然很简单，但是我觉得很生动的展示了Threadlocal的一个应用场景，让人豁然开朗。 试想如果不采用ThreadLocal的话，我自己的做法应该会在创建的线程类里面增加一个字段，用来标明线程的id。但是这么做有两点问题： 第一，增加了字段，挺low。 第二，有很大的限制，你只能为自己实现的线程类里面加字段。但是往往有些线程不是我们自己定义的。 这个例子很好的说明了怎么实现一个线程变量。 12345678910111213141516import java.util.concurrent.atomic.AtomicInteger;public class ThreadId &#123; // Atomic integer containing the next thread ID to be assigned private static final AtomicInteger nextId = new AtomicInteger(0); // Thread local variable containing each thread's ID private static final ThreadLocal&lt;Integer&gt; threadId = new ThreadLocal&lt;Integer&gt;() &#123; @Override protected Integer initialValue() &#123; return nextId.getAndIncrement(); &#125; &#125;; // Returns the current thread's unique ID, assigning it if necessary public static int get() &#123; return threadId.get(); &#125;&#125;]]></content>
      <categories>
        <category>编程</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>多线程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[通过HashMap认识equals与hashcode]]></title>
    <url>%2F2016%2F04%2F28%2Fjava%E4%B8%AD%E7%9A%84equals%E4%B8%8Ehashcode%2F</url>
    <content type="text"><![CDATA[最近读了HashMap的源码，对HashCode与equals有了一定的了解，总结一下，顺便理一下HashMap中的核心算法。 什么是hashcode,hashcode的作用是什么hashcode并不是java中独有的。设想一下，如果让你设计一个算法，根据关键码去得到一个集合中的某个值或者这个关键码所在的位置。普通的做法就是挨个比较，高级一点的使用二分检索或者树形检索等算法。但是以上的检索算法都跟集合的长度N有关，当问题规模N很大时，这些检索的效率可能十分低下。 理想的情况是，根据关键码，我们就可以定位记录所在的位置，而不用去挨个进行比较。也就是说，在关键码与记录存放的位置之间做一种映射。这个映射的方法就是hash(哈希)函数，或者叫散列函数，也就是java中的hashCode()方法，他所返回的值就是hashcode，根据hashcode可以找到记录的位置。 按照散列的存储方式构造的存储结构叫做散列表。散列表中的一个位置称之为一个槽。 hashCode()方法存在于java.lang.Object类当中，任何类都可以继承修改这个方法。hashCode()方法返回调用它的实例的hashCode值，是个int值。 注：以下代码均来自jdk1.7 String中hashCode()方法的实现： 123456789101112public int hashCode() &#123; int h = hash; if (h == 0 &amp;&amp; value.length &gt; 0) &#123; char val[] = value; for (int i = 0; i &lt; value.length; i++) &#123; h = 31 * h + val[i]; &#125; hash = h; &#125; return h;&#125; 什么是equals(Object obj)方法equals(Object obj)方法同样来自Object类。在Object类中，他是这样实现的： 123public boolean equals(Object obj) &#123; return (this == obj);&#125; 也就是说，默认的equals(Object obj)方法直接将要比较的两个对象的内存地址进行了比较，一致则返回true。 这个方法主要用来实现两个对象间的比较，确认他们在逻辑上是否相等。我们同样可以实现自己的equals(Object obj)方法。 String中equals(Object obj)方法的实现： 123456789101112131415161718192021public boolean equals(Object anObject) &#123; if (this == anObject) &#123; return true; &#125; if (anObject instanceof String) &#123; String anotherString = (String) anObject; int n = value.length; if (n == anotherString.value.length) &#123; char v1[] = value; char v2[] = anotherString.value; int i = 0; while (n-- != 0) &#123; if (v1[i] != v2[i]) return false; i++; &#125; return true; &#125; &#125; return false;&#125; 在java中hashcode方法与equals方法的作用首先看一下HashMap中的put方法： 12345678910111213141516171819202122public V put(K key, V value) &#123; if (table == EMPTY_TABLE) &#123; inflateTable(threshold); &#125; if (key == null) return putForNullKey(value); int hash = hash(key);//得到hash值 int i = indexFor(hash, table.length);//找到槽 for (Entry&lt;K,V&gt; e = table[i]; e != null; e = e.next) &#123; Object k; if (e.hash == hash &amp;&amp; ((k = e.key) == key || key.equals(k))) &#123; V oldValue = e.value; e.value = value; e.recordAccess(this); return oldValue; &#125; &#125; modCount++; addEntry(hash, key, value, i); return null; &#125; 我们从 int hash = hash(key); 这一行看起，这行起才是put方法的核心。 首先 int hash = hash(key); key就是我们之前提到的关键码，我们看看HashMap中的这个hash方法做了些什么： 1234567891011121314final int hash(Object k) &#123; int h = hashSeed; if (0 != h &amp;&amp; k instanceof String) &#123; return sun.misc.Hashing.stringHash32((String) k); &#125; h ^= k.hashCode(); // This function ensures that hashCodes that differ only by // constant multiples at each bit position have a bounded // number of collisions (approximately 8 at default load factor). h ^= (h &gt;&gt;&gt; 20) ^ (h &gt;&gt;&gt; 12); return h ^ (h &gt;&gt;&gt; 7) ^ (h &gt;&gt;&gt; 4);&#125; 可以看到，这个方法里调用了key本身的hashCode方法，得到了key的hashcode，然后对该hashcode进行了一些移位操作，最终返回操作后的int值。返回的这个值就是HashMap要用到的hashcode值，通过他可以找到记录所在的位置。那么现在有一个问题：为什么要专门调用这个hash(Onject key)方法来对key的hashcode进行包装然后再使用呢？可以直接使用key的hashcode的呀，这样做看起来不是多此一举吗？ 其实这样做的目的是为下面的函数做准备的，我们看接下来要执行的代码： int i = indexFor(hash, table.length);找到所谓的槽，也就是记录存在的位置。 1234567/** * Returns index for hash code h. */static int indexFor(int h, int length) &#123; // assert Integer.bitCount(length) == 1 : &quot;length must be a non-zero power of 2&quot;; return h &amp; (length-1);&#125; 可以看到，indexFor(int h, int length)如何通过hashcode得到记录的位置。indexFor方法内部是一个取模运算，h是我们通过上面的hash方法得到的，length是散列表的长度。HashMap中的散列表是一个数组，通过取模运算能保证indexFor方法的返回值(记录的位置)一定在这个数组内，没有超过其长度。因为h往往是一个很大的数字(int可以表示40亿这么大的数字)，而散列表的初始长度是可以由我们指定的(默认是16),另一方面，就算给他这么大的数组，内存也是放不下的。所以取模运算是必须的。经过取模运算得到的才是真正的槽值。 回到上一个问题，为什么要专门调用这个hash(Onject key)方法来对key的hashcode进行包装然后再使用呢？而不是直接使用key的hashcode的？ 想明白这个问题，参考JDK 源码中 HashMap 的 hash 方法原理是什么？。我们上面也说了这样做的目的是为indexFor方法做准备的，总的来说就是为了让取模运算不会出现一种极端情况：大量的不同的h经过取模后返回同样的槽值。这样会带来严重的性能问题，也就是严重的冲突情况导致性能下降。关于冲突，看下文。 要理解接下来的代码，我们就需要知道哈希算法的另一个概念：冲突。 散列函数可能对于不相等的关键码计算出相同的hashcode，该现象称为冲突。怎么理解呢？ 比如我们有这样一个串abcd，我们给出这样一个散列函数：将每一个字符的ascii值加起来除以字符的个数，得到他们的平均值就是这个串的hashcode。那么，可以保证没有其他的串经过这样的算法得到相同的hashcode吗？也就是说，无限多的元素通过散列函数映射到有穷集合上，一定会产生冲突。这也是我们理解hashcode的一个重要的点：不同的对象(equals返回false)可以有相同的hashcode。 那么，产生冲突怎么办呢？产生冲突之后，不同的对象在散列表中找到了相同的位置，为了解决这个问题，我们将这个槽中的内容设计成一个链表，当产生冲突的时候，就将新的元素放到链表中，他看起来是这样的： 其中：A，B，C分别为三条记录，他们就是产生冲突的三条记录。1,2,3….为散列表的索引位置。 接下来的代码 for (Entry&lt;K,V&gt; e = table[i]; e != null; e = e.next)就容易理解了。找到记录所对应的槽之后，遍历这个链表直到找到与关键码相同的位置(可能之前已经有以这个关键码为key的value插入)。如果遍历完链表还没有找到这样的值，说明还不存在此关键码对应的记录，直接插入即可：addEntry(hash, key, value, i);. 那么，怎么判断两个关键码在逻辑上是否相同呢？ if (e.hash == hash &amp;&amp; ((k = e.key) == key || key.equals(k))) 可以看到，首先判断关键码的hashcode与链表记录的关键码hashcode是否相同：·e.hash == hash。为什么要加这样的判断？回头看看indexFor方法，经过取模运算后，不同的hashcode可以被散列在同一个槽中。通过这句代码可以将那些因为取模运算散列到同一个槽里的不同对象排除。 我们知道不同的对象(equals返回false)可以有相同的hashcode。相同的对象hashcode也必须相等吗？试想一下，如果两个对象相同，但是他们的hashcode不同，那么这两个对象很有可能被散列在不同的槽里，造成了同一个对象重复存储的问题。所以，我们又得出一个重要结论：相同的对象(equals返回true)hashcode一定相等。 e.hash == hash &amp;&amp; ((k = e.key) == key：这段代码首先判断hashcode是否相等，然后判断关键码是否相等。注意，是判断关键码是否相等，直接比较内存地址，如果满足以上条件，那么可以断定两个关键码相同，是我们要找的记录。 key.equals(k)：如果上述两个条件没有满足，并不能够断定这两个关键码相等，此刻要使用equals方法判断这两个关键码是否相同。如果相同，说明是我们要找的记录。 if (e.hash == hash &amp;&amp; ((k = e.key) == key || key.equals(k)))这句代码中其实包含了一种短路思想，|| 之前的判断如果生效，那么之后的key.equals(k)就不会再执行。很明显内存地址的比较要比equals方法高效的多。这也是Hashmap提高查找效率的一个重要手段。 至此，我们应该对equals和hashcode有了一个相对清晰的认识：hashcode提高了查找指定对象的效率。euqals定义了两个对象之间是否在逻辑上相同。hashcode只在HashMap，HashSet等这样使用了散列思想的地方用到，而equals在判断两个对象之间是否相同时需要用到，比如排序等。 总结通过上面的分析，我们知道了hashcode与equals的几个关键： 1.不同的对象(equals返回false)可以有相同的hashcode2.相同的对象(equals返回true)hashcode一定相等3.若重新定义了上面两种方法中的一种，那么另一种方法也需要重新定义（对1、2的遵守）关于如何重写equals方法与hashCode方法 equals与==“==” 比较的是两个对象的内存地址，是物理意义上的相等 equals比较的是两个对象逻辑意义上的相等，是逻辑意义上的相等 两个对象进行比较： == 返回true，则equals一定返回true； equals返回true，== 不一定返回true。]]></content>
      <categories>
        <category>编程</category>
      </categories>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[java中的类型转换]]></title>
    <url>%2F2016%2F04%2F28%2Fjava%E4%B8%AD%E7%9A%84%E7%B1%BB%E5%9E%8B%E8%BD%AC%E6%8D%A2%2F</url>
    <content type="text"><![CDATA[以前一直对java中的类型转换了解的不是很清楚，因为平时写代码有IDE的帮助，所以往往忽略这一块的内容，但往往就是这样的小知识点不清楚，很有可能造成很大的错误。所以在闲暇时间总结一下这些可能被遗忘的知识点。网上已经有很多相关的介绍文章了，现在来梳理一番： 基本类型 基本类型优先级 首先来看java中的基本类型有哪些： byte：byte数据类型是一个8位有符号二进制补码整数。 short：short数据类型为16位有符号二进制补码整数。 int：int数据类型是一个32位有符号二进制补码整数 long: long数据类型是一个64位二进制补码整数 float: float数据类型是单精度、32位、符合IEEE 754标准的浮点数 boolean: boolean数据类型只有两个可能的值：true和false double: double数据类型是双精度、64位、符合IEEE 754标准的浮点数； char: char数据类型是一个16位的Unicode字符 基本类型优先级由低到高排序： (byte short char) int long float double 其中，byte short char 平级 转换规则 1.有多种数据类型混合计算的时候，低优先级类型自动提升为优先级最大的那个类型再来继续计算 3.高优先级类型转换为低优先级类型时，需要强制类型转换，并且有可能丢失精度或溢出。 2.byte short char 他们三者在计算时，首先会转换为int类型 3.由于byte short char三者平级，他们之间互相转换时需进行强制类型转换。 4.boolean不能与其他类型转换 类类型类类型之间的转换有以下几个规则： 1.当源类型与目标类型不存在父子关系时，转换无法进行，编译时会出现错误。包括两个类为继承同一个父类这种情况，也是不可以进行转换的。 2.源类型是子类，目标类型是父类时，不必强制转换。只是屏蔽了一些子类才有的功能。 3.源类型是父类，目标类型是子类时，要分两种情况：第一，源类型指向的对象就是父类类型。此时不能进行强制转换，编译器可以通过，但运行时会报类型转换错误。第二，源类型指向的对象是子类类型。此时可以进行强制转换，还原子类。 说的比较拗口，用代码来解释吧。 12345678910111213141516171819202122232425262728public class Test &#123; class Father &#123;&#125; class Son extends Father&#123;&#125; class Daughter extends Father &#123;&#125; @org.junit.Test public void test()&#123; Father fatherApp; Son sonApp; Daughter daughterApp; Father fatherIns=new Father(); Son sonIns=new Son(); Daughter daughterIns=new Daughter(); //目标类型为父类，源类型为子类，自动转换 fatherApp=sonIns; //源类型为父类，目标类型为子类，且源类型指向父类对象,运行时报错。 sonApp=(Son) fatherIns; //源类型为父类，目标类型为子类，且源类型指向子类对象，还原子类 sonApp=(Son) fatherApp; //目标类型与源类型不存在父子关系，编译无法通过 daughterApp=sonIns; &#125; &#125; 参考Java 7之基础类型第1篇 - Java数据类型 The Java™ Tutorials Java中的类型转换]]></content>
      <categories>
        <category>编程</category>
      </categories>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ANT编译java工程经jdk路径的设置]]></title>
    <url>%2F2016%2F04%2F25%2Fant%E7%BC%96%E8%AF%91java%E5%B7%A5%E7%A8%8Bjdk%E8%B7%AF%E5%BE%84%E7%9A%84%E8%AE%BE%E7%BD%AE%2F</url>
    <content type="text"><![CDATA[今天工作的时候涉及到使用ant对项目进行编译，打包。此前只知道ant是一个构建工具（当然，现在也是），也基本上没有接触过。但是build.xml是从仓库下载的已经配置好的文件。本来想着只要在eclipse轻轻一点Ant Build 就万事大吉，但是这个打包却折腾了我两个小时。 打包过程中总是报： 1234[javac] 警告: [options] 未与 -source 1.5 一起设置引导类路径[javac] E:\doc\oscartools\driver\oscarJavaDriver\jdbc\V1.0\build\com\oscar\Driver.java:50: 错误: com.oscar.Driver不是抽象的, 并且未覆盖java.sql.Driver中的抽象方法getParentLogger()[javac] public class Driver implements java.sql.Driver &#123;.... 类似这样的一堆错误。 没有过多的思考，百度之…出现了一堆没用的资料和争论。80%的时间花在了看这些人扯淡上面（或许正真的大神并不关注这些问题）。 严重的浪费时间和影响心情，遂放弃。 静下来想想，工程的java build path使用1.5，java compiler 使用1.5，没什么问题啊。。。 后来灵光一现，build.xml中的javac难道与java home有关（原谅我现在才想到）？java home使用jdk为1.7，遂改为1.5。 重启eclipse，悲催，eclipse要求jdk必须大于等于1.7。 等等，如果不同的工程依赖不同的jdk的话，修改java home并不是一个明智的解决方案，一定可以针对某个工程修改它所依赖的javac，谷歌之 ‘ant set java_home in build.xml’ 果然，stackoverflow拯救了我，只需要在build.xml文件中javac标签下添加 12executable="C:\Program Files\Java\jdk1.5.0_22/bin/javac"fork="yes" Build Successfull. 这次的总结并不是为了学习ant(有学习Gradle的计划)，只是从这次解决问题的过程中，学会了： 1.不要用百度 2.先思考问题原因，再寻找解决方案 3.学习英语，尽量用英文搜索 参考Change JDK for running task from within build xml]]></content>
      <categories>
        <category>工具</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>ant</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[java中的编码问题]]></title>
    <url>%2F2016%2F04%2F20%2Fjava%E4%B8%AD%E7%9A%84%E7%BC%96%E7%A0%81%E9%97%AE%E9%A2%98%2F</url>
    <content type="text"><![CDATA[最近在工作过程中总是被编码困扰，出现了很多意想不到的情况。故上网查看资料，总结一番。 2016/9/11 更新：今天在网上看到一篇讲解有关编码的文章 Java中字符编码和字符串所占字节数,个人认为作者写的十分清晰明了。把文章中的例子看懂的话再遇到乱码的情况解决起来应该不难！ 编码什么是编码？程序员应该都知道计算机能够识别的只是1和0，我们看到的文字、图片、视频等在计算机的 世界里都是以二进制的形式存在的。包括你的硬盘或者网络上传输的字节序列，都是无数个0和1组成的。英文字母，数字，汉字等都是字符。不同字符对应二进制数的规则，也就是说不同的字符翻译为不同的0、1组合，就是字符的编码。这个过程的逆过程，就是解码。 Ascii编码 标准的ASCII编码使用的是7（2^7 = 128）位二进制数来表示所有的大小写字母、数字和标点符号已经一些特殊的控制字符，最前面的一位统一规定为0。(一个字节8位)。缺点是只能显示128个字符，显示的字符十分有限，比如对中文就无能为力了。 GB2312 GB2312编码适用于汉字处理、汉字通信等系统之间的信息交换，通行于中国大陆；新加坡等地也采用此编码。中国大陆几乎所有的中文系统和国际化的软件都支持GB 2312。 UTF-8 事实上世界上那么多国家，存在更多的字符是前面的编码所不能表示的。不同国家的不同编码之间也不能够兼容。所以就需要一套通用的编码能够表示世界上所有的符号，这就是Unicode编码事实上，Unicode也是一套字符集。 字符集简单说就是字符的集合。它规定了每个字符对应的二进制编码。比如Unicode是一个很大的集合，现在的规模可以容纳100多万个符号。每个符号的编码都不一样，比如，U+0639表示阿拉伯字母Ain，U+0041表示英语的大写字母A，U+4E25表示汉字”严”。需要注意的是，Unicode只是一个符号集，它只规定了符号的二进制代码，却没有规定这个二进制代码应该如何存储。那既然字符集中的每一个字符都有一个自己的序号，直接把序号作为存储内容就好了。为什么还要多此一举通过字符编码把序号转换成另外一种存储格式呢？ 这是因为： 比如，汉字”严”的unicode是十六进制数4E25，转换成二进制数足足有15位（100111000100101），也就是说这个符号的表示至少需要2个字节。表示其他更大的符号，可能需要3个字节或者4个字节，甚至更多。这里就有两个严重的问题，第一个问题是，如何才能区别Unicode和ASCII？计算机怎么知道三个字节表示一个符号，而不是分别表示三个符号呢？第二个问题是，我们已经知道，英文字母只用一个字节表示就够了，如果Unicode统一规定，每个符号用三个或四个字节表示，那么每个英文字母前都必然有二到三个字节是0，这对于存储来说是极大的浪费，文本文件的大小会因此大出二三倍，这是无法接受的。 字符编码就是用来解决以上所说的如何存储字符对应二进制编码问题的。 UTF-8就是在互联网上使用最广的一种Unicode的实现方式。即，UTF-8就是对应Unicode字符集的一种字符编码。UTF-8最大的一个特点，就是它是一种变长的编码方式。它可以使用1~4个字节表示一个符号，根据不同的符号而变化字节长度。 UTF-8的编码规则很简单，只有两条： 1）对于单字节的符号，字节的第一位设为0，后面7位为这个符号的unicode码。因此对于英语字母，UTF-8编码和ASCII码是相同的。 2）对于n字节的符号（n&gt;1），第一个字节的前n位都设为1，第n+1位设为0，后面字节的前两位一律设为10。剩下的没有提及的二进制位，全部为这个符号的unicode码。 下面以utf-8为例，看下编码的过程。 根据上面的转换表，理解UTF-8的转换编码规则就变得非常简单了：第一个字节的第一位如果为0，则表示这个字节单独就是一个字符;如果为1，连续多少个1就表示该字符占有多少个字节。 以汉字”严”为例，演示如何实现UTF-8编码。 已知”严”的unicode是4E25（100111000100101），根据上表，可以发现4E25处在第三行的范围内（0000 0800-0000 FFFF），因此”严”的UTF-8编码需要三个字节，即格式是”1110xxxx 10xxxxxx 10xxxxxx”。然后，从”严”的最后一个二进制位开始，依次从后向前填入格式中的x，多出的位补0。这样就得到了，”严”的UTF-8编码是”11100100 10111000 10100101″，转换成十六进制就是E4B8A5。 还有一些编码就不再一一介绍了，具体用到的话可以百度或谷歌。 java 中的编码 class文件与内存中的编码 上图说明了java编码转换的过程 首先，java源文件是可以用很多种编码保存的。在使用javac编译源文件时，如果没有指定源文件的编码，javac会默认源文件是以系统默认编码编写的，（Windows通常为GBK），javac使用该编码格式对源文件进行解码并将其中的字符以UTF-8输出到Class文件中。如果源文件并不是已系统默认编码保存的，那么javac读进来的时候就会出现乱码问题。 java程序在运行时，jvm内存中的所有字符的表现形式都是UTF-16。如果需要用户输入信息，则会采用file.encoding编码格式对用户输入的信息进行编码同时转换为Unicode编码格式保存到内存中。程序运行后，将产生的结果再转化为file.encoding格式返回给操作系统并输出到界面去。 总结:Java语言中 不同字符集编码的转换 都是通过Unicode编码作为中介来完成的。 InputStreamReader与OutputStreamWriter Reader 类是 Java 的 I/O 中读字符的父类，而 InputStream 类是读字节的父类，InputStreamReader 类就是关联字节到字符的桥梁，它负责在 I/O 过程中处理读取字节到字符的转换，而具体字节到字符的解码实现它由 StreamDecoder 去实现，在 StreamDecoder 解码过程中必须由用户指定 Charset 编码格式。值得注意的是如果你没有指定 Charset，将使用本地环境中的默认字符集，例如在中文环境中将使用 GBK 编码。 写的情况也是类似，字符的父类是 Writer，字节的父类是 OutputStream，通过 OutputStreamWriter 转换字符到字节。同样 StreamEncoder 类负责将字符编码成字节，编码格式和默认编码规则与解码是一致的。 12345678910111213141516171819202122232425String file = "c:/stream.txt"; String charset = "UTF-8"; // 写字符换转成字节流FileOutputStream outputStream = new FileOutputStream(file); OutputStreamWriter writer = new OutputStreamWriter( outputStream, charset); try &#123; writer.write("这是要保存的中文字符"); &#125; finally &#123; writer.close(); &#125; // 读取字节转换成字符FileInputStream inputStream = new FileInputStream(file); InputStreamReader reader = new InputStreamReader( inputStream, charset); StringBuffer buffer = new StringBuffer(); char[] buf = new char[64]; int count = 0; try &#123; while ((count = reader.read(buf)) != -1) &#123; buffer.append(buf, 0, count); &#125; &#125; finally &#123; reader.close(); &#125; String与byte[] 利用String类的getBytes()方法返回不同字符集的字节流数据，其本质是从Unicode字符集编码向其它字符集编码转换的过程。 123456789String str="中"; // 将内存中的str(utf-16)转换为系统默认编码的字节数组byte[] bytes1 = str.getBytes(); // 将内存中的str(utf-16)转换为ISO-8859-1编码的字节数组 byte[] bytes2 = str.getBytes("ISO-8859-1");// 正常显示中 System.out.println(new String(bytes1)); // 输出"?" System.out.println(new String(bytes2)); 利用String类的构造方法根据不同字符集的字节流数据产生一个字符串对象，其本质是从其它字符集编码向Unicode字符集编码转换的过程。 123456789101112131415// GBK中0xD6 0xD0表示“中”，0x31表示字符“1”byte[] bytes = &#123;(byte)0xD6, (byte)0xD0, (byte)0x31&#125;; // 将bytes按照系统默认编码格式(GBK)解码,产生Unicode字符String str1 = new String(bytes); // 将bytes按照ISO-8859-1解码，产生Unicode字符String str2= new String(bytes,"ISO-8859-1"); // 中1 将Unicode字符转换为GBK编码输出System.out.println(str1); /* *在ISO-8859-1编码方式中没有对应0xD6和0xD0 *的字符，所以前两个字符会产生两个问号，由于0x31*在ISO-8859-1编码中对应字符“1” *（ISO-8859-1也兼容ASCII），所以此语句得到str的值是“??1”。 */ System.out.println(str2); // ??1 CharSet 从jdk1.4开始，java提供了Charset 类，这个类中提供 encode 与 decode 分别对应 char[] 到 byte[] 的编码和 byte[] 到 char[] 的解码。 123Charset charset = Charset.forName("UTF-8"); ByteBuffer byteBuffer = charset.encode(string); CharBuffer charBuffer = charset.decode(byteBuffer); 延伸 byte字节数据类型是一个8位有符号二进制补码整数。它具有-128最小值和127的最大值。 无论是硬盘上数据的存放还是数据在网络上传输，其中的内容都是二进制数据。当你想把一些文本文件或者视频保存时，这些数据会转化为二进制序列存放于你的硬盘。同样，当你使用网络聊天，发语音和图片，程序都会将这些数据转化为（编码）二进制序列进行传输。在java中，这些二进制序列以两个字节为单位，使用Unicode字符集形成byte数组。程序处理的时候再把这些byte数组进行合适的处理（解码）呈现到屏幕上。 有关byte与其他数据类型的转换不再多写，用到的时候再从网上查资料吧。只要知道其中的原理，soeasy. 参考十分钟搞清字符集和字符编码 字符编码笔记：ASCII，Unicode和UTF-8 java编码转换过程 Java 7之基础 - 编码与解码 深入分析 Java 中的中文编码问题]]></content>
      <categories>
        <category>编程</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>编码</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[关于抽象类和接口]]></title>
    <url>%2F2016%2F04%2F15%2F%E5%85%B3%E4%BA%8E%E6%8A%BD%E8%B1%A1%E7%B1%BB%E5%92%8C%E6%8E%A5%E5%8F%A3%2F</url>
    <content type="text"><![CDATA[抽象类： 使用了关键词abstract声明的类叫作“抽象类”。如果一个类里包含了一个或多个抽象方法，类就必须指定成abstract（抽象）. 抽象类不能被实例化 如果一个类继承了抽象类，则该类必须实现所继承抽象类的所有抽象方法，否则该类也必须声明为abstract类 抽象方法必须为public或者protected，缺省情况是public。若声明为private，则子类无法实现该方法。 可以有抽象的构造方法，但该方法不能被用来实例化对象，只能由继承该类的子类通过super()调用。 不可以有抽象的静态方法。因为在java中，静态方法是不可以被继承的，与抽象类的定义矛盾。 抽象类不一定必须包含抽象方法，但包含抽象方法的类一定是抽象类。 子类中的抽象方法不能与父类的抽象方法同名 其余情况抽象类与普通类相同。 接口： 接口（英文：Interface），在JAVA编程语言中是一个抽象类型，是抽象方法的集合，接口通常以interface来声明。一个类通过继承接口的方式，从而来继承接口的抽象方法. 接口中所有的方法都必须为抽象方法，方法会被隐式地指定为public abstract方法且只能是public abstract方法。 接口中的变量被隐式地指定为public static final变量，并且只能是public static final变量。 接口之间也可以继承，子接口可以继承父接口中的常量和抽象方法并添加新的抽象方法。 接口中没有构造方法，不能被实例化。 如果一个非抽象类遵循了某个接口，就必须实现该接口中的所有方法。对于遵循某个接口的抽象类，可以不实现该接口中的抽象方法。 接口中不能含有静态代码块以及静态方法。 在实现多接口的时候一定要避免方法名的重复。 区别与联系： 语义 一个类只能继承一个抽象类，但可以实现多个接口。 抽象类可以提供成员方法的实现细节，而接口中只能存在public abstract 方法 设计思想 抽象类是对一种事物的抽象，即对类抽象，而接口是对行为的抽象。 抽象类可以看作对一群个体的抽象，二接口只是某个个体所具有的功能。抽象类是对整个类整体进行抽象，包括属性，行为，但是接口却是对类局部(行为)进行抽象。 对于抽象类，如果需要添加新的方法，可以直接在抽象类中添加具体的实现，子类可以不进行变更；而对于接口则不行，如果接口进行了变更，则所有实现这个接口的类都必须进行相应的改动。 抽象类是从子类中发现公共部分然后泛化成抽象类，子类继承该父类即可，但是接口不同，实现它的子类可以不存在任何关系。 抽象类所体现的是一种继承关系，要想使得继承关系合理，父类和派生类之间必须存在”is-a” 关系，即父类和派生类在概念本质上应该是相同的。对于接口则不然，并不要求接口的实现者和接口定义在概念本质上是一致的， 仅仅是实现了接口定义的契约而已。 抽象类是自底向上抽象而来的，接口是自顶向下设计出来的。 对于抽象类而言，它是自下而上来设计的，我们要先知道子类才能抽象出父类，而接口则不同，它根本就不需要知道子类的存在，只需要定义一个规则即可，至于什么子类、什么时候怎么实现它一概不知。比如我们只有一个猫类在这里，如果你这是就抽象成一个动物类，是不是设计有点儿过度？我们起码要有两个动物类，猫、狗在这里，我们在抽象他们的共同点形成动物抽象类吧！所以说抽象类往往都是通过重构而来的！但是接口就不同，比如说飞，我们根本就不知道会有什么东西来实现这个飞接口，怎么实现也不得而知，我们要做的就是事前定义好飞的行为接口。 示例 门都有open( )和close( )两个动作，此时我们可以定义通过抽象类和接口来定义这个抽象概念： 1234abstract class Door &#123; public abstract void open(); public abstract void close();&#125; 或 1234interface Door &#123; public abstract void open(); public abstract void close();&#125; 但是现在如果我们需要门具有报警alarm( )的功能，那么该如何实现？下面提供两种思路： 1.将这三个功能都放在抽象类里面，但是这样一来所有继承于这个抽象类的子类都具备了报警功能，但是有的门并不一定具备报警功能； 2.将这三个功能都放在接口里面，需要用到报警功能的类就需要实现这个接口中的open()和close(),也许这个类根本就不具备open( )和close( )这两个功能，比如火灾报警器。 从这里可以看出， Door的open() ,close()和alarm()根本就属于两个不同范畴内的行为，open()和close() 属于门本身固有的行为特性，而alarm()属于延伸的附加行为。因此最好的解决办法是单独将报警设计为一个接口，包含alarm()行为,Door设计为单独的一个抽象类，包含open和close两种行为。再设计一个报警门继承Door类和实现Alarm接口。 123456789101112131415161718interface Alram &#123; void alarm();&#125;abstract class Door &#123; void open(); void close();&#125;class AlarmDoor extends Door implements Alarm &#123; void oepn() &#123; //.... &#125; void close() &#123; //.... &#125; void alarm() &#123; //.... &#125;&#125; 对继承的思考2016/10/27更新 写代码的过程中发现java的继承经常被滥用。思考一下解决方法… 1.当子类和父类属于同一个种类时使用继承，而不是拥有相同的功能。 比如：飞机能飞，鸟也能飞。但是这两种东西不应该归为一类。飞只是个功能，可以作为一个接口。 鸟却可以是大雁的父类，他们从本质上是一种东西 2.继承可用于模板方法模式。即能够从很多类中抽象出同一个流程，把这个流程作为一个模板写在父类当中。设置好钩子供子类实现。 3.既不属于同一种类又没有抽象出模板，但是多个类之间有相同的代码冗余。考虑委托，写一个通用的Utility类，吧冗余的代码放到utility类当中去，把需要的参数传进去。避免滥用继承。比如： 写web服务器时，有很多controller，如果这些controller关联不大，没必要继承同一个父类。但是都有一个验证身份的verify方法，考虑把这个verify方法写到一个Utility类中，所有的controller去调用它。 资料: Java 中的接口有什么作用？ java提高篇（四）—–抽象类与接口]]></content>
      <categories>
        <category>编程</category>
      </categories>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[他可是科比布莱恩特]]></title>
    <url>%2F2016%2F04%2F14%2F%E4%BB%96%E5%8F%AF%E6%98%AF%E7%A7%91%E6%AF%94%C2%B7%E5%B8%83%E8%8E%B1%E6%81%A9%E7%89%B9!%2F</url>
    <content type="text"><![CDATA[what can i say, Mamba out！]]></content>
      <categories>
        <category>生活</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Junit的使用]]></title>
    <url>%2F2016%2F04%2F12%2Fjunit%E4%BD%BF%E7%94%A8%2F</url>
    <content type="text"><![CDATA[Junit是一个Java语言的单元测试框架。利用这个框架编写测试用例，junit会按照规则自动对你要测试的代码进行测试，并给出测试结果。 资料 Unit Testing with JUnit - Tutorial JUnit Tutorial 走进java测试利器-junit]]></content>
      <categories>
        <category>工具</category>
      </categories>
      <tags>
        <tag>junit</tag>
        <tag>测试</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[sphinx安装问题]]></title>
    <url>%2F2016%2F03%2F30%2Fsphinx%E5%AE%89%E8%A3%85%E9%97%AE%E9%A2%98%2F</url>
    <content type="text"><![CDATA[领导给安排的任务是修改数据库的帮助手册。从仓库下载了代码以后就一直在倒腾环境的安装。生成文档的工具是Python 环境下的Sphinx。就是这个Sphinx,昨天倒腾了一天都没装上，郁闷。 一开始安装Python3，到是一路顺畅，没有什么问题。但是在使用Sphinx的时候就报错了。原因是之前文档的创建环境是 Python2，Python3与Python2是不兼容的，在编码问题上报错。 遂改之，卸载Python3，安装Python2.问题来了。 安装完Python2之后，使用 easy_install sphinx指令来安装sphinx。可是死活装不上，换源和使用pip都不行，苦逼。报这样一个错误： UnicodeEncodeError: ‘ascii’ codec can’t encode characters in position 4-5: ordi al not in range(128) 意思就是Python执行环境的默认编码是ascii码，Python调用ascii编码解码程序去处理字符流，当字符流不属于ascii范围内，就会抛出异常（ordinal not in range(128)）。 看了一下报错的位置，都是在安装sphinx之前安装的所需的依赖出了问题，都是一堆.py文件。某些函数读取字符流的时候出了问题。这可咋整。。。我也没法知道他读的流是啥啊。 后来想到了一个解决办法，那就是修改Python编码环境为UTF-8，问题可能就迎刃而解了。 首先所有修改的动作都是要创建一个叫 sitecustomize.py的文件，为什么要创建这个文件呢，是因为python在启动的时候会去load的这个文件，所以你如果要修改一些启动的变量就可以把操作写在这个文件。 修改默认字符编码的代码很简单就2行： 12345# sitecustomize.py # this file can be anywhere in your Python path,# but it usually goes in $&#123;pythondir&#125;/lib/site-packages/import syssys.setdefaultencoding(&apos;utf-8&apos;) 写完这个文件放哪里呢？ windows :存放在你python的安装的目录Lib\site-packages(比如C:\Python27\Lib\site-packages)里。 ok,现在再次运行 easy_install sphinx ，可以通过安装了！ ps:Python3 已经解决了这个问题，所以在Python3 环境下不会出现这个错误。 参考 解决Python2.7的UnicodeEncodeError: ‘ascii’ codec can’t encode异常错误 永久修改python默认的字符编码为utf-8]]></content>
      <categories>
        <category>工具</category>
      </categories>
      <tags>
        <tag>编码</tag>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[代码规范]]></title>
    <url>%2F2016%2F03%2F29%2F%E4%BB%A3%E7%A0%81%E6%A0%BC%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[最近写的代码提上去让领导评审，回来给我的建议都是逻辑虽然正确，但代码十分凌乱，命名不规范，看着很不舒服。 所以决定总结一些规范，以后写代码要注意了~ 命名 变量，方法，类命名要表义，严格禁止使用 name1, name2 等命名 避免使用数字，但可用 2 代替 to，用 4 代替 for 等，如 go2Clean 方法 方法名第一个单词小写，以后每个单词首字母大写。 类、接口 所有单词首字母都大写。使用能确切反应该类、接口含义、功能等的词。一般采用名词 字段、常量 成员变量、局部变量第一个单词小写，如 userName, instance。 常量全部大写，在词与词之前用下划线连接，如 MAX_NUMBER。 代码中禁止使用硬编码，把一些数字或字符串定义成常用量。 注释 成员变量注释 12345678/** 成员变量注释 */protected Object mObject0;/** * 对于注释多于一行的，采用这种方式来 * 定义该变量 */private Object mObject4; 方法描述 12345678/** * 方法描述... * * @param param1 参数1描述... * @param param2 参数2描述... * @param paramXX 参数XX描述... （注意：请将参数、描述都对齐） */ public void doSomething(int param1, float param2, String paramXX) &#123;&#125; 3.方法内部注释 可以使用 /注释/ 进行注释，也可以使用 //注释 进行注释，最好所有代码保持一致。但多行连续注释不应该使用后者。 1234if (a == 2) &#123; return TRUE; /* special case */&#125; else &#123; return isprime(a); /* works only for odd a */&#125; 换行、空格 换行 当代码过长造成阅读困难的时候，就应该考虑代码换行。 有这么几个原则： 1.在逗号之后换行 2.在操作符之前换行 3.考虑在表达式的外层就换行，而不是内层 4.新一行的开头应该与前一行的同一级代码对齐 5.如果以上几个原则使得换行后的表达式过于靠右，那么直接在新行之前插入8个空格代替上面的规则。 示例 123456function(longExpression1, longExpression2, longExpression3, longExpression4, longExpression5);var = function1(longExpression1, function2(longExpression2, longExpression3)); 在表达式外层换行： 12345longName1 = longName2 * (longName3 + longName4 - longName5) + 4 * longname6; // PREFERlongName1 = longName2 * (longName3 + longName4 - longName5) + 4 * longname6; // AVOID 插入8个空格的情况 12345678910111213//INDENT 8 SPACES TO AVOID VERY DEEP INDENTSprivate static synchronized horkingLongMethodName(int anArg, Object anotherArg, String yetAnotherArg, Object andStillAnother) &#123; ...&#125; //条件表达式8空格原则if ((condition1 &amp;&amp; condition2) || (condition3 &amp;&amp; condition4) ||!(condition5 &amp;&amp; condition6)) &#123; doSomethingAboutIt();&#125; 空格 1.{内的语句，之前插入4个空格。包括函数，if语句，for循环，while循环等。 操作符左右，大括号{}左右，等于号左右都要有一个空格的间距。f 参考JavaCode Conventions]]></content>
      <categories>
        <category>编程</category>
      </categories>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[常用快捷键总结]]></title>
    <url>%2F2016%2F03%2F22%2F%E5%B8%B8%E7%94%A8%E5%BF%AB%E6%8D%B7%E9%94%AE%E6%80%BB%E7%BB%93%2F</url>
    <content type="text"><![CDATA[ECLIPSE: 查看代码 Ctrl+O 搜索当前类变量及方法 Ctrl+H 打开搜索对话框 Ctrl+Shift+G 搜索选中变量或方法的引用 Ctrl+D 删除当前行 Ctrl+Shift+F 格式化代码 F4 查看当前类继承结构 Ctrl+Shift+R 搜索类，文件等资源 Ctrl+Shift+O 倒包 Ctrl + 1 ：快速修复 Ctrl + Shift + /(小键盘) ：收起左侧导航树或代码(依据当前焦点而定) Ctrl + *(小键盘) ：展开代码 Shift + Enter ：在当前行下方插入一行空行 Alt + 向上键 ：当前行与上方行交换 Alt + 向下键 ：当前行与下方行交换 Shift + Alt + R : 重命名 Shift + Alt + L (表达式末尾)：为表达式赋值为局部变量 Shift + 向上键/向下键 : 选中此行 Shift + Alt + M : 提取选中代码为一个方法 Ctrl + . : 下一个错误 调试 F5 进入方法内部 F6 顺序执行到下一行 F7 跳出方法，返回调用处 F8 执行到下一个断点 Ctrl+Shift+I 查看选中表达式的值 Ctrl+ALT+鼠标左键点击 调试进入左键点击的方法 Ctrl+R 运行到光标所在的行 WINDOWS: ALT+TAB 切换窗口 ALT+F4 关闭窗口 Ctrl+L 锁定 Windows+D 显示桌面 Windows+E 打开我的电脑 Windows+R 打开运行对话框 Ctrl+Z 撤销上一步操作 Ctrl+Y 恢复撤销的操作 Ctrl+Shift+Esc 打开任务管理器 按Shift键同时右击文件夹，点击选项在此处打开命令窗口，可直接打开该路径下的cmd窗口 Chorme: Ctrl+N 打开新窗口 Ctrl+Tab 切换标签页 Ctrl+L 选中网址栏 Ctrl+T 新建标签页 Ctrl+Shift+T 重新打开上次关闭的标签页 Home 转至网页顶部 Ctrl+W 关闭标签页]]></content>
      <categories>
        <category>工具</category>
      </categories>
      <tags>
        <tag>快捷键</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Markdown]]></title>
    <url>%2F2016%2F03%2F03%2Fmarkdown%2F</url>
    <content type="text"><![CDATA[Markdown 是一种可以使用普通文本编辑器编写的标记语言，通过简单的标记语法，它可以使普通文本内容具有一定的格式。 即：Markdown 就是一种类似于Html的标记语言，比Html更简单，通过转换之后使普通文本内容具有一定的格式。 常用语法 makedown 语法 代码```public void main(String args[]){ System.out.print(“Hello World”);}``` Use the `printf()` function. 标题# 标题1 ## 标题2 ### 标题3 #### 标题4 ##### 标题5 ###### 标题6 列表 有序列表1 有序列表2 - 无序列表1 - 无序列表2 * 无序列表3 + 无序列表4 链接[谷歌](http://www.google.com) 这是一个 [例子](http://google.com/ “google”) 行内链接. 这是一个 [例子] [id] 参考链接. [id]: http://google.com/ “google” 自动链接 1&lt;http://example.com/&gt; 图片行内链接：![](http://img3.3lian.com/2013/s1/65/d/104.jpg) 参考链接：![img] [img]:http://img3.3lian.com/2013/s1/65/d/104.jpg 指定宽高：需用html标记 1&lt;img src=&quot;http://img3.3lian.com/2013/s1/65/d/104.jpg&quot; width=&quot;200&quot; height=&quot;128&quot; /&gt; 引用> 引用 >&gt; 嵌套引用 粗体 斜体*这里是斜体* **这里是粗体** ***这里是粗斜体*** 表格dog | bird | cat —-|——|—- foo | foo | foo bar | bar | bar baz | baz | baz 转义 利用 \ 进行转义 \\ 反斜线 \` 反引号 \* 星号 \_ 底线 \{} 花括号 \[] 方括号 \() 括弧 \# 井字号 \+ 加号 \- 减号 \. 英文句点 \! 惊叹号 删除线~~删除这里的内容~~ 效果makedown 语法 代码123public void main(String args[])&#123; System.out.print(&quot;Hello World&quot;);&#125; Use the printf() function. 标题标题1标题2标题3标题4标题5标题6 列表 有序列表1 有序列表2 无序列表1 无序列表2 无序列表3 无序列表4 链接谷歌 这是一个 例子 行内链接. 这是一个 例子 参考链接. 自动链接http://example.com/ 图片行内链接： 参考链接： 指定宽高：需用html标记 引用 引用 嵌套引用 粗体 斜体这里是斜体 这里是粗体 这里是粗斜体 表格 dog bird cat foo foo foo bar bar bar baz baz baz 转义 利用 \ 进行转义 \ 反斜线 ` 反引号 * 星号 _ 底线 {} 花括号 [] 方括号 () 括弧 # 井字号 + 加号 - 减号 . 英文句点 ! 惊叹号 删除线删除这里的内容 一些参考Markdown 语法说明 (简体中文版) Markdown 维基百科]]></content>
      <categories>
        <category>工具</category>
      </categories>
      <tags>
        <tag>markdown</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[notify 问题]]></title>
    <url>%2F2015%2F12%2F21%2Fnotify%E9%97%AE%E9%A2%98%2F</url>
    <content type="text"><![CDATA[今天遇到了这么个情况：有线程若干，我需要他们按顺序执行。代码大概长这样： 12345678910111213141516171819202122232425262728293031323334353637class SyncTag &#123; public int threadNO; public SyncTag() &#123; threadNO = 0; &#125;&#125;class ThreadA extend Thread&#123; SyncTag syncTag; int scriptNO; ThreadA(SyncTag syncTag,int scriptNO)&#123; this.syncTag=syncTag; this.scriptNO=scriptNO; &#125; public void Run()&#123; synchronized (syncTag) &#123; if (syncTag.threadNO != scriptNO) &#123; try &#123; syncTag.wait(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; dosomething(); syncTag.threadNO++; syncTag.notifyAll(); &#125; &#125;&#125;public class Test&#123; public static void main(String args[])&#123; SyncTag syncTag=new SyncTag(); for(int i=0;i&lt;10;++i)&#123; ThreadA t=new ThreadA(syncTag,i); t.start(); &#125; &#125;&#125; 结果却不是像我预料的那样。这十个线程的执行顺序竟然是混乱的，无序的。虽然他们是之间实现了串行执行。研究一番，发现是 notify 与notifyAll 在捣鬼。当调用 同步对象（syncTag）的notify方法 的时候，唤醒了N多等待资源线程中的一个（即 调用了同步对象的wait 方法而阻塞的那些线程）；至于唤醒哪个线程，是不确定的。其他的线程仍然在阻塞，需要被notify 或者 notifyAll 唤醒。 当调用同步对象（syncTag）的notifyAll方法 的时候，所有进入wait 方法而阻塞的那些线程都被唤醒了。他们中的一个会抢到同步锁（syncTag），继续执行下去，剩下的没有获得锁的线程则继续等待。与上面情况不同的是，这些等待的线层不再需要notify或者notifyAll去唤醒了，一旦拥有锁的线程放弃锁，这些线程就一拥而上，去抢占锁，抢到的运行，没抢到的老实等着。 这就是notify 与 notifyAll两者的区别. 那么我遇到的问题是否是因为使用了notifyAll 的原因呢？其实并不是。即使我改成notify ，这些线程也没有按照顺序去运行。原因在于：当某个先执行的线程（线程0）调用了notify 或者notifyAll 之后，某个线程被选中了。但是这个选中的线程并不一定是线程1.因为唤醒某个线程之后，他并不会再去检查是否符合syncTag.threadNO == scriptNO 这个条件，只要被唤醒了，又恰好拥有了锁。那他就执行下去了。我们只需要让他在执行之前再检查一下是否 符合syncTag.threadNO == scriptNO 这个条件，如果不符合，就继续wait.符合则执行。很简单，将 1234567if (syncTag.threadNO != scriptNO) &#123; try &#123; syncTag.wait(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125;&#125; 这部分代码 改为： 1234567while (syncTag.threadNO != scriptNO) &#123; try &#123; syncTag.wait(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125;&#125; 这个问题就解决了。 所以，应该记住这样一个原则：永远在循环（loop）里调用 wait 和 notify，不是在 If 语句。 延伸：假设这样一种情况：我们按照上面的方法把代码改了，但同时把下面的 notifyAll 改为 notify.问题又出现了：设想一下，如果线程0执行完毕之后调用syncTag.notify（），唤醒某个线程（线程3），但是在这个线程中恰好不满足 syncTag.threadNO == scriptNO这个条件。那么这个线程（线程3）会继续wait. 这个时候，所有的线程都在 wait,但并没有一个线程在运行，也没有其他线程能够调用 notify或者notifyAll来唤醒他们中的一个。于是陷入死锁，无尽的等待。 所以，具体使用notify还是notifyAll 就得具体情况具体分析了。]]></content>
      <categories>
        <category>编程</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>多线程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[java同步锁锁什么]]></title>
    <url>%2F2015%2F12%2F17%2Fjava%E5%90%8C%E6%AD%A5%E9%94%81%E9%94%81%E4%BB%80%E4%B9%88%2F</url>
    <content type="text"><![CDATA[在今天的苦逼遍代码的过程中，有这样一个问题困扰了我半天：情景是这样的：有N个线程ThreadTest，在类A中被创建。构造ThreadTest，向其传入A中的成员变量 Integer i;ThreadTest中的成员变量 j 被赋值为 i在 ThreadTest 的 run 方法中，我 加入了 synchronized块，对象锁正是 j ;在synchronized块中，我改变了这个 j 的值。代码大概是这样的： 123456789Integer j;ThreadTest(Integer i)&#123; j=i;&#125;public void run() &#123; synchronized(j)&#123; j++; &#125;&#125; 一方面 我希望这N个线程操作的是同一个 Integer （引用），我需要多个线程改变这个 Integer 的值 来更新进度条。 另一方面，各个线程之间还要互斥地访问这个变量。于是有了上面的写法。 苦逼了。结果不对后来想了想，发现了这样一个问题：当调用 Java 中的一个函数的时候传入实参对象引用，在这个函数内部会将这个引用复制一份，即 void test(Object i){ i.dosomething()…… }函数体中的i 与 传入的实参 i 实际上是两个不同的引用 指向了同一份内存。这样就解释了出错的 原因：Integer 是不可变类 当对 Integer 进行加减操作时，会 重新new 一份出来赋给 原来的引用变量。所以 对于 1. 当执行j++ 的时候，j已经指向了另一个内存 此时 这个 j 与其他线程中的 j 都不是同一个对象了 无法实现操作同一个对象的愿望 对于 2. 使用 synchronized块，对象锁为 j ,这个时候各个线程中的j 已经不是同一个对象了 所以就无法同步 上面的情况也证明了，synchronized 锁的是内存 ，而不是指向内存的引用。 这样的情况也说明了另外一种情况的问题，那就是在函数中给实参分配内存,实际在函数体外是得不到这个对象的。 解决的办法：放弃使用 Integer（当初使用Integer而不是int的原因就在于各个线程希望操作同一个对象），用一个类将int 封装起来，将这个类对象作为同步关键字，各个线程操作这个对象中的 int 。这样，所有的线程都在修改同一份内存里的东西。]]></content>
      <categories>
        <category>编程</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>多线程</tag>
      </tags>
  </entry>
</search>